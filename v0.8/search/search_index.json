{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Sqooler","text":"<p>Sqooler is a pydantic based SDK that allows you to receive jobs for quantum quantum hardware in a reliable fashion. It is therefore meant for the developer and quantum hardware owner who wants to provide a cloud access to their code in a secure fashion. A few important features:</p> <ul> <li>The PC never has to grant access privileges to any outside contributor.</li> <li>The remote jobs are heavily controlled through pydantic.</li> <li>Simple setup through templates.</li> </ul>"},{"location":"#our-related-projects","title":"Our related projects","text":"<ul> <li><code>labscript-qc-example</code> - Template to provide cloud access to your labscript code.</li> <li><code>sqooler-example</code> - Template to provide cloud access to your simulator.</li> <li><code>qlued</code> - Webkit for user management etc.</li> </ul>"},{"location":"#related-projects","title":"Related projects","text":"<ul> <li><code>labscript</code> - The labscript suite is a powerful and extensible framework for experiment composition, control, execution, and analysis.</li> <li><code>qiskit-cold-atom</code> - qiskit code to access cold atoms as an end user.</li> </ul>"},{"location":"contributing/","title":"Welcome to the sqooler contributing guide","text":"<p>Thank you for investing your time in potentially contributing to our project! Any contribution you make will be reflected on the repository of the open source project sqooler .</p> <p>You can contribute to the sqooler  content and site in several ways, which we will present you below. </p>"},{"location":"contributing/#discussions","title":"Discussions","text":"<p>Discussions are where we have conversations.</p> <p>If you'd like help troubleshooting a sqooler PR you're working on, have a great new idea, or want to share something amazing you've learned about quantum hardware access, join us in discussions.</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Issues are used to track tasks that contributors can help with. </p> <p>If you've found something in the content or the code that should be updated, search open issues to see if someone else has reported the same thing. If it's something new, open an issue here. We'll use the issue to have a conversation about the problem you want to fix.</p>"},{"location":"contributing/#create-a-new-issue","title":"Create a new issue","text":"<p>If you spot a problem with the docs, search if an issue already exists. If a related issue doesn't exist, you can open a new issue.</p>"},{"location":"contributing/#solve-an-issue","title":"Solve an issue","text":"<p>Scan through our existing issues to find one that interests you. You can narrow down the search using labels as filters. See Labels for more information. As a general rule, we don\u2019t assign issues to anyone. If you find an issue to work on, you are welcome to open a PR with a fix.</p>"},{"location":"contributing/#make-changes-in-the-github-ui","title":"Make Changes in the github UI","text":"<p>Click Make a contribution at the top of any page to make small changes such as a typo, sentence fix, or a broken link. This takes you to the .md file where you can make your changes and create a pull request for a review.</p>"},{"location":"contributing/#commit-your-update","title":"Commit your update","text":"<p>Commit the changes once you are happy with them. Don't forget to self-review to speed up the review process .</p>"},{"location":"contributing/#pull-requests","title":"Pull requests","text":"<p>A pull request is a way to suggest changes in our repository. When we merge those changes, they should be deployed to the live site almost immediately. </p> <p>So when you're finished with the changes, create a pull request, also known as a PR.</p> <ul> <li>Fill the description so that we can review your PR. This template helps reviewers understand your changes as well as the purpose of your pull request. </li> <li>Don't forget to link PR to issue if you are solving one.</li> <li>Enable the checkbox to allow maintainer edits so the branch can be updated for a merge. Once you submit your PR, a sqooler team member will review your proposal. We may ask questions or request additional information.</li> <li>We may ask for changes to be made before a PR can be merged, either using suggested changes or pull request comments. You can apply suggested changes directly through the UI. You can make any other changes in your fork, then commit them to your branch.</li> <li>As you update your PR and apply changes, mark each conversation as resolved.</li> <li>If you run into any merge issues, checkout this git tutorial to help you resolve merge conflicts and other issues.</li> </ul>"},{"location":"contributing/#your-pr-is-merged","title":"Your PR is merged!","text":"<p>Congratulations  The sqooler team thanks you . </p> <p>Once your PR is merged, your contributions will be publicly visible on the sqooler repo. </p> <p>Now you are part of the sqooler community. Thank you for your contributions! We look forward to working with you to make our project even better.</p>"},{"location":"contributing/#attribution","title":"Attribution","text":"<p>These contribution guidelines are adapted from the contribution guidelines for Github docs, available online on the github.</p>"},{"location":"description/","title":"General description","text":"<p>In this document, we will outline the general ideas behind <code>sqooler</code>. <code>sqooler</code> was built by cold atom hardware providers who wanted something like <code>qiskit</code> or <code>pennylane</code> for their systems. It is meant to allow access to quantum hardware to non-experts in the construction and maintenance of quantum hardware to provide access to their hardware. It also stems from the observation the different people have very different interests.</p> <ul> <li>As a user, often a theoretical physicist,  we have very little interest in the supplier of the calculation. We just want the calculation properly done. In the following we will call this person Alice.</li> <li>As a supplier backend provider, often experimental physicists or engineers, we have little interest in the person demanding the calculation. If you are european you might even be happy to not know too much about them. In the following we will call this person Bob.</li> </ul> <p>Until now we might sketch the whole process up like this:</p> <pre><code>sequenceDiagram\n  autonumber\n  actor Alice\n  actor Bob\n  Alice-&gt;&gt;Bob: I want to have a calculation done.\n  Bob-&gt;&gt;Alice: Send me your instructions that go with the hardware constraints.\n  Alice-&gt;&gt;Bob: Here are my instructions.\n  loop shots\n        Bob-&gt;&gt;Bob: Verify the instruction!\n        Bob-&gt;&gt;Bob: Execute the job!\n        Bob-&gt;&gt;Bob: Save the results in a nice fashion!\n  end\n  Bob-&gt;&gt;Alice: Here are the (signed) results.</code></pre> <p>In the typical collaboration between experimental and theoretical physicists the whole process would be done in long and detailled discussions. However, with <code>sqooler</code> we standardize the process and make it more efficient. This standardization comes with the following choices:</p> <ul> <li>All operations on the hardware are formulated as discrete gates. This abstracts away the hardware and makes it possible to use the same code for different hardware.</li> <li>The instructions are sent in a json format. This makes it easy to verify the instructions and to execute the job.</li> <li>The results are sent back in a json format. This makes it easy to verify the results and to save them in a nice fashion.</li> <li>We align with the qiskit ecosystem where possible. However, we are much closer to the \"metal\" than most qiskit modules.</li> </ul> <p>As you can see the above diagram contains all the necessary steps to get the job done. </p>"},{"location":"description/#the-basic-architecture","title":"The basic architecture","text":"<p>It was around this idea that <code>sqooler</code> was built. Technically it was implemented in the following rough architecture:</p> <ul> <li>Alice communicates only with a <code>qlued</code> server. This server is responsible to enforce all the above standards.</li> <li>If the received instructions are valid, the <code>qlued</code> server sends the instructions to a storage.</li> <li>Bob looks regularly into the storage, executes the jobs and safe the results there. He never interacts with the qlued instance or Alice.</li> </ul> <p>Hence, we can sketch the information exchange as follows:</p> <pre><code>flowchart LR\n    id1(Alice) -- json API --- id2[qlued]\n    id2[qlued] -- sqooler --- id3[(storage)]\n    id3[(storage)] -- sqooler --- id4(Bob)</code></pre> <p>This means that Alice only needs to have an efficient way to communicate with the qlued instance. This problem is solved by <code>qlued</code> and <code>qiskit-cold-atoms</code>:</p> <ul> <li><code>qlued</code> provides a json API with all the necessary endpoints to send in the instructions.</li> <li><code>qiskit-cold-atoms</code> provides a circuit based qiskit module to directly access the qlued instance as any other provider.</li> </ul> <p>Any interaction with the storage happens through <code>sqooler</code>.  Especially the interaction between Bob and the database happens through <code>sqooler</code>:</p> <ul> <li>Bob is regularly looking for new jobs in the storage, executes them and saves the results there.</li> <li>This makes sure that Bob never has to grant access privileges to any outside contributor.</li> <li>This also decouples the execution of the jobs from the communication with Alice.</li> </ul> <p>For more details on the implementation feel free to look into the detailled documents. </p>"},{"location":"description/#a-few-words-on-decentralization","title":"A few words on decentralization","text":"<p>The whole scheme is set up to be as modular as possible. This makes the maintenance of the system easier and allows for a lot of flexibility. Some key considerations are:</p> <ul> <li>Anyone can set up a <code>qlued</code> instance and provide access to their hardware.</li> <li>Any <code>qlued</code> instance can be connected to several storages. Ownership of the <code>qlued</code> instance and the storage can be decoupled.</li> <li>Bob can choose to work with any storage he likes. For the moment the queue is not set up to work with several storages at the same time. However, this is a feature that could be easily added in the future if there is a demand for it.</li> </ul> <p>This means that the whole scheme can be fairly decentral and does not necessarily involve any trust. The only needed trust is at the following points:</p> <ul> <li>Alice has to trust that she receives good results. How this can be tested for a quantum computer is to our understanding a hard and fairly open problem.</li> <li>The storage provider has to put the access keys into the <code>qlued</code> instance. Right now we have not yet cryptographically encrypted the access keys. Adding this feature would actually also allow us to remove any trust from the storage provider.</li> </ul> <p>Finally, you might have recognized that the whole scheme does not involve any financial incentives for anyone. Considerations there are on </p>"},{"location":"idea_payment/","title":"Ideas on payment","text":"<p>In this document, I will outline some ideas on how to handle payment in the app. This is still a very rough sketch, but might be a good starting point for further discussion. I will try to summarize the problem and then outline some ideas on how to solve it. There seem to be two possible ways to handle payment:</p> <ol> <li>The centralized way where everything is handled in chain of trust.</li> <li>The decentralized way where the payment is handled through a blockchain.</li> </ol> <p>I will try to explore both options and then also outline the challenges. Let us get back to the scheme from the description and extend it by the basic idea of money versus results.</p> <pre><code>flowchart LR\n    id1(Alice) -- json API --- id2[qlued]\n    id2[qlued] -- sqooler --- id3[(storage)]\n    id3[(storage)] -- sqooler --- id4(Bob)\n    id1(Alice) == payment ===&gt; id4(Bob)</code></pre> <p>The challenge is now to integrate payment into this system.</p>"},{"location":"idea_payment/#some-simple-ideas-on-how-to-integrate-payment","title":"Some simple ideas on how to integrate payment","text":"<p>The simplest idea is to go with low-tech and allow access to specific users only. This is the traditional way to handle access to a service. However, this is not very flexible and does not allow for a lot of automation. So you would like to be able to charge for the service. Several options are imaginable:</p> <ul> <li>Flatrate If you have large customers they would most likely be interested in a monthly flatrate. This is easy and predicatable. Possibly even very interesting for systems such as simulators. However, they have a massive drawback for the occasional user that would just like to use the system for some specific jobs.</li> <li>Pay per use This is the most flexible way to handle payment. However, it is also the most complicated to set up and predict the pricing. But it seems likely that this is the way to go at least for the capital intense systems.</li> </ul> <p>Both options are fairly interesting for users and for backend providers. </p>"},{"location":"idea_payment/#some-ideas-on-pay-per-use","title":"Some ideas on pay per use","text":"<p>The typical usage would be to tie the whole thing together and basically wrap a service like stripe into the service.  Then you send the job in a trusted way to the person doing the calculation and there you go. </p> <p>Note</p> <p>It could be interesting to have a look how the structure is behind Polar. They seem to have a similar problem concerning payment between user and service provider.</p> <p>Most likely it would also have to have the following requirements:</p> <ul> <li>Alice has to register with some payment options.</li> <li>Bob has to register with some payment options.</li> <li>The system has to securely send the money from Alice to Bob.</li> <li>Alice has to be able to see the cost of a calculation before she submits it. Or does she ?</li> </ul> <p>This brings up the question on how to calculate the estimated costs:</p> <ul> <li>You might just say that each shot costs some amount of money.</li> <li>You might also base the costs on the time the calculation takes this is similiar to the way cloud services are often billed.</li> <li>When should be the money transferred ? Most likely some monthly bill would be most reasonable ?</li> <li>How can Bob sign his results such that the ownership is clear ? Maybe something like an MD5 hash that includes his username and the json file with the results ? This would be especially important for research groups.</li> </ul> <p>Whatever the case, we really have to enable Bob to register and this brings him back into <code>qlued</code>. </p>"},{"location":"idea_payment/#some-ideas-on-the-decentralized-way","title":"Some ideas on the decentralized way","text":"<p>As mentionned at the end of the description the system is set up with as much decoupling as possible for the moment. As we have seen Bob can easily change the storage, has no connection with Alice and lives a fairly indpendent life. So you start to wonder if the system could not be transferred to some fancy blockchain infrastructure. The system would then look very roughly like this:</p> <pre><code>flowchart LR\n    id1(Alice) --- id2[smart contract]\n    id2[smart contract] --- id3(Bob)</code></pre> <p>The logic would then be something like this:</p> <ul> <li>Alice sends a job to the smart contract.</li> <li>Bob picks up the job and does the calculation.</li> <li>Bob sends the result back to the smart contract and gets paid.</li> </ul> <p>This is tempting in several ways:</p> <ul> <li>It pushes the decentralization to the most extreme.</li> <li>Block-chain systems are all about payment options so the technology sounds like a good fit.</li> <li>The whole user registration etc gets fully offloaded to the blockchain with masks etc.</li> <li>The whole privacy issue is also simplified due the use of wallets.</li> <li>For research groups it could be extra interesting as the ownership of the calculation is very clearly traceble.</li> </ul> <p>The setup obivously also raises a lot of questions. Some of the main questions are:</p> <ol> <li>How can Alice make sure that she is the only one that can access the results if she wants them to be private?</li> <li>How can Alice be sure that she receives \"good\" results?</li> <li>How much are the gas costs? </li> </ol> <p>If you have any technical input to the questions above you are welcome to contribute to the discussion. Until we have some good draft in this direction we will most likely have to stick to the centralized way.</p>"},{"location":"releases/","title":"Release information","text":"<p>In this guide we will cover the key information about the different releases.</p>"},{"location":"releases/#v08","title":"v0.8","text":"<p>In this release we focused on a substantially more flexible <code>StorageProvider</code> and added the new <code>StorageCore</code>.</p>"},{"location":"releases/#whats-changed","title":"What's Changed","text":"<ul> <li>We introduced the <code>StorageCore</code> that only contains the essential file manipulations.</li> <li>Simpler testing as <code>get_dummy config</code> is now part of the <code>utils</code> module.</li> <li>Made the function in the <code>StorageCore</code> and <code>StorageProvider</code> more consistent.</li> <li>Verify that the display name in the uploaded config dict is the same as the argument that was used</li> <li>Made the path used in the <code>MongodbProvider</code> more transparent.</li> <li>Add some documentation on the <code>StorageProvider</code>.</li> </ul>"},{"location":"releases/#migration-guide","title":"Migration Guide","text":"<p>We have simplified the naming of a number of functions and depreceated them:</p> <ul> <li><code>update_file</code> is now <code>update</code></li> <li><code>get_file_content</code> is now <code>get</code></li> <li><code>upload_file</code> is now <code>upload</code></li> <li><code>delete_file</code> is now <code>delete</code></li> <li><code>move_file</code> is now <code>move</code></li> <li><code>get_job_content</code> is now <code>get_job</code></li> </ul> <p>This also likely the last release which allows the <code>operational</code> attribute in the <code>BackendConfigSchemaIn</code>.</p>"},{"location":"releases/#v07","title":"v0.7","text":"<p>We focused on a simpler usage of the sqooler in this release and the stabilization of the code.</p>"},{"location":"releases/#whats-changed_1","title":"What's Changed","text":"<ul> <li>Make the operational status depend on last checked</li> <li>Fix the default if the <code>private_jwk</code> is missing </li> <li>Make the delay between runs in the main loop adjustable</li> <li>Remove the operational status from the backend config. Now calculated directly from the last time the queued was checked</li> <li>Sign also upload status</li> <li>Identify the kid with the display name of the spooler</li> <li>Add a simple option to verify results</li> <li>Have a command line option to create the private jwk string</li> <li>Fail get next safely if no config is presen</li> <li>Cleaner tests for improved coverage and more precise testing</li> <li>Migration fixes for upgrades from v0.6</li> </ul>"},{"location":"releases/#migration-guide_1","title":"Migration Guide","text":"<ul> <li>The operational status is now dependent on the last checked in time. This means that the operational status is now only <code>True</code> if the last checked in time is less than the <code>T_TIMEOUT</code>. It can be set as a config variable.</li> <li><code>T_WAIT_MAIN</code> set the relay between loops in the <code>main</code> function. It can be set as a config variable.</li> </ul>"},{"location":"releases/#v06","title":"v0.6","text":"<p>In this release, we continued the work on clean typing and we introduced first concepts for better security and logging, so extending the list of features.</p>"},{"location":"releases/#whats-changed_2","title":"What's Changed","text":"<ul> <li>Improved documentation </li> <li>Fix the cold atom type by </li> <li>Clean distinction between backend name and display name </li> <li>timestamp the loops of the queue</li> <li>Much cleaner add job </li> <li>Cleaner tests </li> <li>Make it possible to sign the results for the backend supplier </li> <li>Delete file should fail if file does not exist</li> <li>Do not allow to add a config with a name that already exists</li> <li>Make it possible to log basic activities</li> </ul>"},{"location":"releases/#migration-guide_2","title":"Migration Guide","text":"<ul> <li>We have changed the syntax for the <code>gen_circuit</code> function to make it simpler to understand the code. It now takes the <code>exp_name</code> as the first argument and the <code>exp_dict</code> of the new type <code>ExperimentalInputDict</code> as the second argument. </li> <li>We are now distinguishing pretty strictly between the <code>backend_name</code> and the <code>display_name</code>. The <code>display_name</code> is the short alphanumeric string that acts as identifier. The <code>backend_name</code> also contains the name of the <code>StorageProvider</code> and if the system is a simulator or not.</li> <li>To sign the results and the config you need to store a private <code>jwk</code> as described in the documentation for security.</li> <li>The <code>add_job</code> function now takes the <code>job_id</code> as the second parameter instead of the the <code>StatusMsgDict</code>. This removed some error sources.</li> </ul>"},{"location":"releases/#v05","title":"v0.5","text":"<p>This release further increased the typing and testing of the package. It also fixed some long standing usability bugs for the user. </p>"},{"location":"releases/#whats-changed_3","title":"What's Changed","text":"<ul> <li>Cleaner error handling of missing status</li> <li>Unify the error handling for the <code>get_file_content</code> function amongst <code>StorageProvider</code>s.</li> <li>Put the different <code>StorageProvider</code>s into the <code>storage_provider</code> module to make it easier to add new ones.</li> <li>Type and verify the status string to be \"INITIALIZING\", \"QUEUED\", \"DONE\", \"ERROR\" and introduce the functions <code>get_init_status</code> as well as <code>get_init_results</code> that help with the initialization.</li> <li>Clean out the names given to the backends and storage providers such that they conform with the intended logic of being alphanumeric names only.</li> <li>Enforce the coupling map of the <code>GateInstruction</code>.</li> <li>Give back the measured wires and the instructions for each experiment to make it easier to reconstruct. </li> <li>Introduced the new <code>DataDict</code> for better typing for the results.</li> </ul>"},{"location":"releases/#v04","title":"v0.4","text":"<p>This release focused on better typing with <code>pydantic</code> and a simpler deployment on the back-end side.</p>"},{"location":"releases/#whats-changed_4","title":"What's Changed","text":"<ul> <li>Introduce the <code>StatusMsgDict</code> for proper typing of status messages </li> <li>Enforce cleaner typing of <code>ExperimentDict</code> </li> <li>Improved testing of the <code>Spooler</code> </li> <li>Introduce the <code>GateDict</code> to properly type the <code>gate_list_from_dict</code></li> <li>Improved testing, typing and error handling of the <code>gen_circuit</code> </li> <li>Added <code>LabscriptSpooler</code> class </li> <li>Add the <code>gen_script</code> from the labscriptspooler nd created the <code>spoolers</code> module</li> </ul>"},{"location":"security_general/","title":"Security and signing","text":"<p>In this section we will discuss some of the cryptographic work that we started. All of the code in this regard can be found in the security module.  Before we go into more detail on the discussion, let us remind ourselves of the general architecture of the workflow:</p> <pre><code>flowchart LR\n    id1(Alice) -- json API --- id2[qlued]\n    id2[qlued] -- sqooler --- id3[(storage)]\n    id3[(storage)] -- sqooler --- id4(Bob)</code></pre>"},{"location":"security_general/#signing-the-results","title":"Signing the results","text":"<p>For the moment, we have decided to only sign results and not encrypt them.  For simplicity, we have further focused on the asymmetric signing with ED25519.  This means that only the part at which Bob uploads the results to the storage is signed. Signing / encrypting the other steps of the workflow would be likely desirable, however, it is not implemented yet.</p> <p>Having chosen the results as a first step allows us to keep the workflow as simple as possible. It further introduces the possibility for Bob to show that he is producer of the results and Alice to verify that the results are authentic through the public key. So for the moment it is only needed for Bob to set up a private key and upload the public key to the storage. Similiar possbilities for Alice might follow in the future.</p>"},{"location":"security_general/#setting-up-the-private-key","title":"Setting up the private key","text":"<p>We have decided to work with the widely used crypotgraphic python library cryptography. To use it, Bob first needs to create and store a private key. This done with Json Web Keys as they allow us also to store some context around the key.</p> <p>This is done by running the following command in the terminal:</p> <pre><code>sqoolerkey --kid &lt;YOUR-PREFERRED-KEY-ID&gt; \n</code></pre> <p>The <code>kid</code> is the key id and should be unique for each key. As Bob you can then copy this string into your preferred storage from which we load it.</p> <p>Warning</p> <p>The private key should be kept secret and should not be shared with anyone. Never ever ever. Don't do it. Even if you are a good person and you want to share it with your friends, don't do it.</p>"},{"location":"security_general/#the-public-key","title":"The public key","text":"<p>Once the private is set up, Bob can upload the public key to the <code>StorageProvider</code>. This is done by the <code>upload_public_key</code> method, which stores the public key at the appropiate point in the storage. The public key can then be be accessed by anyone through the <code>get_public_key</code> method. A few important points are here to note about the public key:</p> <ul> <li>We store the public key as Json Web Key (JWK) in the storage. This allows us to store some context around the key.</li> <li>Importantly this also allows us to add the algorithm and a key id.</li> <li>However, for the moment anyone with access to the storage can access and change the public key. This is a security risk that we have not yet addressed. The key challenge will be that the public key is stored and immutable once it is published.</li> <li>It is possible that several <code>Sqooler</code> objects use the same private/public key pair if they run on the same control machine. While this is unlikely for real hardware it is actually exactly the configuration of the sqooler-example. For this reason, we have attached the kid of the pair to each configuration.</li> </ul>"},{"location":"security_general/#verifying-the-results","title":"Verifying the results","text":"<p>Alice is now also able to verify the results through the <code>verify_result</code>, which is available for each <code>StorageProvider</code>. It uses the <code>display_name</code> to get the appropiate public key, the <code>job_id</code> to pull the result and then verifies the payload. </p>"},{"location":"security_general/#signing-the-configuration","title":"Signing the configuration","text":"<p>It is now also possible to sign the backend configuration. This happens automatically if the <code>Spooler</code> object is configured to be signed. The <code>upload_config</code> and <code>update_config</code> will then sign the document before uploading it to the storage. This enables us now to have several backend providers in parallel without a central authority. Importantly, we can now hinder the collusion of two backends with the same name because you can only update the files if you are the owner of the private key.</p>"},{"location":"spooler_general/","title":"Bobs' perspective","text":"<p>In this part, we will focus on a general description of the <code>Spooler</code> object as they  are the central objects for the backend provider, i.e. Bob from the general description. Bob will be in one of two situations:</p> <ol> <li> <p>Bob is really deep into the construction of quantum hardware and focuses a lot on fidelity, scalability etc. In this case, Bob will have a control PC with some complex control system like labscript. In industry it is known as the world of operational technology.</p> </li> <li> <p>Bob loves high performance numerical computing. So he will focus on every in part of the hardware and code to make it as fast as possible. But once again it is a bit unlikely that Bob is deeply focused on a connection to the outside world.</p> </li> </ol> <p>In both cases, Bob will be able to use a <code>Spooler</code> that allows him to interact with others without too much of a hazzle. The <code>Spooler</code> object is actually provides Bob with a common interface to communicate with Alice. There he can define available gates and the configuration of the system. For the specific implementation of the <code>Spooler</code> object, see the API documentation. Here, we will simply describe the general idea of the <code>Spooler</code> object.</p>"},{"location":"spooler_general/#general-idea","title":"General idea","text":"<p>The <code>Spooler</code> allows Bob to define:</p> <ul> <li>The available gates in th <code>ins_schema_dict</code> that contains the input schema of the gates</li> <li>Translate the gates in executable code through the <code>gen_circuit</code> function</li> <li>Define a substantial amount of general properties like the name, maximum amount of executions, etc.</li> <li>Manage jobs through the <code>add_job</code> function.</li> <li>Directly connect to the <code>StorageProvider</code> where Alice submit her jobs.</li> <li>If Bob is a bit more advanced, he can also sign the jobs with a private key and improve the security of the system.</li> </ul>"},{"location":"spooler_general/#the-different-types-of-spooler","title":"The different types of <code>Spooler</code>","text":"<p>There are different types of <code>Spooler</code> objects that Bob can use. </p> <ul> <li>The <code>BaseSpooler</code> provides the basic functionality of the <code>Spooler</code> object. It is the base class for all other <code>Spooler</code> objects.</li> <li>The <code>LabscriptSpooler</code> is a <code>Spooler</code> object that is used for hardware controlled by labscript.</li> <li>The <code>Spooler</code> class that is mostly adopted for numerical code.</li> </ul>"},{"location":"spooler_general/#the-operational-status","title":"The operational status","text":"<p>One of the hardest things to get right is the operational status of your machine. </p> <ul> <li>In the most naive approach you might say that Alice will figure it out if the device is not around and that's it. </li> <li>In the second step, you would like to be able to set the operational status and make it transparent to Alice. This was actually possible through the <code>operational</code> property for some time.</li> <li>But bad things might happen to your system and it might take Bob quite some time to see that the machine is currently not available. And once Bob figures this out he certainly has better things to do than to set the operational status to <code>False</code>. </li> </ul> <p>So with <code>v0.6</code> of the code we have introduced the <code>last_queue_check</code> as a property of the <code>Sqooler</code> configuration. This provides Alice additional information and might allow Alice to decide on her own if she sees the machine as active. </p> <p>In <code>v0.7</code> we started to calculate the <code>operational</code> status based on the <code>last_queue_check</code>. This made the parameter <code>operational</code> of the spooler irrelevant and we could simply calculate it for the config dictionary. So based on these properties, we are currently at the following situation:</p> <ul> <li>Each <code>StorageProvider</code> has a function <code>get_backend_status</code> that gives back the current status of the device. The here is just calculated from the last time the queue was checked.</li> </ul> <p>So the <code>operational</code> status does not need to be set by Bob at all. We just calculate it based on the other information provided by Bob.</p>"},{"location":"storage_general/","title":"Introduction to storage providers","text":"<p>In this part, we will focus on a general description of the <code>StorageProvider</code> object as they are essential links between the backend provider, i.e. Bob from the general description, and the frontend provider, i.e. Alice. For the specific implementation of the <code>StorageProvider</code> object, see the API documentation. The <code>StorageProvider</code> fulfills two major objectives:</p> <ol> <li>It gives a common set of functions to the backend provider to store and retrieve information that is necessary for the operation.</li> <li>It provides a basic interface that is implemented by different storages like a local file system, an unstructured database, or a cloud storage.</li> </ol> <p>In the following, we will therefore explain the basic ideas behind the objects and how they are used within the <code>sqooler</code> package.</p>"},{"location":"storage_general/#core-functions","title":"Core functions","text":"<p>In any situation Bob and Alice have to manipulate information on the storage. And the basic functions are very much the same. Therefore we have defined the <code>StorageCore</code>, which defines the basic set of functions that are necessary for the operation. These functions are:</p> <ul> <li><code>upload</code>: Uploads a file to the storage to the given path.</li> <li><code>update</code>: Updates a file in the storage at the given path.</li> <li><code>get</code>: Gets a file from the storage at the given path.</li> <li><code>move</code>: Moves a file from one path to another.</li> <li><code>delete</code>: Deletes a file from the storage at the given path.</li> </ul> <p>So it is basically a standardized CRUD interface, which allows you to build upon on fairly easily the more complicated functions.</p>"},{"location":"storage_general/#storage-provider","title":"Storage provider","text":"<p>The <code>StorageProvider</code> wraps around the <code>StorageCore</code> and provides a more high-level interface that really makes it possible to send quantum circuits around and check their status. It provides functionality to manipulate the following main points:</p> <ul> <li>Configuration: Somehow Alice and Bob need to exchange information about the configuration of the backend on which the calculation should be performed. This can be done with the appropiate <code>upload_config</code>, <code>update_config</code> and <code>get_config</code>. The <code>get_backend_dict</code> and <code>get_backend_status</code> wrapped around the <code>get_config</code> to provide information that is compatible with <code>QISKIT</code>. </li> <li>Job: Alice main interest in the system is to submit jobs. So the <code>StorageProvider</code> has functions to <code>upload_job</code>, <code>get_job</code>. Bob is further able to handle the jobs in th queue through <code>get_next_job_in_queue</code>.</li> <li>Result: After the job is done, Bob needs to store the results. This is done with the <code>upload_result</code> and <code>get_result</code> functions. It is also possible to verify the origin with <code>verify_result</code>.</li> <li>Status: The <code>StorageProvider</code> also provides functions to update the status of the job with <code>upload_status</code> and <code>get_status</code>. </li> <li>Keys: The <code>StorageProvider</code> also provides functionality to sign and verify files through the functionality of the security module.</li> </ul> <p>All of this is set up to be as flexible as possible and we have now implemented the <code>StorageProvider</code> for three different storage systems:</p> <ul> <li>Local files: This is most helpful for testing and small users. For more information see local.</li> <li>MongoDB: This is a more scalable solution that can be used for larger projects. For more information see mongodb.</li> <li>Dropbox: One of the classic cloud storage providers. For more information see dropbox.</li> </ul>"},{"location":"api/cli_api/","title":"API documentation of cli","text":"<p>This module contains some cli commands that simplify the work with the sqooler package.</p>"},{"location":"api/cli_api/#src.sqooler.cli.cli_private_key_str","title":"<code>cli_private_key_str(kid)</code>","text":"<p>This command line allows you to generate a private key string that is necessary to enable signing within sqooler.</p> Source code in <code>src/sqooler/cli.py</code> <pre><code>@click.command()\n@click.option(\n    \"--kid\", prompt=\"Key ID\", help=\"The key identifier. Should be short and unique.\"\n)\ndef cli_private_key_str(kid: str) -&gt; None:\n    \"\"\"\n    This command line allows you to generate a private key string that is necessary to enable\n    signing within sqooler.\n    \"\"\"\n    private_jwk, _ = create_jwk_pair(kid=kid)\n    private_key_str = private_jwk.to_config_str()\n    click.echo(\"Your private key is:\\n\")\n    click.secho(private_key_str, fg=\"green\")\n    click.echo(\"\\n\")\n    click.echo(\"Save it now in the environment variables or the appropiate .env file\")\n</code></pre>"},{"location":"api/schemes/","title":"API documentation of schemes","text":"<p>The module that contains common logic for schemes, validation etc. There is no obvious need, why this code should be touch in a new back-end.</p>"},{"location":"api/schemes/#src.sqooler.schemes.BackendConfigSchemaIn","title":"<code>BackendConfigSchemaIn</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The schema send in to detail the configuration of the backend. This is uploaded to the storage provider.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class BackendConfigSchemaIn(BaseModel, validate_assignment=True):\n    \"\"\"\n    The schema send in to detail the configuration of the backend.\n    This is uploaded to the storage provider.\n    \"\"\"\n\n    description: str = Field(description=\"A description for the backend\")\n    version: str = Field(description=\"The backend version in the form X.Y.Z\")\n    display_name: Optional[DisplayNameStr]\n    cold_atom_type: ColdAtomStr\n    gates: list = Field(\n        description=\"The list of GateConfig objects for the basis gates of the backend\"\n    )\n    max_experiments: int = Field(\n        description=\"The maximum number of experiments per job\"\n    )\n    max_shots: int = Field(\n        description=\"The maximum number of shots allowed on the backend\"\n    )\n    simulator: bool = Field(description=\"True if the backend is a simulator\")\n    supported_instructions: list[str] = Field(\n        description=\"Instructions supported by the backend.\"\n    )\n    num_wires: int = Field(description=\"The number of qubits / wires for the backend\")\n    wire_order: WireOrderStr\n    num_species: int = Field(description=\"The number of species in the system.\")\n\n    pending_jobs: Optional[int] = Field(\n        default=None, description=\"The number of pending jobs on the backend\"\n    )\n    status_msg: Optional[str] = Field(\n        default=None, description=\"The status message for the backend\"\n    )\n    last_queue_check: Optional[datetime] = Field(\n        default=None, description=\"The last time the queue was checked.\"\n    )\n    sign: bool = Field(\n        default=False,\n        description=\"True if the results are signed by the backend provider.\",\n    )\n    kid: Optional[str] = Field(\n        default=None,\n        description=\"The identifier for the public and private key of the backend.\",\n    )\n    operational: Optional[bool] = Field(\n        default=True, description=\"True if the backend is operational\", deprecated=True\n    )\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.BackendConfigSchemaOld","title":"<code>BackendConfigSchemaOld</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The schema send in to detail the configuration of the backend. This is uploaded to the storage provider.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class BackendConfigSchemaOld(BaseModel, validate_assignment=True):\n    \"\"\"\n    The schema send in to detail the configuration of the backend.\n    This is uploaded to the storage provider.\n    \"\"\"\n\n    description: str = Field(description=\"A description for the backend\")\n    version: str = Field(description=\"The backend version in the form X.Y.Z\")\n    display_name: Optional[DisplayNameStr]\n    cold_atom_type: ColdAtomStr\n    gates: list = Field(\n        description=\"The list of GateConfig objects for the basis gates of the backend\"\n    )\n    max_experiments: int = Field(\n        description=\"The maximum number of experiments per job\"\n    )\n    max_shots: int = Field(\n        description=\"The maximum number of shots allowed on the backend\"\n    )\n    simulator: bool = Field(description=\"True if the backend is a simulator\")\n    supported_instructions: list[str] = Field(\n        description=\"Instructions supported by the backend.\"\n    )\n    num_wires: int = Field(description=\"The number of qubits / wires for the backend\")\n    wire_order: WireOrderStr\n    num_species: int = Field(description=\"The number of species in the system.\")\n\n    pending_jobs: Optional[int] = Field(\n        default=None, description=\"The number of pending jobs on the backend\"\n    )\n    status_msg: Optional[str] = Field(\n        default=None, description=\"The status message for the backend\"\n    )\n    last_queue_check: Optional[datetime] = Field(\n        default=None, description=\"The last time the queue was checked.\"\n    )\n    sign: bool = Field(\n        default=False,\n        description=\"True if the results are signed by the backend provider.\",\n    )\n    kid: Optional[str] = Field(\n        default=None,\n        description=\"The identifier for the public and private key of the backend.\",\n    )\n    operational: Optional[bool] = Field(\n        default=True, description=\"True if the backend is operational\", deprecated=True\n    )\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.BackendConfigSchemaOut","title":"<code>BackendConfigSchemaOut</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The schema send out to detail the configuration of the backend. We follow the conventions of the qiskit configuration dictionary here.</p> <p>Will becomes compatible with qiskit.providers.models.BackendConfiguration</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class BackendConfigSchemaOut(BaseModel, validate_assignment=True):\n    \"\"\"\n    The schema send out to detail the configuration of the backend. We follow the\n    conventions of the qiskit configuration dictionary here.\n\n    Will becomes compatible with qiskit.providers.models.BackendConfiguration\n    \"\"\"\n\n    description: str = Field(description=\"A description for the backend\")\n    display_name: DisplayNameStr\n    conditional: bool = Field(\n        default=False, description=\"True if the backend supports conditional operations\"\n    )\n    coupling_map: str = Field(\n        default=\"linear\", description=\"The coupling map for the device\"\n    )\n    dynamic_reprate_enabled: bool = Field(\n        default=False,\n        description=\"whether delay between programs can be set dynamically \",\n    )\n    local: bool = Field(\n        default=False, description=\"True if the backend is local or False if remote\"\n    )\n    memory: bool = Field(default=False, description=\"True if backend supports memory\")\n    open_pulse: bool = Field(default=False, description=\"True if backend is OpenPulse\")\n    backend_version: str = Field(description=\"The backend version in the form X.Y.Z\")\n    n_qubits: int = Field(description=\"The number of qubits / wires for the backend\")\n    backend_name: BackendNameStr\n    basis_gates: list[str] = Field(\n        description=\"The list of strings for the basis gates of the backends\"\n    )\n    max_experiments: int = Field(\n        description=\"The maximum number of experiments per job\"\n    )\n    max_shots: int = Field(\n        description=\"The maximum number of shots allowed on the backend\"\n    )\n    simulator: bool = Field(description=\"True if the backend is a simulator\")\n    gates: list = Field(\n        description=\"The list of GateConfig objects for the basis gates of the backend\"\n    )\n    supported_instructions: list[str] = Field(\n        description=\"Instructions supported by the backend.\"\n    )\n    cold_atom_type: ColdAtomStr\n    wire_order: WireOrderStr\n    num_species: int = Field(\n        description=\"The number of species in the system. Non standard qiskit field.\"\n    )\n    url: Optional[str] = Field(default=None, description=\"The url of the backend\")\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.BackendStatusSchemaOut","title":"<code>BackendStatusSchemaOut</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The schema for the status of a backend. Follows the conventions of the <code>qiskit.providers.models.BackendStatus</code>.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class BackendStatusSchemaOut(BaseModel):\n    \"\"\"\n    The schema for the status of a backend. Follows the conventions of the\n    `qiskit.providers.models.BackendStatus`.\n    \"\"\"\n\n    backend_name: BackendNameStr\n    backend_version: str = Field(\n        description=\"The version of the backend. Of the form X.Y.Z\"\n    )\n    operational: bool = Field(description=\"True if the backend is operational\")\n    pending_jobs: int = Field(description=\"The number of pending jobs on the backend\")\n    status_msg: str = Field(description=\"The status message for the backend\")\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.DataDict","title":"<code>DataDict</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A class that defines the structure of the data within the ExperimentDict.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class DataDict(BaseModel):\n    \"\"\"\n    A class that defines the structure of the data within the ExperimentDict.\n    \"\"\"\n\n    memory: list[str] = Field(description=\"A list of results safed as string.\")\n    instructions: Optional[list[GateDict]] = Field(\n        default=None, description=\"The indices of the wires that were measured.\"\n    )\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.DropboxLoginInformation","title":"<code>DropboxLoginInformation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The login information for the dropbox</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class DropboxLoginInformation(BaseModel):\n    \"\"\"\n    The login information for the dropbox\n    \"\"\"\n\n    app_key: str\n    app_secret: str\n    refresh_token: str\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.ExperimentDict","title":"<code>ExperimentDict</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A class that defines the structure of the experiments. Strongly inspired by the qiskit class qiskit.result.ExperimentData.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class ExperimentDict(BaseModel):\n    \"\"\"\n    A class that defines the structure of the experiments. Strongly inspired by the\n    qiskit class qiskit.result.ExperimentData.\n    \"\"\"\n\n    header: dict = Field(description=\"Contains centralized information about the job.\")\n    shots: int = Field(description=\"number of shots in the experiment.\")\n    success: bool = Field(description=\"True if experiment ran successfully.\")\n    data: DataDict = Field(description=\"dictionary of results for the experiment.\")\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.ExperimentalInputDict","title":"<code>ExperimentalInputDict</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The input for the experimental job.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class ExperimentalInputDict(BaseModel):\n    \"\"\"\n    The input for the experimental job.\n    \"\"\"\n\n    instructions: list[GateDict] = Field(description=\"The instructions for the job\")\n    num_wires: int = Field(description=\"The number of wires for the job\")\n    shots: int = Field(description=\"The number of shots for the job\")\n    wire_order: WireOrderStr\n    seed: Optional[int] = Field(\n        default=None,\n        description=\"The seed for the random number generator if one might be used\",\n    )\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.GateDict","title":"<code>GateDict</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The most basic class for a gate as it is communicated in the json API.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class GateDict(BaseModel):\n    \"\"\"\n    The most basic class for a gate as it is communicated in\n    the json API.\n    \"\"\"\n\n    name: str = Field(description=\"The name of the gate\")\n    wires: list[int] = Field(description=\"The wires on which the gate acts\")\n    params: list[float] = Field(description=\"The parameters of the gate\")\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.GateInstruction","title":"<code>GateInstruction</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The basic class for all the gate intructions of a backend. Any gate has to have the following attributes.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class GateInstruction(BaseModel):\n    \"\"\"\n    The basic class for all the gate intructions of a backend.\n    Any gate has to have the following attributes.\n    \"\"\"\n\n    name: str\n    parameters: str\n    wires: list[int] = Field(description=\"The wires on which the gate acts\")\n    description: str\n    coupling_map: list\n    qasm_def: str = \"{}\"\n    is_gate: bool = True\n\n    @classmethod\n    def config_dict(cls) -&gt; dict:\n        \"\"\"\n        Give back the properties of the instruction such as needed for the server.\n        \"\"\"\n        return {\n            \"coupling_map\": cls.model_fields[\"coupling_map\"].default,\n            \"description\": cls.model_fields[\"description\"].default,\n            \"name\": cls.model_fields[\"name\"].default,\n            \"parameters\": [cls.model_fields[\"parameters\"].default],\n            \"qasm_def\": cls.model_fields[\"qasm_def\"].default,\n        }\n\n    @field_validator(\"wires\")\n    @classmethod\n    def valid_coupling(cls, wires: list) -&gt; list:\n        \"\"\"\n        Validate that the wires are within the coupling map.\n\n        Args:\n            wires: the wires of the gate\n\n        Returns:\n            the wires if they are valid\n\n        Raises:\n            ValueError: if the wires are not within the coupling map\n        \"\"\"\n        if not wires in cls.model_fields[\"coupling_map\"].default:\n            raise ValueError(\"The combination of wires is not in the coupling map.\")\n        return wires\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.GateInstruction.config_dict","title":"<code>config_dict()</code>  <code>classmethod</code>","text":"<p>Give back the properties of the instruction such as needed for the server.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>@classmethod\ndef config_dict(cls) -&gt; dict:\n    \"\"\"\n    Give back the properties of the instruction such as needed for the server.\n    \"\"\"\n    return {\n        \"coupling_map\": cls.model_fields[\"coupling_map\"].default,\n        \"description\": cls.model_fields[\"description\"].default,\n        \"name\": cls.model_fields[\"name\"].default,\n        \"parameters\": [cls.model_fields[\"parameters\"].default],\n        \"qasm_def\": cls.model_fields[\"qasm_def\"].default,\n    }\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.GateInstruction.valid_coupling","title":"<code>valid_coupling(wires)</code>  <code>classmethod</code>","text":"<p>Validate that the wires are within the coupling map.</p> <p>Parameters:</p> Name Type Description Default <code>wires</code> <code>list</code> <p>the wires of the gate</p> required <p>Returns:</p> Type Description <code>list</code> <p>the wires if they are valid</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the wires are not within the coupling map</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>@field_validator(\"wires\")\n@classmethod\ndef valid_coupling(cls, wires: list) -&gt; list:\n    \"\"\"\n    Validate that the wires are within the coupling map.\n\n    Args:\n        wires: the wires of the gate\n\n    Returns:\n        the wires if they are valid\n\n    Raises:\n        ValueError: if the wires are not within the coupling map\n    \"\"\"\n    if not wires in cls.model_fields[\"coupling_map\"].default:\n        raise ValueError(\"The combination of wires is not in the coupling map.\")\n    return wires\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.LabscriptParams","title":"<code>LabscriptParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A class that defines the parameters for the labscript folders.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class LabscriptParams(BaseModel):\n    \"\"\"\n    A class that defines the parameters for the labscript folders.\n    \"\"\"\n\n    exp_script_folder: str = Field(\n        description=\"The relative path to the experimental scripts.\"\n    )\n    t_wait: float = Field(description=\"The time to wait between checks.\")\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.LocalLoginInformation","title":"<code>LocalLoginInformation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The login information for a local storage provider.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class LocalLoginInformation(BaseModel):\n    \"\"\"\n    The login information for a local storage provider.\n    \"\"\"\n\n    base_path: str = Field(\n        description=\"The base path of the storage provider on your local file system.\"\n    )\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.MongodbLoginInformation","title":"<code>MongodbLoginInformation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The login information for MongoDB</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class MongodbLoginInformation(BaseModel):\n    \"\"\"\n    The login information for MongoDB\n    \"\"\"\n\n    mongodb_username: str\n    mongodb_password: str\n    mongodb_database_url: str\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.NextJobSchema","title":"<code>NextJobSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The schema for the next job to be executed.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class NextJobSchema(BaseModel):\n    \"\"\"\n    The schema for the next job to be executed.\n    \"\"\"\n\n    job_id: str = Field(description=\"unique execution id from the backend.\")\n    job_json_path: str = Field(description=\"The path to the job json file.\")\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.ResultDict","title":"<code>ResultDict</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A class that defines the structure of results. It is closely related to the qiskit class qiskit.result.Result.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class ResultDict(BaseModel):\n    \"\"\"\n    A class that defines the structure of results. It is closely related to the\n    qiskit class qiskit.result.Result.\n    \"\"\"\n\n    backend_name: BackendNameStr | None = None\n    display_name: DisplayNameStr\n    backend_version: str = Field(description=\"backend version, in the form X.Y.Z.\")\n    job_id: str = Field(description=\"unique execution id from the backend.\")\n    qobj_id: Optional[str] = Field(default=None, description=\"user-generated Qobj id.\")\n    success: bool = Field(\n        description=\"True if complete input qobj executed correctly.\", default=True\n    )\n    status: StatusStr\n    header: dict = Field(\n        description=\"Contains centralized information about the job.\", default={}\n    )\n    results: list[ExperimentDict] = Field(\n        description=\"corresponding results for array of experiments of the input qobj\",\n        default=[],\n    )\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.StatusMsgDict","title":"<code>StatusMsgDict</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A class that defines the structure of the status messages.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class StatusMsgDict(BaseModel):\n    \"\"\"\n    A class that defines the structure of the status messages.\n    \"\"\"\n\n    job_id: str = Field(description=\"unique execution id from the backend.\")\n    status: StatusStr\n    detail: str = Field(description=\"detailed status of job execution.\")\n    error_message: str = Field(description=\"error message of job execution.\")\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.get_init_results","title":"<code>get_init_results()</code>","text":"<p>A support function that returns the result dict for an initializing job.</p> <p>Returns:</p> Type Description <code>ResultDict</code> <p>the result dict</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def get_init_results() -&gt; ResultDict:\n    \"\"\"\n    A support function that returns the result dict for an initializing job.\n\n    Returns:\n        the result dict\n    \"\"\"\n    return ResultDict(\n        display_name=\"\",\n        backend_version=\"\",\n        job_id=\"\",\n        qobj_id=None,\n        success=True,\n        status=\"INITIALIZING\",\n    )\n</code></pre>"},{"location":"api/schemes/#src.sqooler.schemes.get_init_status","title":"<code>get_init_status()</code>","text":"<p>A support function that returns the status message for an initializing job.</p> <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>the status message</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def get_init_status() -&gt; StatusMsgDict:\n    \"\"\"\n    A support function that returns the status message for an initializing job.\n\n    Returns:\n        the status message\n    \"\"\"\n    return StatusMsgDict(\n        job_id=\"None\",\n        status=\"INITIALIZING\",\n        detail=\"Got your json.\",\n        error_message=\"None\",\n    )\n</code></pre>"},{"location":"api/security_api/","title":"API documentation of security","text":"<p>In this module we define important classes for signing, encryption etc.  Please be aware that this module has not yet undergone a security audit and is still in an early version. Any suggestions for improvements will be very welcome.</p>"},{"location":"api/security_api/#src.sqooler.security.JWK","title":"<code>JWK</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The JSON Web Key (JWK) for Ed25519 as standardized in</p> <p>https://datatracker.ietf.org/doc/html/rfc8037</p> Source code in <code>src/sqooler/security.py</code> <pre><code>class JWK(BaseModel):\n    \"\"\"\n    The JSON Web Key (JWK) for Ed25519 as standardized in\n\n    https://datatracker.ietf.org/doc/html/rfc8037\n    \"\"\"\n\n    x: bytes = Field(\n        description=\"Contain the public key encoded using the base64url encoding\"\n    )\n    key_ops: Literal[\"sign\", \"verify\"] = Field(\n        description=\"Identifies the operation for which the key is intended to be used\"\n    )\n    kid: str = Field(description=\"The key id of the key\")\n    d: Optional[bytes] = Field(\n        default=None,\n        description=\"Contains the private key encoded using the base64url encoding.\",\n    )\n    kty: Literal[\"OKP\"] = Field(\n        default=\"OKP\",\n        description=\"Identifies the cryptographic algorithm family used with the key\",\n    )\n    alg: Literal[\"EdDSA\"] = Field(\n        default=\"EdDSA\", description=\"The algorithm used for signing\"\n    )\n    crv: Literal[\"Ed25519\"] = Field(\n        default=\"Ed25519\", description=\"Identifies the cryptographic curve used\"\n    )\n\n    def to_config_str(self) -&gt; str:\n        \"\"\"\n        Convert the JWK to a string that can be stored in a config file.\n        \"\"\"\n        # now it would be nice to have the whole thing as a string\n        jwk_string = self.model_dump_json()\n\n        # create a byte string\n        jwk_bytes = jwk_string.encode(\"utf-8\")\n\n        # and now we can base64 encode it\n        jwk_base64 = base64.urlsafe_b64encode(jwk_bytes)\n\n        # and for storing it in a file we would like to decode it\n        jwk_base64_str = jwk_base64.decode(\"utf-8\")\n        return jwk_base64_str\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.JWK.to_config_str","title":"<code>to_config_str()</code>","text":"<p>Convert the JWK to a string that can be stored in a config file.</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def to_config_str(self) -&gt; str:\n    \"\"\"\n    Convert the JWK to a string that can be stored in a config file.\n    \"\"\"\n    # now it would be nice to have the whole thing as a string\n    jwk_string = self.model_dump_json()\n\n    # create a byte string\n    jwk_bytes = jwk_string.encode(\"utf-8\")\n\n    # and now we can base64 encode it\n    jwk_base64 = base64.urlsafe_b64encode(jwk_bytes)\n\n    # and for storing it in a file we would like to decode it\n    jwk_base64_str = jwk_base64.decode(\"utf-8\")\n    return jwk_base64_str\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.JWSDict","title":"<code>JWSDict</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A JSON Web Signature in a dictionary form. We follow the JWS standard as defined in RFC 7515.</p> <p>https://datatracker.ietf.org/doc/html/rfc7515</p> Source code in <code>src/sqooler/security.py</code> <pre><code>class JWSDict(BaseModel):\n    \"\"\"\n    A JSON Web Signature in a dictionary form. We follow the JWS standard as defined in RFC 7515.\n\n    https://datatracker.ietf.org/doc/html/rfc7515\n    \"\"\"\n\n    header: JWSHeader = Field(description=\"The header of the JWS object\")\n    payload: dict = Field(description=\"The payload of the JWS object\")\n    signature: str = Field(\n        description=\"The signature of the JWS objec. It is base64url encoded as a string.\"\n    )\n\n    def verify_signature(self, public_jwk: JWK) -&gt; bool:\n        \"\"\"\n        Verify the integraty of JWS object.\n\n        Args:\n            public_jwk: The public key to use for verification\n\n        Returns:\n            if the signature can be verified\n        \"\"\"\n\n        if not public_jwk.key_ops == \"verify\":\n            raise ValueError(\"The key is not intended for verification\")\n\n        public_bytes = base64.urlsafe_b64decode(public_jwk.x)\n        public_key = Ed25519PublicKey.from_public_bytes(public_bytes)\n        signature_base64 = self.signature.encode(\"utf-8\")  # pylint: disable=no-member\n        signature_decoded = base64.urlsafe_b64decode(signature_base64)\n\n        header_base64 = self.header.to_base64url()  # pylint: disable=no-member\n        payload_base64 = payload_to_base64url(self.payload)\n        full_message = header_base64 + b\".\" + payload_base64\n\n        try:\n            public_key.verify(signature_decoded, full_message)\n            return True\n        except InvalidSignature:\n            return False\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.JWSDict.verify_signature","title":"<code>verify_signature(public_jwk)</code>","text":"<p>Verify the integraty of JWS object.</p> <p>Parameters:</p> Name Type Description Default <code>public_jwk</code> <code>JWK</code> <p>The public key to use for verification</p> required <p>Returns:</p> Type Description <code>bool</code> <p>if the signature can be verified</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def verify_signature(self, public_jwk: JWK) -&gt; bool:\n    \"\"\"\n    Verify the integraty of JWS object.\n\n    Args:\n        public_jwk: The public key to use for verification\n\n    Returns:\n        if the signature can be verified\n    \"\"\"\n\n    if not public_jwk.key_ops == \"verify\":\n        raise ValueError(\"The key is not intended for verification\")\n\n    public_bytes = base64.urlsafe_b64decode(public_jwk.x)\n    public_key = Ed25519PublicKey.from_public_bytes(public_bytes)\n    signature_base64 = self.signature.encode(\"utf-8\")  # pylint: disable=no-member\n    signature_decoded = base64.urlsafe_b64decode(signature_base64)\n\n    header_base64 = self.header.to_base64url()  # pylint: disable=no-member\n    payload_base64 = payload_to_base64url(self.payload)\n    full_message = header_base64 + b\".\" + payload_base64\n\n    try:\n        public_key.verify(signature_decoded, full_message)\n        return True\n    except InvalidSignature:\n        return False\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.JWSHeader","title":"<code>JWSHeader</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The header of a JWS object</p> Source code in <code>src/sqooler/security.py</code> <pre><code>class JWSHeader(BaseModel):\n    \"\"\"\n    The header of a JWS object\n    \"\"\"\n\n    alg: str = Field(default=\"EdDSA\", description=\"The algorithm used for signing\")\n    kid: str = Field(description=\"The key id of the key used for signing\")\n    typ: str = Field(default=\"JWS\", description=\"The type of the signature\")\n    version: str = Field(\n        default=\"0.1\", description=\"The base64 encoded version of the signature\"\n    )\n\n    def to_base64url(self) -&gt; bytes:\n        \"\"\"\n        Convert the header to a base64url encoded string.\n\n        Returns:\n            bytes : The base64url encoded header\n        \"\"\"\n\n        # transform into a json string\n        header_json = self.model_dump_json()\n\n        # binary encode the json string\n        binary_string = header_json.encode()\n\n        # base64 encode the binary string\n        base64_encoded = base64.urlsafe_b64encode(binary_string)\n        return base64_encoded\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.JWSHeader.to_base64url","title":"<code>to_base64url()</code>","text":"<p>Convert the header to a base64url encoded string.</p> <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>The base64url encoded header</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def to_base64url(self) -&gt; bytes:\n    \"\"\"\n    Convert the header to a base64url encoded string.\n\n    Returns:\n        bytes : The base64url encoded header\n    \"\"\"\n\n    # transform into a json string\n    header_json = self.model_dump_json()\n\n    # binary encode the json string\n    binary_string = header_json.encode()\n\n    # base64 encode the binary string\n    base64_encoded = base64.urlsafe_b64encode(binary_string)\n    return base64_encoded\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.create_jwk_pair","title":"<code>create_jwk_pair(kid)</code>","text":"<p>Create a pair of JWKs designed for signing and verification.</p> <p>Parameters:</p> Name Type Description Default <code>kid</code> <p>The key id of the key</p> required <p>Returns:</p> Name Type Description <code>JWK</code> <code>tuple[JWK, JWK]</code> <p>The JWK object</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def create_jwk_pair(kid: str) -&gt; tuple[JWK, JWK]:\n    \"\"\"\n    Create a pair of JWKs designed for signing and verification.\n\n    Args:\n        kid : The key id of the key\n\n    Returns:\n        JWK : The JWK object\n    \"\"\"\n\n    # create a new key pair\n    private_key = Ed25519PrivateKey.generate()\n    public_key = private_key.public_key()\n\n    # transform the keys into base64url encoded strings\n    private_base64 = base64.urlsafe_b64encode(private_key.private_bytes_raw())\n    public_base64 = base64.urlsafe_b64encode(public_key.public_bytes_raw())\n\n    # create the JWK\n    private_jwk = JWK(key_ops=\"sign\", kid=kid, d=private_base64, x=public_base64)\n    public_jwk = JWK(key_ops=\"verify\", kid=kid, x=public_base64)\n    return private_jwk, public_jwk\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.create_key_pair","title":"<code>create_key_pair()</code>","text":"<p>Create a new key pair for signing and verification.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[Ed25519PrivateKey, Ed25519PublicKey]</code> <p>A tuple containing the public and private keys</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def create_key_pair() -&gt; tuple[Ed25519PrivateKey, Ed25519PublicKey]:\n    \"\"\"\n    Create a new key pair for signing and verification.\n\n    Returns:\n        tuple : A tuple containing the public and private keys\n    \"\"\"\n\n    # create a new key pair\n    private_key = Ed25519PrivateKey.generate()\n    public_key = private_key.public_key()\n\n    return private_key, public_key\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.datetime_handler","title":"<code>datetime_handler(in_var)</code>","text":"<p>Convert a datetime object to a string.</p> <p>Parameters:</p> Name Type Description Default <code>in_var</code> <p>The object to convert</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The string representation of the object</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def datetime_handler(in_var: Any) -&gt; str:\n    \"\"\"\n    Convert a datetime object to a string.\n\n    Args:\n        in_var : The object to convert\n\n    Returns:\n        str : The string representation of the object\n    \"\"\"\n    if isinstance(in_var, datetime.datetime):\n        return in_var.isoformat()\n    raise TypeError(\"Unknown type\")\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.jwk_from_config_str","title":"<code>jwk_from_config_str(jwk_base64_str)</code>","text":"<p>Create a JWK from a string that was stored in a config file.</p> <p>Parameters:</p> Name Type Description Default <code>jwk_base64_str</code> <p>The base64 encoded JWK</p> required <p>Returns:</p> Name Type Description <code>JWK</code> <code>JWK</code> <p>The JWK object</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def jwk_from_config_str(jwk_base64_str: str) -&gt; JWK:\n    \"\"\"\n    Create a JWK from a string that was stored in a config file.\n\n    Args:\n        jwk_base64_str : The base64 encoded JWK\n\n    Returns:\n        JWK : The JWK object\n    \"\"\"\n    jwk_base64 = jwk_base64_str.encode(\"utf-8\")\n    jwk_bytes = base64.urlsafe_b64decode(jwk_base64)\n\n    jwk_json_str = jwk_bytes.decode(\"utf-8\")\n    jwk_dict = json.loads(jwk_json_str)\n    jwk = JWK(**jwk_dict)\n    return jwk\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.payload_to_base64url","title":"<code>payload_to_base64url(payload)</code>","text":"<p>Convert an arbitrary payload to a base64url encoded string.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <p>The dictionary to encode</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>The base64url encoded header</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def payload_to_base64url(payload: dict) -&gt; bytes:\n    \"\"\"\n    Convert an arbitrary payload to a base64url encoded string.\n\n    Args:\n        payload : The dictionary to encode\n\n    Returns:\n        bytes : The base64url encoded header\n    \"\"\"\n\n    # transform into a json string\n    payload_string = json.dumps(payload, default=datetime_handler)\n\n    # binary encode the json string\n    binary_string = payload_string.encode()\n\n    # base64 encode the binary string\n    base64_encoded = base64.urlsafe_b64encode(binary_string)\n    return base64_encoded\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.public_from_private_jwk","title":"<code>public_from_private_jwk(private_jwk)</code>","text":"<p>Create a public JWK from a private JWK.</p> <p>Parameters:</p> Name Type Description Default <code>private_jwk</code> <p>The private JWK</p> required <p>Returns:</p> Name Type Description <code>JWK</code> <code>JWK</code> <p>The public JWK</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the private key is not intended for signing</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def public_from_private_jwk(private_jwk: JWK) -&gt; JWK:\n    \"\"\"\n    Create a public JWK from a private JWK.\n\n    Args:\n        private_jwk : The private JWK\n\n    Returns:\n        JWK : The public JWK\n\n    Raises:\n        ValueError : If the private key is not intended for signing\n    \"\"\"\n\n    # is the key intended for signing?\n    if not private_jwk.key_ops == \"sign\" or private_jwk.d is None:\n        raise ValueError(\n            \"The private key is not intended for signing. Might not be a private key.\"\n        )\n\n    public_jwk = JWK(\n        key_ops=\"verify\",\n        kid=private_jwk.kid,\n        x=private_jwk.x,\n    )\n    return public_jwk\n</code></pre>"},{"location":"api/security_api/#src.sqooler.security.sign_payload","title":"<code>sign_payload(payload, jwk)</code>","text":"<p>Convert a payload to a JWS object.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <p>The payload to convert</p> required <code>jwk</code> <code>JWK</code> <p>The private JWK to use for signing</p> required <p>Returns:</p> Name Type Description <code>JWSDict</code> <code>JWSDict</code> <p>The JWS object</p> Source code in <code>src/sqooler/security.py</code> <pre><code>def sign_payload(payload: dict, jwk: JWK) -&gt; JWSDict:\n    \"\"\"\n    Convert a payload to a JWS object.\n\n    Args:\n        payload : The payload to convert\n        jwk: The private JWK to use for signing\n\n    Returns:\n        JWSDict : The JWS object\n    \"\"\"\n\n    header = JWSHeader(kid=jwk.kid)\n    header_base64 = header.to_base64url()\n    payload_base64 = payload_to_base64url(payload)\n    full_message = header_base64 + b\".\" + payload_base64\n    # create the private key from the JWK\n    # make sure that the key is intended for signing and contains the private key\n    if not jwk.key_ops == \"sign\":\n        raise ValueError(\"The key is not intended for signing\")\n    if jwk.d is None:\n        raise ValueError(\"The private key is missing from the JWK\")\n\n    private_bytes = base64.urlsafe_b64decode(jwk.d)\n    private_key = Ed25519PrivateKey.from_private_bytes(private_bytes)\n\n    signature = private_key.sign(full_message)\n    signature_base64 = base64.urlsafe_b64encode(signature)\n    signature_str = signature_base64.decode(\"utf-8\")\n    return JWSDict(header=header, payload=payload, signature=signature_str)\n</code></pre>"},{"location":"api/spoolers_api/","title":"API documentation of spoolers","text":"<p>This module contains the code for the Spooler classes and its helpers. So it mainly meant to be deployed on the back-end side for people that would like to perform calculations and work through the job queue.</p> <p>The main class is the <code>Spooler</code> class. It is the class that is used for the simulators.  The <code>LabscriptSpooler</code> class is a specialized version of the <code>Spooler</code> class that allows us to execute  jobs in labscript directly.</p>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler","title":"<code>BaseSpooler</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for spoolers. They are the main logic of the back-end.</p> <p>Attributes:</p> Name Type Description <code>ins_schema_dict</code> <p>A dictionary the contains all the allowed instructions for this spooler.</p> <code>device_config</code> <p>A dictionary that some main config params for the experiment.</p> <code>n_wires</code> <p>maximum number of wires for the spooler</p> <code>n_max_shots</code> <p>the maximum number of shots for the spooler</p> <code>version</code> <p>the version of the backend</p> <code>cold_atom_type</code> <p>the type of cold atom that is used in the experiment</p> <code>n_max_experiments</code> <p>the maximum number of experiments that can be executed</p> <code>wire_order</code> <p>the order of the wires</p> <code>num_species</code> <p>the number of atomic species in the experiment</p> <code>sign</code> <p>sign the results of the job</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>class BaseSpooler(ABC):\n    \"\"\"\n    Abstract base class for spoolers. They are the main logic of the back-end.\n\n    Attributes:\n        ins_schema_dict : A dictionary the contains all the allowed instructions for this spooler.\n        device_config: A dictionary that some main config params for the experiment.\n        n_wires: maximum number of wires for the spooler\n        n_max_shots: the maximum number of shots for the spooler\n        version: the version of the backend\n        cold_atom_type: the type of cold atom that is used in the experiment\n        n_max_experiments: the maximum number of experiments that can be executed\n        wire_order: the order of the wires\n        num_species: the number of atomic species in the experiment\n        sign: sign the results of the job\n    \"\"\"\n\n    def __init__(\n        self,\n        ins_schema_dict: dict,\n        device_config: Type[BaseModel],\n        n_wires: int,\n        description: str = \"\",\n        n_max_shots: int = 1000,\n        version: str = \"0.0.1\",\n        cold_atom_type: ColdAtomStr = \"spin\",\n        n_max_experiments: int = 15,\n        wire_order: WireOrderStr = \"interleaved\",\n        num_species: int = 1,\n        sign: bool = False,\n    ):\n        \"\"\"\n        The constructor of the class.\n        \"\"\"\n        self.ins_schema_dict = ins_schema_dict\n        self.device_config = device_config\n        self.n_max_shots = n_max_shots\n        self.n_wires = n_wires\n        self.description = description\n        self.version = version\n        self.cold_atom_type = cold_atom_type\n        self.n_max_experiments = n_max_experiments\n        self.wire_order = wire_order\n        self.num_species = num_species\n        self._display_name: str = \"\"\n        self.sign = sign\n\n    def check_experiment(self, exper_dict: dict) -&gt; tuple[str, bool]:\n        \"\"\"\n        Check the validity of the experiment. It checks if the the instructions are valid\n        based on the device configuration of the spooler.\n\n        Args:\n            exper_dict: The dictionary that contains the logic and should\n                be verified.\n\n        Returns:\n            str: The error message\n            bool: Is the experiment ok ?\n        \"\"\"\n        try:\n            self.device_config(**exper_dict)\n            return \"\", True\n        except ValidationError as err:\n            return str(err), False\n\n    def get_configuration(self) -&gt; BackendConfigSchemaIn:\n        \"\"\"\n        Sends back the configuration dictionary of the spooler.\n\n        This creates the configuration of the Spooler. However, it does not contain\n        any information about the operational status. This is not really connected to\n        the machine but much rather to the queue etc. So items of the `BackendConfigSchemaIn`\n        like `operational` or `last_queue_check` are not set here at just the default values.\n        ``\n\n        Returns:\n            The configuration dictionary of the spooler.\n        \"\"\"\n        gate_list = []\n        for _, ins_obj in self.ins_schema_dict.items():\n            if \"is_gate\" in ins_obj.model_fields:\n                gate_list.append(ins_obj.config_dict())\n        backend_config_dict = {\n            \"description\": self.description,\n            \"version\": self.version,\n            \"cold_atom_type\": self.cold_atom_type,\n            \"gates\": gate_list,\n            \"max_experiments\": self.n_max_experiments,\n            \"max_shots\": self.n_max_shots,\n            \"simulator\": True,\n            \"supported_instructions\": list(self.ins_schema_dict.keys()),\n            \"num_wires\": self.n_wires,\n            \"wire_order\": self.wire_order,\n            \"num_species\": self.num_species,\n            \"display_name\": self.display_name,\n            \"sign\": self.sign,\n        }\n        return BackendConfigSchemaIn(**backend_config_dict)\n\n    def check_instructions(self, ins_list: list) -&gt; tuple[str, bool]:\n        \"\"\"\n        Check all the instruction to make sure that they are valid and part\n        of the allowed instructions.\n\n        Args:\n            ins_list: The list of instructions that should be checked.\n\n        Returns:\n            str: The error message\n            bool: Are the instructions ok ?\n        \"\"\"\n        err_code = \"\"\n        exp_ok = False\n        # first check that we actually have any instructions safed in the ins_schema_dict\n        if len(self.ins_schema_dict) == 0:\n            err_code = \"No instructions allowed. Add instructions to the spooler.\"\n            exp_ok = False\n            return err_code, exp_ok\n\n        for ins in ins_list:\n            try:\n                gate_instr = gate_dict_from_list(ins)\n                # see if the instruction is part of the allowed instructions\n                if gate_instr.name not in self.ins_schema_dict.keys():\n                    err_code = f\"Instruction {gate_instr.name} not allowed.\"\n                    exp_ok = False\n                    return err_code, exp_ok\n\n                # now verify that the parameters are ok\n                gate_dict = gate_instr.model_dump()\n                self.ins_schema_dict[gate_instr.name](**gate_dict)\n                exp_ok = True\n            except ValidationError as err:\n                err_code = \"Error in instruction \" + str(err)\n                exp_ok = False\n            if not exp_ok:\n                break\n        return err_code, exp_ok\n\n    def check_dimension(self, json_dict: dict) -&gt; tuple[str, bool]:\n        \"\"\"\n        Make sure that the Hilbert space dimension is not too large.\n\n        It can be implemented in the class that inherits, but it is not necessary.\n        So this is only a placeholder.\n\n        Args:\n            json_dict: the dictonary with the instructions\n\n        Returns:\n            str: the error message\n            bool: is the dimension ok ?\n        \"\"\"\n        # pylint: disable=W0613\n        return \"\", True\n\n    def check_json_dict(\n        self, json_dict: dict[str, dict]\n    ) -&gt; tuple[str, bool, dict[str, ExperimentalInputDict]]:\n        \"\"\"\n        Check if the json file has the appropiate syntax.\n\n        Args:\n            json_dict (dict): the dictonary that we will test.\n\n        Returns:\n            str: the error message\n            bool: is the expression having the appropiate syntax ?\n            dict: the cleaned dictionary with proper typing\n        \"\"\"\n        err_code = \"No instructions received.\"\n        exp_ok = False\n        clean_dict: dict[str, ExperimentalInputDict] = {}\n        for expr in json_dict:\n            err_code = \"Wrong experiment name or too many experiments\"\n            # test the name of the experiment\n            if not expr.startswith(\"experiment_\"):\n                err_code = \"Experiment name must start with experiment_\"\n                exp_ok = False\n                break\n            if not expr[11:].isdigit():\n                err_code = \"Experiment name must end with a number\"\n                exp_ok = False\n                break\n            if int(expr[11:]) &gt; self.n_max_experiments:\n                err_code = f\"Experiment number too high. Must be less than {self.n_max_experiments}\"\n                exp_ok = False\n                break\n            exp_ok = True\n\n            # test the structure of the experiment\n            err_code, exp_ok = self.check_experiment(json_dict[expr])\n            if not exp_ok:\n                break\n            # time to check the structure of the instructions\n            ins_list = json_dict[expr][\"instructions\"]\n            err_code, exp_ok = self.check_instructions(ins_list)\n            if not exp_ok:\n                break\n            clean_dict[expr] = self.get_exp_input_dict(json_dict[expr])\n        return err_code.replace(\"\\n\", \"..\"), exp_ok, clean_dict\n\n    def _prep_job(\n        self, json_dict: dict, job_id: str\n    ) -&gt; tuple[ResultDict, StatusMsgDict, dict]:\n        \"\"\"\n        Prepare the job for execution. It checks the json file and prepares the\n        result and status dictionaries.\n\n        Args:\n            json_dict: The dictionary with the instructions.\n            job_id: The id of the job.\n\n        Returns:\n            result_dict: The dictionary with the results of the job.\n            status_msg_dict: The status dictionary of the job.\n            clean_dict: The cleaned dictionary with the instructions.\n        \"\"\"\n        status_msg_dict = get_init_status()\n        status_msg_dict.job_id = job_id\n\n        result_dict = ResultDict(\n            display_name=self.display_name,\n            backend_version=self.version,\n            job_id=job_id,\n            status=\"INITIALIZING\",\n        )\n\n        result_dict.results = []  # this simply helps pylint to understand the code\n\n        # check that the json_dict is indeed well behaved\n        err_msg, json_is_fine, clean_dict = self.check_json_dict(json_dict)\n\n        if not json_is_fine:\n            status_msg_dict.detail += (\n                \"; Failed json sanity check. File will be deleted. Error message : \"\n                + err_msg\n            )\n            status_msg_dict.error_message += (\n                \"; Failed json sanity check. File will be deleted. Error message : \"\n                + err_msg\n            )\n            status_msg_dict.status = \"ERROR\"\n            logging.error(\n                \"Error in json compatibility test.\",\n                extra={\"error_message\": status_msg_dict.error_message},\n            )\n            return result_dict, status_msg_dict, clean_dict\n\n        # now we need to check the dimensionality of the experiment\n        dim_err_msg, dim_ok = self.check_dimension(json_dict)\n        if not dim_ok:\n            status_msg_dict.detail += (\n                \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message : \"\n                + dim_err_msg\n            )\n            status_msg_dict.error_message += (\n                \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message :  \"\n                + dim_err_msg\n            )\n            status_msg_dict.status = \"ERROR\"\n            logging.error(\n                \"Error in dimensionality test.\",\n                extra={\"error_message\": status_msg_dict.error_message},\n            )\n            return result_dict, status_msg_dict, clean_dict\n\n        return result_dict, status_msg_dict, clean_dict\n\n    @property\n    def display_name(self) -&gt; str:\n        \"\"\"\n        The name of the spooler.\n        \"\"\"\n        return self._display_name\n\n    @display_name.setter\n    def display_name(self, value: str) -&gt; None:\n        if isinstance(value, str):  # Check if the provided value is a string\n            self._display_name = value\n        else:\n            raise ValueError(\"display_name must be a string\")\n\n    def get_exp_input_dict(self, json_dict: dict) -&gt; ExperimentalInputDict:\n        \"\"\"\n        Transforms the dictionary into an ExperimentalInputDict object.\n\n        Args:\n            json_dict: The dictionary that should be transformed.\n\n        Returns:\n            A ExperimentalInputDict object.\n        \"\"\"\n        raw_ins_list = json_dict[\"instructions\"]\n        ins_list = [gate_dict_from_list(instr) for instr in raw_ins_list]\n        exp_info = ExperimentalInputDict(\n            instructions=ins_list,\n            shots=json_dict[\"shots\"],\n            wire_order=json_dict[\"wire_order\"],\n            num_wires=json_dict[\"num_wires\"],\n        )\n        exp_info = ExperimentalInputDict(\n            instructions=ins_list,\n            shots=json_dict[\"shots\"],\n            wire_order=json_dict[\"wire_order\"],\n            num_wires=json_dict[\"num_wires\"],\n            seed=json_dict.get(\"seed\", None),\n        )\n        return exp_info\n\n    def get_private_jwk(self) -&gt; JWK:\n        \"\"\"\n        Get the private JWK for the spooler.\n\n        Returns:\n            The private JWK for the spooler.\n\n        Raises:\n            ValueError: If the private JWK is not set.\n        \"\"\"\n        private_jwk_str = config(\"PRIVATE_JWK_STR\", default=None)\n        if private_jwk_str == \"\":\n            logging.error(\"PRIVATE_JWK_STR must not be empty.\")\n\n            raise ValueError(\"PRIVATE_JWK_STR must not be empty.\")\n\n        if private_jwk_str is None:\n            logging.error(\"PRIVATE_JWK_STR is not set and available.\")\n            raise ValueError(\"PRIVATE_JWK_STR is not set and available.\")\n        try:\n            return jwk_from_config_str(private_jwk_str)\n        except BinasciiError as bin_err:\n            logging.error(\"PRIVATE_JWK_STR is invalid.\")\n            raise ValueError(\"PRIVATE_JWK_STR is invalid.\") from bin_err\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.display_name","title":"<code>display_name: str</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the spooler.</p>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.__init__","title":"<code>__init__(ins_schema_dict, device_config, n_wires, description='', n_max_shots=1000, version='0.0.1', cold_atom_type='spin', n_max_experiments=15, wire_order='interleaved', num_species=1, sign=False)</code>","text":"<p>The constructor of the class.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def __init__(\n    self,\n    ins_schema_dict: dict,\n    device_config: Type[BaseModel],\n    n_wires: int,\n    description: str = \"\",\n    n_max_shots: int = 1000,\n    version: str = \"0.0.1\",\n    cold_atom_type: ColdAtomStr = \"spin\",\n    n_max_experiments: int = 15,\n    wire_order: WireOrderStr = \"interleaved\",\n    num_species: int = 1,\n    sign: bool = False,\n):\n    \"\"\"\n    The constructor of the class.\n    \"\"\"\n    self.ins_schema_dict = ins_schema_dict\n    self.device_config = device_config\n    self.n_max_shots = n_max_shots\n    self.n_wires = n_wires\n    self.description = description\n    self.version = version\n    self.cold_atom_type = cold_atom_type\n    self.n_max_experiments = n_max_experiments\n    self.wire_order = wire_order\n    self.num_species = num_species\n    self._display_name: str = \"\"\n    self.sign = sign\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.check_dimension","title":"<code>check_dimension(json_dict)</code>","text":"<p>Make sure that the Hilbert space dimension is not too large.</p> <p>It can be implemented in the class that inherits, but it is not necessary. So this is only a placeholder.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the dictonary with the instructions</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the error message</p> <code>bool</code> <code>bool</code> <p>is the dimension ok ?</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def check_dimension(self, json_dict: dict) -&gt; tuple[str, bool]:\n    \"\"\"\n    Make sure that the Hilbert space dimension is not too large.\n\n    It can be implemented in the class that inherits, but it is not necessary.\n    So this is only a placeholder.\n\n    Args:\n        json_dict: the dictonary with the instructions\n\n    Returns:\n        str: the error message\n        bool: is the dimension ok ?\n    \"\"\"\n    # pylint: disable=W0613\n    return \"\", True\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.check_experiment","title":"<code>check_experiment(exper_dict)</code>","text":"<p>Check the validity of the experiment. It checks if the the instructions are valid based on the device configuration of the spooler.</p> <p>Parameters:</p> Name Type Description Default <code>exper_dict</code> <code>dict</code> <p>The dictionary that contains the logic and should be verified.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The error message</p> <code>bool</code> <code>bool</code> <p>Is the experiment ok ?</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def check_experiment(self, exper_dict: dict) -&gt; tuple[str, bool]:\n    \"\"\"\n    Check the validity of the experiment. It checks if the the instructions are valid\n    based on the device configuration of the spooler.\n\n    Args:\n        exper_dict: The dictionary that contains the logic and should\n            be verified.\n\n    Returns:\n        str: The error message\n        bool: Is the experiment ok ?\n    \"\"\"\n    try:\n        self.device_config(**exper_dict)\n        return \"\", True\n    except ValidationError as err:\n        return str(err), False\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.check_instructions","title":"<code>check_instructions(ins_list)</code>","text":"<p>Check all the instruction to make sure that they are valid and part of the allowed instructions.</p> <p>Parameters:</p> Name Type Description Default <code>ins_list</code> <code>list</code> <p>The list of instructions that should be checked.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The error message</p> <code>bool</code> <code>bool</code> <p>Are the instructions ok ?</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def check_instructions(self, ins_list: list) -&gt; tuple[str, bool]:\n    \"\"\"\n    Check all the instruction to make sure that they are valid and part\n    of the allowed instructions.\n\n    Args:\n        ins_list: The list of instructions that should be checked.\n\n    Returns:\n        str: The error message\n        bool: Are the instructions ok ?\n    \"\"\"\n    err_code = \"\"\n    exp_ok = False\n    # first check that we actually have any instructions safed in the ins_schema_dict\n    if len(self.ins_schema_dict) == 0:\n        err_code = \"No instructions allowed. Add instructions to the spooler.\"\n        exp_ok = False\n        return err_code, exp_ok\n\n    for ins in ins_list:\n        try:\n            gate_instr = gate_dict_from_list(ins)\n            # see if the instruction is part of the allowed instructions\n            if gate_instr.name not in self.ins_schema_dict.keys():\n                err_code = f\"Instruction {gate_instr.name} not allowed.\"\n                exp_ok = False\n                return err_code, exp_ok\n\n            # now verify that the parameters are ok\n            gate_dict = gate_instr.model_dump()\n            self.ins_schema_dict[gate_instr.name](**gate_dict)\n            exp_ok = True\n        except ValidationError as err:\n            err_code = \"Error in instruction \" + str(err)\n            exp_ok = False\n        if not exp_ok:\n            break\n    return err_code, exp_ok\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.check_json_dict","title":"<code>check_json_dict(json_dict)</code>","text":"<p>Check if the json file has the appropiate syntax.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the dictonary that we will test.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the error message</p> <code>bool</code> <code>bool</code> <p>is the expression having the appropiate syntax ?</p> <code>dict</code> <code>dict[str, ExperimentalInputDict]</code> <p>the cleaned dictionary with proper typing</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def check_json_dict(\n    self, json_dict: dict[str, dict]\n) -&gt; tuple[str, bool, dict[str, ExperimentalInputDict]]:\n    \"\"\"\n    Check if the json file has the appropiate syntax.\n\n    Args:\n        json_dict (dict): the dictonary that we will test.\n\n    Returns:\n        str: the error message\n        bool: is the expression having the appropiate syntax ?\n        dict: the cleaned dictionary with proper typing\n    \"\"\"\n    err_code = \"No instructions received.\"\n    exp_ok = False\n    clean_dict: dict[str, ExperimentalInputDict] = {}\n    for expr in json_dict:\n        err_code = \"Wrong experiment name or too many experiments\"\n        # test the name of the experiment\n        if not expr.startswith(\"experiment_\"):\n            err_code = \"Experiment name must start with experiment_\"\n            exp_ok = False\n            break\n        if not expr[11:].isdigit():\n            err_code = \"Experiment name must end with a number\"\n            exp_ok = False\n            break\n        if int(expr[11:]) &gt; self.n_max_experiments:\n            err_code = f\"Experiment number too high. Must be less than {self.n_max_experiments}\"\n            exp_ok = False\n            break\n        exp_ok = True\n\n        # test the structure of the experiment\n        err_code, exp_ok = self.check_experiment(json_dict[expr])\n        if not exp_ok:\n            break\n        # time to check the structure of the instructions\n        ins_list = json_dict[expr][\"instructions\"]\n        err_code, exp_ok = self.check_instructions(ins_list)\n        if not exp_ok:\n            break\n        clean_dict[expr] = self.get_exp_input_dict(json_dict[expr])\n    return err_code.replace(\"\\n\", \"..\"), exp_ok, clean_dict\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.get_configuration","title":"<code>get_configuration()</code>","text":"<p>Sends back the configuration dictionary of the spooler.</p> <p>This creates the configuration of the Spooler. However, it does not contain any information about the operational status. This is not really connected to the machine but much rather to the queue etc. So items of the <code>BackendConfigSchemaIn</code> like <code>operational</code> or <code>last_queue_check</code> are not set here at just the default values. ``</p> <p>Returns:</p> Type Description <code>BackendConfigSchemaIn</code> <p>The configuration dictionary of the spooler.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def get_configuration(self) -&gt; BackendConfigSchemaIn:\n    \"\"\"\n    Sends back the configuration dictionary of the spooler.\n\n    This creates the configuration of the Spooler. However, it does not contain\n    any information about the operational status. This is not really connected to\n    the machine but much rather to the queue etc. So items of the `BackendConfigSchemaIn`\n    like `operational` or `last_queue_check` are not set here at just the default values.\n    ``\n\n    Returns:\n        The configuration dictionary of the spooler.\n    \"\"\"\n    gate_list = []\n    for _, ins_obj in self.ins_schema_dict.items():\n        if \"is_gate\" in ins_obj.model_fields:\n            gate_list.append(ins_obj.config_dict())\n    backend_config_dict = {\n        \"description\": self.description,\n        \"version\": self.version,\n        \"cold_atom_type\": self.cold_atom_type,\n        \"gates\": gate_list,\n        \"max_experiments\": self.n_max_experiments,\n        \"max_shots\": self.n_max_shots,\n        \"simulator\": True,\n        \"supported_instructions\": list(self.ins_schema_dict.keys()),\n        \"num_wires\": self.n_wires,\n        \"wire_order\": self.wire_order,\n        \"num_species\": self.num_species,\n        \"display_name\": self.display_name,\n        \"sign\": self.sign,\n    }\n    return BackendConfigSchemaIn(**backend_config_dict)\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.get_exp_input_dict","title":"<code>get_exp_input_dict(json_dict)</code>","text":"<p>Transforms the dictionary into an ExperimentalInputDict object.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>The dictionary that should be transformed.</p> required <p>Returns:</p> Type Description <code>ExperimentalInputDict</code> <p>A ExperimentalInputDict object.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def get_exp_input_dict(self, json_dict: dict) -&gt; ExperimentalInputDict:\n    \"\"\"\n    Transforms the dictionary into an ExperimentalInputDict object.\n\n    Args:\n        json_dict: The dictionary that should be transformed.\n\n    Returns:\n        A ExperimentalInputDict object.\n    \"\"\"\n    raw_ins_list = json_dict[\"instructions\"]\n    ins_list = [gate_dict_from_list(instr) for instr in raw_ins_list]\n    exp_info = ExperimentalInputDict(\n        instructions=ins_list,\n        shots=json_dict[\"shots\"],\n        wire_order=json_dict[\"wire_order\"],\n        num_wires=json_dict[\"num_wires\"],\n    )\n    exp_info = ExperimentalInputDict(\n        instructions=ins_list,\n        shots=json_dict[\"shots\"],\n        wire_order=json_dict[\"wire_order\"],\n        num_wires=json_dict[\"num_wires\"],\n        seed=json_dict.get(\"seed\", None),\n    )\n    return exp_info\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.BaseSpooler.get_private_jwk","title":"<code>get_private_jwk()</code>","text":"<p>Get the private JWK for the spooler.</p> <p>Returns:</p> Type Description <code>JWK</code> <p>The private JWK for the spooler.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the private JWK is not set.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def get_private_jwk(self) -&gt; JWK:\n    \"\"\"\n    Get the private JWK for the spooler.\n\n    Returns:\n        The private JWK for the spooler.\n\n    Raises:\n        ValueError: If the private JWK is not set.\n    \"\"\"\n    private_jwk_str = config(\"PRIVATE_JWK_STR\", default=None)\n    if private_jwk_str == \"\":\n        logging.error(\"PRIVATE_JWK_STR must not be empty.\")\n\n        raise ValueError(\"PRIVATE_JWK_STR must not be empty.\")\n\n    if private_jwk_str is None:\n        logging.error(\"PRIVATE_JWK_STR is not set and available.\")\n        raise ValueError(\"PRIVATE_JWK_STR is not set and available.\")\n    try:\n        return jwk_from_config_str(private_jwk_str)\n    except BinasciiError as bin_err:\n        logging.error(\"PRIVATE_JWK_STR is invalid.\")\n        raise ValueError(\"PRIVATE_JWK_STR is invalid.\") from bin_err\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.LabscriptSpooler","title":"<code>LabscriptSpooler</code>","text":"<p>               Bases: <code>BaseSpooler</code></p> <p>A specialized spooler class that allows us to execute jobs in labscript directly. The main changes are that we need to add the job in a different way and connect it to a  <code>runmanager.remoteClient</code>. It adds three new attributes to the <code>BaseSpooler</code> class.</p> <p>Attributes:</p> Name Type Description <code>remote_client</code> <p>The remote client that is used to connect to the labscript server.</p> <code>labscript_params</code> <p>The parameters that are used to generate the folder for the shots.</p> <code>run</code> <p>The run object that is used to execute the labscript file.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>class LabscriptSpooler(BaseSpooler):\n    \"\"\"\n    A specialized spooler class that allows us to execute jobs in labscript directly.\n    The main changes are that we need to add the job in a different way and connect it to a\n     `runmanager.remoteClient`. It adds three new attributes to the `BaseSpooler` class.\n\n    Attributes:\n        remote_client: The remote client that is used to connect to the labscript server.\n        labscript_params: The parameters that are used to generate the folder for the shots.\n        run: The run object that is used to execute the labscript file.\n    \"\"\"\n\n    def __init__(\n        self,\n        ins_schema_dict: dict,\n        device_config: Type[BaseModel],\n        n_wires: int,\n        remote_client: Any,  # it would be really nice to fix this type\n        labscript_params: LabscriptParams,\n        run: Any,  # it would be really nice to fix this type\n        description: str = \"\",\n        n_max_shots: int = 1000,\n        version: str = \"0.0.1\",\n        cold_atom_type: ColdAtomStr = \"spin\",\n        n_max_experiments: int = 15,\n        wire_order: WireOrderStr = \"interleaved\",\n        num_species: int = 1,\n        sign: bool = False,\n    ):\n        \"\"\"\n        The constructor of the class. The  arguments are the same as for the Spooler\n        class with two additions.\n\n\n        \"\"\"\n        super().__init__(\n            ins_schema_dict,\n            device_config,\n            n_wires,\n            description,\n            n_max_shots,\n            version,\n            cold_atom_type,\n            n_max_experiments,\n            wire_order,\n            num_species,\n            sign,\n        )\n        self.remote_client = remote_client\n        self.labscript_params = labscript_params\n        self.run = run\n\n    def add_job(\n        self, json_dict: dict[str, dict], job_id: str\n    ) -&gt; tuple[ResultDict, StatusMsgDict]:\n        \"\"\"\n        The function that translates the json with the instructions into some circuit\n        and executes it. It performs several checks for the job to see if it is properly\n        working. If things are fine the job gets added the list of things that should be\n        executed.\n\n        Args:\n            json_dict: The job dictonary of all the instructions.\n            job_id: the id of the the job we are treating.\n\n        Returns:\n            result_dict: The dictionary with the results of the job.\n            status_msg_dict: The status dictionary of the job.\n        \"\"\"\n        result_dict, status_msg_dict, clean_dict = self._prep_job(json_dict, job_id)\n\n        if status_msg_dict.status == \"ERROR\":\n            return result_dict, status_msg_dict\n\n        for exp_name, exp_info in clean_dict.items():\n            # prepare the shots folder\n            self.remote_client.reset_shot_output_folder()\n            self._modify_shot_output_folder(job_id + \"/\" + str(exp_name))\n\n            try:\n                result_dict.results.append(self.gen_circuit(exp_name, exp_info, job_id))\n            except FileNotFoundError as err:\n                error_message = str(err)\n                status_msg_dict.detail += \"; Failed to generate labscript file.\"\n                status_msg_dict.error_message += f\"; Failed to generate labscript \\\n                            file. Error: {error_message}\"\n                status_msg_dict.status = \"ERROR\"\n                return result_dict, status_msg_dict\n        status_msg_dict.detail += \"; Passed json sanity check; Compilation done. \\\n                    Shots sent to solver.\"\n        status_msg_dict.status = \"DONE\"\n        return result_dict, status_msg_dict\n\n    def _modify_shot_output_folder(self, new_dir: str) -&gt; str:\n        \"\"\"\n        I am not sure what this function does.\n\n        Args:\n            new_dir: The new directory under which we save the shots.\n\n        Returns:\n            The path to the new directory.\n        \"\"\"\n\n        # we should simplify this at some point\n        defaut_shot_folder = str(self.remote_client.get_shot_output_folder())\n\n        modified_shot_folder = (defaut_shot_folder.rsplit(\"\\\\\", 1)[0]) + \"/\" + new_dir\n        # suggested better emthod whcih works the same way on all platforms\n        # modified_shot_folder = os.path.join(\n        #    os.path.dirname(defaut_shot_folder), new_dir\n        # )\n        self.remote_client.set_shot_output_folder(modified_shot_folder)\n        return modified_shot_folder\n\n    def gen_circuit(\n        self, exp_name: str, json_dict: ExperimentalInputDict, job_id: str\n    ) -&gt; ExperimentDict:\n        \"\"\"\n        This is the main script that generates the labscript file.\n\n        Args:\n            exp_name: The name of the experiment\n            json_dict: The dictionary that contains the instructions for the circuit.\n            job_id: The user id of the user that is running the experiment.\n\n        Returns:\n            The path to the labscript file.\n        \"\"\"\n        # parameters for the function\n        exp_script_folder = self.labscript_params.exp_script_folder\n\n        # local files\n        header_path = f\"{exp_script_folder}/header.py\"\n        remote_experiments_path = f\"{exp_script_folder}/remote_experiments\"\n        # make sure that the folder exists\n        if not os.path.exists(remote_experiments_path):\n            raise FileNotFoundError(\n                f\"The path {remote_experiments_path} does not exist.\"\n            )\n\n        n_shots = json_dict.shots\n        ins_list = json_dict.instructions\n\n        globals_dict = {\n            \"job_id\": \"guest\",\n            \"shots\": 4,\n        }\n        globals_dict[\"shots\"] = list(range(n_shots))\n        globals_dict[\"job_id\"] = job_id\n\n        self.remote_client.set_globals(globals_dict)\n        script_name = f\"experiment_{globals_dict['job_id']}.py\"\n        exp_script = os.path.join(remote_experiments_path, script_name)\n        code = \"\"\n        # this is the top part of the script it allows us to import the\n        # typical functions that we require for each single sequence\n        # first have a look if the file exists\n        if not os.path.exists(header_path):\n            raise FileNotFoundError(f\"Header file not found at {header_path}\")\n\n        with open(header_path, \"r\", encoding=\"UTF-8\") as header_file:\n            code = header_file.read()\n\n        # add a line break to the code\n        code += \"\\n\"\n\n        with open(exp_script, \"w\", encoding=\"UTF-8\") as script_file:\n            script_file.write(code)\n\n        for inst in ins_list:\n            # we can directly use the function name as we have already verified\n            # that the function exists in the `add_job` function\n            code = f\"Experiment.{inst.name}({inst.wires}, {inst.params})\\n\"\n            # we should add proper error handling here\n            # pylint: disable=bare-except\n            try:\n                with open(exp_script, \"a\", encoding=\"UTF-8\") as script_file:\n                    script_file.write(code)\n            except:\n                logging.error(\"Something wrong. Does file path exists?\")\n\n        code = \"Experiment.final_action()\" + \"\\n\" + \"stop(Experiment.t+0.1)\"\n        # pylint: disable=bare-except\n        try:\n            with open(exp_script, \"a\", encoding=\"UTF-8\") as script_file:\n                script_file.write(code)\n        except:\n            logging.error(\"Something wrong. Does file path exists?\")\n        self.remote_client.set_labscript_file(\n            exp_script\n        )  # CAUTION !! This command only selects the file. It does not generate it!\n\n        # be careful. This is not a blocking command\n        self.remote_client.engage()\n\n        # now that we have engaged the calculation we need to wait for the\n        # calculation to be done\n\n        # we need to get the current shot output folder\n        current_shot_folder = self.remote_client.get_shot_output_folder()\n        # we need to get the list of files in the folder\n        hdf5_files = get_file_queue(current_shot_folder)\n\n        # we need to wait until we have the right number of files\n        while len(hdf5_files) &lt; n_shots:\n            sleep(self.labscript_params.t_wait)\n            hdf5_files = get_file_queue(current_shot_folder)\n\n        shots_array = []\n        # once the files are there we can read them\n        for file in hdf5_files:\n            this_run = self.run(current_shot_folder + \"/\" + file)\n            got_nat = False\n            n_tries = 0\n            # sometimes the file is not ready yet. We need to wait a bit\n            while not got_nat and n_tries &lt; 15:\n                # the exception is raised if the file is not ready yet\n                # it is broadly defined within labscript so we cannot do anything about\n                # it here.\n                # pylint: disable=W0718\n                try:\n                    # append the result to the array\n                    shots_array.append(this_run.get_results(\"/measure\", \"nat\"))\n                    got_nat = True\n                except Exception as exc:\n                    logging.exception(exc)\n                    sleep(self.labscript_params.t_wait)\n                    n_tries += 1\n        exp_sub_dict = create_memory_data(shots_array, exp_name, n_shots, ins_list)\n        return exp_sub_dict\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.LabscriptSpooler.__init__","title":"<code>__init__(ins_schema_dict, device_config, n_wires, remote_client, labscript_params, run, description='', n_max_shots=1000, version='0.0.1', cold_atom_type='spin', n_max_experiments=15, wire_order='interleaved', num_species=1, sign=False)</code>","text":"<p>The constructor of the class. The  arguments are the same as for the Spooler class with two additions.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def __init__(\n    self,\n    ins_schema_dict: dict,\n    device_config: Type[BaseModel],\n    n_wires: int,\n    remote_client: Any,  # it would be really nice to fix this type\n    labscript_params: LabscriptParams,\n    run: Any,  # it would be really nice to fix this type\n    description: str = \"\",\n    n_max_shots: int = 1000,\n    version: str = \"0.0.1\",\n    cold_atom_type: ColdAtomStr = \"spin\",\n    n_max_experiments: int = 15,\n    wire_order: WireOrderStr = \"interleaved\",\n    num_species: int = 1,\n    sign: bool = False,\n):\n    \"\"\"\n    The constructor of the class. The  arguments are the same as for the Spooler\n    class with two additions.\n\n\n    \"\"\"\n    super().__init__(\n        ins_schema_dict,\n        device_config,\n        n_wires,\n        description,\n        n_max_shots,\n        version,\n        cold_atom_type,\n        n_max_experiments,\n        wire_order,\n        num_species,\n        sign,\n    )\n    self.remote_client = remote_client\n    self.labscript_params = labscript_params\n    self.run = run\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.LabscriptSpooler.add_job","title":"<code>add_job(json_dict, job_id)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict[str, dict]</code> <p>The job dictonary of all the instructions.</p> required <code>job_id</code> <code>str</code> <p>the id of the the job we are treating.</p> required <p>Returns:</p> Name Type Description <code>result_dict</code> <code>ResultDict</code> <p>The dictionary with the results of the job.</p> <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>The status dictionary of the job.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def add_job(\n    self, json_dict: dict[str, dict], job_id: str\n) -&gt; tuple[ResultDict, StatusMsgDict]:\n    \"\"\"\n    The function that translates the json with the instructions into some circuit\n    and executes it. It performs several checks for the job to see if it is properly\n    working. If things are fine the job gets added the list of things that should be\n    executed.\n\n    Args:\n        json_dict: The job dictonary of all the instructions.\n        job_id: the id of the the job we are treating.\n\n    Returns:\n        result_dict: The dictionary with the results of the job.\n        status_msg_dict: The status dictionary of the job.\n    \"\"\"\n    result_dict, status_msg_dict, clean_dict = self._prep_job(json_dict, job_id)\n\n    if status_msg_dict.status == \"ERROR\":\n        return result_dict, status_msg_dict\n\n    for exp_name, exp_info in clean_dict.items():\n        # prepare the shots folder\n        self.remote_client.reset_shot_output_folder()\n        self._modify_shot_output_folder(job_id + \"/\" + str(exp_name))\n\n        try:\n            result_dict.results.append(self.gen_circuit(exp_name, exp_info, job_id))\n        except FileNotFoundError as err:\n            error_message = str(err)\n            status_msg_dict.detail += \"; Failed to generate labscript file.\"\n            status_msg_dict.error_message += f\"; Failed to generate labscript \\\n                        file. Error: {error_message}\"\n            status_msg_dict.status = \"ERROR\"\n            return result_dict, status_msg_dict\n    status_msg_dict.detail += \"; Passed json sanity check; Compilation done. \\\n                Shots sent to solver.\"\n    status_msg_dict.status = \"DONE\"\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.LabscriptSpooler.gen_circuit","title":"<code>gen_circuit(exp_name, json_dict, job_id)</code>","text":"<p>This is the main script that generates the labscript file.</p> <p>Parameters:</p> Name Type Description Default <code>exp_name</code> <code>str</code> <p>The name of the experiment</p> required <code>json_dict</code> <code>ExperimentalInputDict</code> <p>The dictionary that contains the instructions for the circuit.</p> required <code>job_id</code> <code>str</code> <p>The user id of the user that is running the experiment.</p> required <p>Returns:</p> Type Description <code>ExperimentDict</code> <p>The path to the labscript file.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def gen_circuit(\n    self, exp_name: str, json_dict: ExperimentalInputDict, job_id: str\n) -&gt; ExperimentDict:\n    \"\"\"\n    This is the main script that generates the labscript file.\n\n    Args:\n        exp_name: The name of the experiment\n        json_dict: The dictionary that contains the instructions for the circuit.\n        job_id: The user id of the user that is running the experiment.\n\n    Returns:\n        The path to the labscript file.\n    \"\"\"\n    # parameters for the function\n    exp_script_folder = self.labscript_params.exp_script_folder\n\n    # local files\n    header_path = f\"{exp_script_folder}/header.py\"\n    remote_experiments_path = f\"{exp_script_folder}/remote_experiments\"\n    # make sure that the folder exists\n    if not os.path.exists(remote_experiments_path):\n        raise FileNotFoundError(\n            f\"The path {remote_experiments_path} does not exist.\"\n        )\n\n    n_shots = json_dict.shots\n    ins_list = json_dict.instructions\n\n    globals_dict = {\n        \"job_id\": \"guest\",\n        \"shots\": 4,\n    }\n    globals_dict[\"shots\"] = list(range(n_shots))\n    globals_dict[\"job_id\"] = job_id\n\n    self.remote_client.set_globals(globals_dict)\n    script_name = f\"experiment_{globals_dict['job_id']}.py\"\n    exp_script = os.path.join(remote_experiments_path, script_name)\n    code = \"\"\n    # this is the top part of the script it allows us to import the\n    # typical functions that we require for each single sequence\n    # first have a look if the file exists\n    if not os.path.exists(header_path):\n        raise FileNotFoundError(f\"Header file not found at {header_path}\")\n\n    with open(header_path, \"r\", encoding=\"UTF-8\") as header_file:\n        code = header_file.read()\n\n    # add a line break to the code\n    code += \"\\n\"\n\n    with open(exp_script, \"w\", encoding=\"UTF-8\") as script_file:\n        script_file.write(code)\n\n    for inst in ins_list:\n        # we can directly use the function name as we have already verified\n        # that the function exists in the `add_job` function\n        code = f\"Experiment.{inst.name}({inst.wires}, {inst.params})\\n\"\n        # we should add proper error handling here\n        # pylint: disable=bare-except\n        try:\n            with open(exp_script, \"a\", encoding=\"UTF-8\") as script_file:\n                script_file.write(code)\n        except:\n            logging.error(\"Something wrong. Does file path exists?\")\n\n    code = \"Experiment.final_action()\" + \"\\n\" + \"stop(Experiment.t+0.1)\"\n    # pylint: disable=bare-except\n    try:\n        with open(exp_script, \"a\", encoding=\"UTF-8\") as script_file:\n            script_file.write(code)\n    except:\n        logging.error(\"Something wrong. Does file path exists?\")\n    self.remote_client.set_labscript_file(\n        exp_script\n    )  # CAUTION !! This command only selects the file. It does not generate it!\n\n    # be careful. This is not a blocking command\n    self.remote_client.engage()\n\n    # now that we have engaged the calculation we need to wait for the\n    # calculation to be done\n\n    # we need to get the current shot output folder\n    current_shot_folder = self.remote_client.get_shot_output_folder()\n    # we need to get the list of files in the folder\n    hdf5_files = get_file_queue(current_shot_folder)\n\n    # we need to wait until we have the right number of files\n    while len(hdf5_files) &lt; n_shots:\n        sleep(self.labscript_params.t_wait)\n        hdf5_files = get_file_queue(current_shot_folder)\n\n    shots_array = []\n    # once the files are there we can read them\n    for file in hdf5_files:\n        this_run = self.run(current_shot_folder + \"/\" + file)\n        got_nat = False\n        n_tries = 0\n        # sometimes the file is not ready yet. We need to wait a bit\n        while not got_nat and n_tries &lt; 15:\n            # the exception is raised if the file is not ready yet\n            # it is broadly defined within labscript so we cannot do anything about\n            # it here.\n            # pylint: disable=W0718\n            try:\n                # append the result to the array\n                shots_array.append(this_run.get_results(\"/measure\", \"nat\"))\n                got_nat = True\n            except Exception as exc:\n                logging.exception(exc)\n                sleep(self.labscript_params.t_wait)\n                n_tries += 1\n    exp_sub_dict = create_memory_data(shots_array, exp_name, n_shots, ins_list)\n    return exp_sub_dict\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.Spooler","title":"<code>Spooler</code>","text":"<p>               Bases: <code>BaseSpooler</code></p> <p>The class for the spooler as it can be used for simulators.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>class Spooler(BaseSpooler):\n    \"\"\"\n    The class for the spooler as it can be used for simulators.\n    \"\"\"\n\n    @property\n    def gen_circuit(self) -&gt; Callable[[str, ExperimentalInputDict], ExperimentDict]:\n        \"\"\"\n        The function that generates the circuit.\n        It can be basically anything that allows the execution of the circuit.\n\n        Returns:\n            The function that generates the circuit.\n\n        Raises:\n            ValueError: if the gen_circuit is not a callable function\n        \"\"\"\n        if not hasattr(self, \"_gen_circuit\"):\n            raise ValueError(\"gen_circuit must be set\")\n        return self._gen_circuit\n\n    @gen_circuit.setter\n    def gen_circuit(\n        self, value: Callable[[str, ExperimentalInputDict], ExperimentDict]\n    ) -&gt; None:\n        \"\"\"\n        The setter for the gen_circuit function. The first argument is the name of the\n        experiment and the second argument is the dictionary with the instructions.\n\n        Args:\n            value: The function that generates the circuit.\n        \"\"\"\n        if callable(value):  # Check if the provided value is a callable (function)\n            self._gen_circuit = value\n        else:\n            raise ValueError(\"gen_circuit must be a callable function\")\n\n    def add_job(\n        self, json_dict: dict[str, dict], job_id: str\n    ) -&gt; tuple[ResultDict, StatusMsgDict]:\n        \"\"\"\n        The function that translates the json with the instructions into some circuit and executes it.\n        It performs several checks for the job to see if it is properly working.\n        If things are fine the job gets added the list of things that should be executed.\n\n        Args:\n            json_dict: The job dictonary of all the instructions.\n            job_id: the id of the the job we are treating.\n\n        Returns:\n            result_dict: The dictionary with the results of the job.\n            status_msg_dict: The status dictionary of the job.\n        \"\"\"\n        result_dict, status_msg_dict, clean_dict = self._prep_job(json_dict, job_id)\n        if status_msg_dict.status == \"ERROR\":\n            return result_dict, status_msg_dict\n        # now we can generate the circuit for each experiment\n        for exp_name, exp_info in clean_dict.items():\n            try:\n                result_dict.results.append(self.gen_circuit(exp_name, exp_info))\n                logging.info(\"Experiment %s done.\", exp_name)\n            except ValueError as err:\n                status_msg_dict.detail += \"; \" + str(err)\n                status_msg_dict.error_message += \"; \" + str(err)\n                status_msg_dict.status = \"ERROR\"\n                logging.exception(\n                    \"Error in gen_circuit.\",\n                    extra={\"error_message\": status_msg_dict.error_message},\n                )\n                return result_dict, status_msg_dict\n        status_msg_dict.detail += \"; Passed json sanity check; Compilation done. \\\n                    Shots sent to solver.\"\n        status_msg_dict.status = \"DONE\"\n        return result_dict, status_msg_dict\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.Spooler.gen_circuit","title":"<code>gen_circuit: Callable[[str, ExperimentalInputDict], ExperimentDict]</code>  <code>property</code> <code>writable</code>","text":"<p>The function that generates the circuit. It can be basically anything that allows the execution of the circuit.</p> <p>Returns:</p> Type Description <code>Callable[[str, ExperimentalInputDict], ExperimentDict]</code> <p>The function that generates the circuit.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the gen_circuit is not a callable function</p>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.Spooler.add_job","title":"<code>add_job(json_dict, job_id)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict[str, dict]</code> <p>The job dictonary of all the instructions.</p> required <code>job_id</code> <code>str</code> <p>the id of the the job we are treating.</p> required <p>Returns:</p> Name Type Description <code>result_dict</code> <code>ResultDict</code> <p>The dictionary with the results of the job.</p> <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>The status dictionary of the job.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def add_job(\n    self, json_dict: dict[str, dict], job_id: str\n) -&gt; tuple[ResultDict, StatusMsgDict]:\n    \"\"\"\n    The function that translates the json with the instructions into some circuit and executes it.\n    It performs several checks for the job to see if it is properly working.\n    If things are fine the job gets added the list of things that should be executed.\n\n    Args:\n        json_dict: The job dictonary of all the instructions.\n        job_id: the id of the the job we are treating.\n\n    Returns:\n        result_dict: The dictionary with the results of the job.\n        status_msg_dict: The status dictionary of the job.\n    \"\"\"\n    result_dict, status_msg_dict, clean_dict = self._prep_job(json_dict, job_id)\n    if status_msg_dict.status == \"ERROR\":\n        return result_dict, status_msg_dict\n    # now we can generate the circuit for each experiment\n    for exp_name, exp_info in clean_dict.items():\n        try:\n            result_dict.results.append(self.gen_circuit(exp_name, exp_info))\n            logging.info(\"Experiment %s done.\", exp_name)\n        except ValueError as err:\n            status_msg_dict.detail += \"; \" + str(err)\n            status_msg_dict.error_message += \"; \" + str(err)\n            status_msg_dict.status = \"ERROR\"\n            logging.exception(\n                \"Error in gen_circuit.\",\n                extra={\"error_message\": status_msg_dict.error_message},\n            )\n            return result_dict, status_msg_dict\n    status_msg_dict.detail += \"; Passed json sanity check; Compilation done. \\\n                Shots sent to solver.\"\n    status_msg_dict.status = \"DONE\"\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.create_memory_data","title":"<code>create_memory_data(shots_array, exp_name, n_shots, instructions=None)</code>","text":"<p>The function to create memory key in results dictionary with proprer formatting.</p> <p>Parameters:</p> Name Type Description Default <code>shots_array</code> <code>list</code> <p>The array with the shots.</p> required <code>exp_name</code> <code>str</code> <p>The name of the experiment.</p> required <code>n_shots</code> <code>int</code> <p>The number of shots.</p> required <code>instructions</code> <code>Optional[list[GateDict]]</code> <p>The list of instructions that were executed</p> <code>None</code> <p>Returns:</p> Type Description <code>ExperimentDict</code> <p>The ExperimentDict object describing the results.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def create_memory_data(\n    shots_array: list,\n    exp_name: str,\n    n_shots: int,\n    instructions: Optional[list[GateDict]] = None,\n) -&gt; ExperimentDict:\n    \"\"\"\n    The function to create memory key in results dictionary\n    with proprer formatting.\n\n    Args:\n        shots_array: The array with the shots.\n        exp_name: The name of the experiment.\n        n_shots: The number of shots.\n        instructions: The list of instructions that were executed\n\n    Returns:\n        The ExperimentDict object describing the results.\n    \"\"\"\n    exp_sub_dict: dict = {\n        \"header\": {\"name\": \"experiment_0\", \"extra metadata\": \"text\"},\n        \"shots\": 3,\n        \"success\": True,\n        \"data\": {\"memory\": None},\n    }\n\n    exp_sub_dict[\"header\"][\"name\"] = exp_name\n    exp_sub_dict[\"shots\"] = n_shots\n    memory_list = [\n        str(shot).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n        for shot in shots_array\n    ]\n    exp_sub_dict[\"data\"][\"memory\"] = memory_list\n    if instructions is not None:\n        exp_sub_dict[\"data\"][\"instructions\"] = instructions\n    return ExperimentDict(**exp_sub_dict)\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.gate_dict_from_list","title":"<code>gate_dict_from_list(inst_list)</code>","text":"<p>Transforms a list into an appropiate dictionnary for instructions. The list is assumed to be in the format [name, wires, params].</p> <p>Parameters:</p> Name Type Description Default <code>inst_list</code> <code>list</code> <p>The list that should be transformed.</p> required <p>Returns:</p> Type Description <code>GateDict</code> <p>A GateDict object.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def gate_dict_from_list(inst_list: list) -&gt; GateDict:\n    \"\"\"\n    Transforms a list into an appropiate dictionnary for instructions. The list\n    is assumed to be in the format [name, wires, params].\n\n    Args:\n        inst_list: The list that should be transformed.\n\n    Returns:\n        A GateDict object.\n    \"\"\"\n    gate_draft = {\"name\": inst_list[0], \"wires\": inst_list[1], \"params\": inst_list[2]}\n    return GateDict(**gate_draft)\n</code></pre>"},{"location":"api/spoolers_api/#src.sqooler.spoolers.get_file_queue","title":"<code>get_file_queue(dir_path)</code>","text":"<p>A function that returns the list of files in the directory.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>str</code> <p>The path to the directory.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files in the directory. It excludes directories.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the path is not a directory.</p> Source code in <code>src/sqooler/spoolers.py</code> <pre><code>def get_file_queue(dir_path: str) -&gt; list[str]:\n    \"\"\"\n    A function that returns the list of files in the directory.\n\n    Args:\n        dir_path: The path to the directory.\n\n    Returns:\n        A list of files in the directory. It excludes directories.\n\n    Raises:\n        ValueError: If the path is not a directory.\n    \"\"\"\n\n    # make sure that the path is an existing directory\n    if not os.path.isdir(dir_path):\n        raise ValueError(f\"The path {dir_path} is not a directory.\")\n    files = [\n        file\n        for file in os.listdir(dir_path)\n        if os.path.isfile(os.path.join(dir_path, file))\n    ]\n    return files\n</code></pre>"},{"location":"api/utils/","title":"API documentation of utils","text":"<p>This module contains some functions that are especially helpful for deployment of the  sqooler package.</p>"},{"location":"api/utils/#src.sqooler.utils.get_dummy_config","title":"<code>get_dummy_config(sign=True)</code>","text":"<p>Generate the dummy config of the fermion type.</p> <p>Parameters:</p> Name Type Description Default <code>sign</code> <code>bool</code> <p>Whether to sign the files.</p> <code>True</code> <p>Returns:     The backend name and the backend config input.</p> Source code in <code>src/sqooler/utils.py</code> <pre><code>def get_dummy_config(sign: bool = True) -&gt; Tuple[str, BackendConfigSchemaIn]:\n    \"\"\"\n    Generate the dummy config of the fermion type.\n\n    Args:\n        sign: Whether to sign the files.\n    Returns:\n        The backend name and the backend config input.\n    \"\"\"\n\n    dummy_id = uuid.uuid4().hex[:5]\n    backend_name = f\"dummy{dummy_id}\"\n\n    dummy_dict: dict = {}\n    dummy_dict[\"gates\"] = []\n    dummy_dict[\"display_name\"] = backend_name\n    dummy_dict[\"num_wires\"] = 3\n    dummy_dict[\"version\"] = \"0.0.1\"\n    dummy_dict[\"description\"] = \"This is a dummy backend.\"\n    dummy_dict[\"cold_atom_type\"] = \"fermion\"\n    dummy_dict[\"max_experiments\"] = 1\n    dummy_dict[\"max_shots\"] = 1\n    dummy_dict[\"simulator\"] = True\n    dummy_dict[\"supported_instructions\"] = []\n    dummy_dict[\"wire_order\"] = \"interleaved\"\n    dummy_dict[\"num_species\"] = 1\n    dummy_dict[\"sign\"] = sign\n\n    backend_info = BackendConfigSchemaIn(**dummy_dict)\n    return backend_name, backend_info\n</code></pre>"},{"location":"api/utils/#src.sqooler.utils.main","title":"<code>main(storage_provider, backends, num_iter=0)</code>","text":"<p>Function for processing jobs continuously.</p> <p>Parameters:</p> Name Type Description Default <code>storage_provider</code> <code>StorageProvider</code> <p>The storage provider that should be used.</p> required <code>backends</code> <code>dict[str, Spooler]</code> <p>A dictionary of all the backends that should be updated.</p> required <code>num_iter</code> <code>int</code> <p>The number of iterations that should be done. If 0, then the loop will run forever.</p> <code>0</code> Source code in <code>src/sqooler/utils.py</code> <pre><code>def main(\n    storage_provider: StorageProvider,\n    backends: dict[str, Spooler],\n    num_iter: int = 0,\n) -&gt; None:\n    \"\"\"\n    Function for processing jobs continuously.\n\n    Args:\n        storage_provider: The storage provider that should be used.\n        backends: A dictionary of all the backends that should be updated.\n        num_iter: The number of iterations that should be done. If 0, then the loop\n            will run forever.\n    \"\"\"\n    backends_list = list(backends.keys())\n    # set the appropiate display names for all the back-ends\n    for requested_backend, spooler in backends.items():\n        # the content\n        spooler.display_name = requested_backend\n\n    counter = 0\n    # loop which is looking for the jobs\n\n    t_wait_main = config(\"T_WAIT_MAIN\", cast=float, default=0.2)\n    while num_iter == 0 or counter &lt; num_iter:\n        time.sleep(t_wait_main)\n        # the following a fancy for loop of going through all the back-ends in the list\n        requested_backend = backends_list[0]\n        backends_list.append(backends_list.pop(0))\n\n        spooler = backends[requested_backend]\n        # let us first see if jobs are waiting\n        logging.info(\"Looking for jobs in %s\", requested_backend)\n        if spooler.sign:\n            private_jwk = spooler.get_private_jwk()\n        else:\n            private_jwk = None\n        try:\n            job_dict = storage_provider.get_next_job_in_queue(\n                requested_backend, private_jwk\n            )\n        except ValidationError as val_err:\n            logging.error(\n                \"Validation error in job queue.\",\n                extra={\"error_message\": val_err.errors()},\n            )\n            job_dict = NextJobSchema(job_id=\"None\", job_json_path=\"None\")\n\n        if job_dict.job_json_path == \"None\":\n            counter += 1\n            continue\n        logging.debug(\"Got a job in %s\", requested_backend)\n        job_json_dict = storage_provider.get_job(\n            storage_path=job_dict.job_json_path, job_id=job_dict.job_id\n        )\n\n        result_dict = get_init_results()\n        # Fix this pylint issue whenever you have time, but be careful !\n        # pylint: disable=W0703\n        try:\n            result_dict, status_msg_dict = backends[requested_backend].add_job(\n                job_json_dict, job_dict.job_id\n            )\n\n        except Exception:\n            # test if the status_msg_dict is already initialized\n            if not status_msg_dict:\n                status_msg_dict = get_init_status()\n                status_msg_dict.job_id = job_dict.job_id\n            # Remove sensitive info like filepaths\n            tb_list = traceback.format_exc().splitlines()\n            for i, dummy in enumerate(tb_list):\n                tb_list[i] = re.sub(\n                    r'File \".*[\\\\/]([^\\\\/]+.py)\"', r'File \"\\1\"', tb_list[i]\n                )  # Regex for repalcing absolute filepath with only filename.\n                # Basically search for slashes and replace with the first group or\n                # bracketed expression which is obviously the filename.\n            slimmed_tb = \" \".join(tb_list)\n            # Update status dict\n            status_msg_dict.status = \"ERROR\"\n            status_msg_dict.detail += \"; \" + slimmed_tb\n            status_msg_dict.error_message += \"; \" + slimmed_tb\n            logging.exception(\"Error in add_job for %s .\", requested_backend)\n\n        logging.debug(\"Updating in database.\")\n        storage_provider.update_in_database(\n            result_dict,\n            status_msg_dict,\n            job_dict.job_id,\n            requested_backend,\n            private_jwk,\n        )\n\n        counter += 1\n</code></pre>"},{"location":"api/utils/#src.sqooler.utils.run_json_circuit","title":"<code>run_json_circuit(json_dict, job_id, spooler)</code>","text":"<p>A support function that executes the job. Should be only used for testing.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the job dict that will be treated</p> required <code>job_id</code> <code>str</code> <p>the number of the job</p> required <code>spooler</code> <code>Spooler</code> <p>the spooler that will be used</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the results dict</p> Source code in <code>src/sqooler/utils.py</code> <pre><code>def run_json_circuit(json_dict: dict, job_id: str, spooler: Spooler) -&gt; dict:\n    \"\"\"\n    A support function that executes the job. Should be only used for testing.\n\n    Args:\n        json_dict: the job dict that will be treated\n        job_id: the number of the job\n        spooler: the spooler that will be used\n\n    Returns:\n        the results dict\n    \"\"\"\n\n    result_dict, status_msg_dict = spooler.add_job(json_dict, job_id)\n    if not status_msg_dict.status == \"DONE\":\n        logging.error(status_msg_dict.error_message)\n        raise AssertionError(\"Job failed\")\n    return result_dict.model_dump()\n</code></pre>"},{"location":"api/utils/#src.sqooler.utils.update_backends","title":"<code>update_backends(storage_provider, backends)</code>","text":"<p>Update the backends on the storage. Uploads it as a new one if it fails.</p> <p>Parameters:</p> Name Type Description Default <code>storage_provider</code> <code>StorageProvider</code> <p>The storage provider that should be used.</p> required <code>backends</code> <code>dict[str, Spooler]</code> <p>A dictionary of all the backends that should be updated.</p> required Source code in <code>src/sqooler/utils.py</code> <pre><code>def update_backends(\n    storage_provider: StorageProvider, backends: dict[str, Spooler]\n) -&gt; None:\n    \"\"\"\n    Update the backends on the storage. Uploads it as a new one if it fails.\n\n    Args:\n        storage_provider: The storage provider that should be used.\n        backends: A dictionary of all the backends that should be updated.\n    \"\"\"\n    for requested_backend, spooler in backends.items():\n        # the content\n        backend_config_dict = spooler.get_configuration()\n        # set the display name\n        backend_config_dict.display_name = requested_backend\n        # upload the public key if the backend has one and is designed to sign\n        if spooler.sign:\n            private_jwk = spooler.get_private_jwk()\n        else:\n            private_jwk = None\n\n        # upload the content through the storage provider\n        try:\n            storage_provider.update_config(\n                backend_config_dict, requested_backend, private_jwk=private_jwk\n            )\n\n            logging.info(\n                \"Updated the config for %s .\",\n                requested_backend,\n            )\n        except FileNotFoundError:\n            # this should become a log\n            logging.warning(\n                \"Failed to update the configuration for %s . Uploading it as a new one.\",\n                requested_backend,\n            )\n            storage_provider.upload_config(\n                backend_config_dict, requested_backend, private_jwk\n            )\n\n        if spooler.sign:\n            # this line is IMHO needless but somehow mypy thinks that it could be a\n            # None (no idea how this could happen)\n            private_jwk = spooler.get_private_jwk()\n\n            # this has to happen after the config was uploaded to be sure\n            # the we know the appropiate kid\n            public_jwk = public_from_private_jwk(private_jwk)\n            storage_provider.upload_public_key(public_jwk, requested_backend)\n</code></pre>"},{"location":"storage_providers/dropbox/","title":"API documentation of the Dropbox provider","text":"<p>The module that contains all the necessary logic for communication with the Dropbox providers.</p>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore","title":"<code>DropboxCore</code>","text":"<p>               Bases: <code>StorageCore</code></p> <p>Base class that creates the most important functions for the local storage provider.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>class DropboxCore(StorageCore):\n    \"\"\"\n    Base class that creates the most important functions for the local storage provider.\n    \"\"\"\n\n    def __init__(\n        self, login_dict: DropboxLoginInformation, name: str, is_active: bool = True\n    ) -&gt; None:\n        \"\"\"\n        Args:\n            login_dict: The dictionary that contains the login information\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n        \"\"\"\n\n        super().__init__(name, is_active)\n        self.app_key = login_dict.app_key\n        self.app_secret = login_dict.app_secret\n        self.refresh_token = login_dict.refresh_token\n\n    def upload_string(\n        self, content_string: str, storage_path: str, job_id: str\n    ) -&gt; None:\n        \"\"\"\n        Upload the content_string as a json file to the dropbox\n\n        Args:\n            content_string: the content of the file that should be uploaded\n            storage_path: the path where the file should be stored, but excluding the file name\n            job_id: the name of the file without the .json extension\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            dbx.users_get_current_account()\n            dbx.files_upload(\n                content_string.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n            )\n\n    @validate_active\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the content_dict as a json file to the dropbox\n\n        Args:\n            content_dict: the content of the file that should be uploaded\n            storage_path: the path where the file should be stored, but excluding the file name\n            job_id: the name of the file without the .json extension\n        \"\"\"\n\n        # let us first see if the file already exists by using the get function\n        # it would be much nicer to use an exists function, but we do not have that\n        try:\n            self.get(storage_path, job_id)\n            raise FileExistsError(\n                f\"The file {job_id} in {storage_path} already exists and should not be overwritten.\"\n            )\n        except FileNotFoundError:\n            # create the appropriate string for the dropbox API\n            dump_str = json.dumps(content_dict, default=datetime_handler)\n            self.upload_string(dump_str, storage_path, job_id)\n\n    @validate_active\n    def get(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the dropbox\n\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n            full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n            try:\n                _, res = dbx.files_download(path=full_path)\n            except ApiError as err:\n                raise FileNotFoundError(\n                    f\"Could not find file under {full_path}\"\n                ) from err\n            data = res.content\n        return json.loads(data.decode(\"utf-8\"))\n\n    @validate_active\n    def update(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # create the appropriate string for the dropbox API\n        dump_str = json.dumps(content_dict, default=datetime_handler)\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            dbx.users_get_current_account()\n\n            try:\n                dbx.files_get_metadata(full_path)\n            except ApiError as err:\n                raise FileNotFoundError(\n                    f\"Could not update file under {full_path}\"\n                ) from err\n\n            dbx.files_upload(\n                dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n            )\n\n    @validate_active\n    def move(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n        # strip trailing and leading slashes from the paths\n        start_path = start_path.strip(\"/\")\n        final_path = final_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            dbx.users_get_current_account()\n\n            full_start_path = \"/\" + start_path + \"/\" + job_id + \".json\"\n            full_final_path = \"/\" + final_path + \"/\" + job_id + \".json\"\n            dbx.files_move_v2(full_start_path, full_final_path)\n\n    @validate_active\n    def delete(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Remove the file from the dropbox\n\n        Args:\n            storage_path: the path where the file should be stored, but excluding the file name\n            job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n\n            full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n            try:\n                _ = dbx.files_delete_v2(path=full_path)\n            except ApiError as err:\n                raise FileNotFoundError(\n                    f\"Could not delete file under {full_path}\"\n                ) from err\n\n    def delete_folder(self, folder_path: str) -&gt; None:\n        \"\"\"\n        Remove the folder from the dropbox. Attention this will remove all the files in the folder.\n        It is not a standard function for storage providers, but allows us to better clean up the\n        tests.\n\n        Args:\n            folder_path: the path where the file should be stored, but excluding the file name\n\n        Returns:\n            None\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        folder_path = folder_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n\n            # to remove a folder there must be no trailing slash\n            full_path = \"/\" + folder_path\n            _ = dbx.files_delete_v2(path=full_path)\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore.__init__","title":"<code>__init__(login_dict, name, is_active=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>DropboxLoginInformation</code> <p>The dictionary that contains the login information</p> required <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def __init__(\n    self, login_dict: DropboxLoginInformation, name: str, is_active: bool = True\n) -&gt; None:\n    \"\"\"\n    Args:\n        login_dict: The dictionary that contains the login information\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n    \"\"\"\n\n    super().__init__(name, is_active)\n    self.app_key = login_dict.app_key\n    self.app_secret = login_dict.app_secret\n    self.refresh_token = login_dict.refresh_token\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore.delete","title":"<code>delete(storage_path, job_id)</code>","text":"<p>Remove the file from the dropbox</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file. Is a json file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>@validate_active\ndef delete(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Remove the file from the dropbox\n\n    Args:\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n        try:\n            _ = dbx.files_delete_v2(path=full_path)\n        except ApiError as err:\n            raise FileNotFoundError(\n                f\"Could not delete file under {full_path}\"\n            ) from err\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore.delete_folder","title":"<code>delete_folder(folder_path)</code>","text":"<p>Remove the folder from the dropbox. Attention this will remove all the files in the folder. It is not a standard function for storage providers, but allows us to better clean up the tests.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def delete_folder(self, folder_path: str) -&gt; None:\n    \"\"\"\n    Remove the folder from the dropbox. Attention this will remove all the files in the folder.\n    It is not a standard function for storage providers, but allows us to better clean up the\n    tests.\n\n    Args:\n        folder_path: the path where the file should be stored, but excluding the file name\n\n    Returns:\n        None\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    folder_path = folder_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n\n        # to remove a folder there must be no trailing slash\n        full_path = \"/\" + folder_path\n        _ = dbx.files_delete_v2(path=full_path)\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore.get","title":"<code>get(storage_path, job_id)</code>","text":"<p>Get the file content from the dropbox</p> <p>storage_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>@validate_active\ndef get(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the dropbox\n\n    storage_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n        try:\n            _, res = dbx.files_download(path=full_path)\n        except ApiError as err:\n            raise FileNotFoundError(\n                f\"Could not find file under {full_path}\"\n            ) from err\n        data = res.content\n    return json.loads(data.decode(\"utf-8\"))\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore.move","title":"<code>move(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>@validate_active\ndef move(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n    # strip trailing and leading slashes from the paths\n    start_path = start_path.strip(\"/\")\n    final_path = final_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        dbx.users_get_current_account()\n\n        full_start_path = \"/\" + start_path + \"/\" + job_id + \".json\"\n        full_final_path = \"/\" + final_path + \"/\" + job_id + \".json\"\n        dbx.files_move_v2(full_start_path, full_final_path)\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore.update","title":"<code>update(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>@validate_active\ndef update(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # create the appropriate string for the dropbox API\n    dump_str = json.dumps(content_dict, default=datetime_handler)\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        dbx.users_get_current_account()\n\n        try:\n            dbx.files_get_metadata(full_path)\n        except ApiError as err:\n            raise FileNotFoundError(\n                f\"Could not update file under {full_path}\"\n            ) from err\n\n        dbx.files_upload(\n            dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n        )\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the content_dict as a json file to the dropbox</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>Mapping</code> <p>the content of the file that should be uploaded</p> required <code>storage_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file without the .json extension</p> required Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>@validate_active\ndef upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the content_dict as a json file to the dropbox\n\n    Args:\n        content_dict: the content of the file that should be uploaded\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file without the .json extension\n    \"\"\"\n\n    # let us first see if the file already exists by using the get function\n    # it would be much nicer to use an exists function, but we do not have that\n    try:\n        self.get(storage_path, job_id)\n        raise FileExistsError(\n            f\"The file {job_id} in {storage_path} already exists and should not be overwritten.\"\n        )\n    except FileNotFoundError:\n        # create the appropriate string for the dropbox API\n        dump_str = json.dumps(content_dict, default=datetime_handler)\n        self.upload_string(dump_str, storage_path, job_id)\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxCore.upload_string","title":"<code>upload_string(content_string, storage_path, job_id)</code>","text":"<p>Upload the content_string as a json file to the dropbox</p> <p>Parameters:</p> Name Type Description Default <code>content_string</code> <code>str</code> <p>the content of the file that should be uploaded</p> required <code>storage_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file without the .json extension</p> required Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def upload_string(\n    self, content_string: str, storage_path: str, job_id: str\n) -&gt; None:\n    \"\"\"\n    Upload the content_string as a json file to the dropbox\n\n    Args:\n        content_string: the content of the file that should be uploaded\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file without the .json extension\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        dbx.users_get_current_account()\n        dbx.files_upload(\n            content_string.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n        )\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProvider","title":"<code>DropboxProvider</code>","text":"<p>               Bases: <code>DropboxProviderExtended</code></p> <p>The class that implements the dropbox storage provider.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>class DropboxProvider(DropboxProviderExtended):\n    \"\"\"\n    The class that implements the dropbox storage provider.\n    \"\"\"\n\n    def __init__(self, login_dict: DropboxLoginInformation) -&gt; None:\n        \"\"\"\n        Args:\n            login_dict: The dictionary that contains the login information\n        \"\"\"\n\n        super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>DropboxLoginInformation</code> <p>The dictionary that contains the login information</p> required Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def __init__(self, login_dict: DropboxLoginInformation) -&gt; None:\n    \"\"\"\n    Args:\n        login_dict: The dictionary that contains the login information\n    \"\"\"\n\n    super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended","title":"<code>DropboxProviderExtended</code>","text":"<p>               Bases: <code>StorageProvider</code>, <code>DropboxCore</code></p> <p>The class that implements the dropbox storage provider.</p> <p>Attributes:</p> Name Type Description <code>configs_path</code> <code>PathStr</code> <p>The path to the folder where the configurations are stored</p> <code>queue_path</code> <code>PathStr</code> <p>The path to the folder where the jobs are stored</p> <code>running_path</code> <code>PathStr</code> <p>The path to the folder where the running jobs are stored</p> <code>finished_path</code> <code>PathStr</code> <p>The path to the folder where the finished jobs are stored</p> <code>deleted_path</code> <code>PathStr</code> <p>The path to the folder where the deleted jobs are stored</p> <code>status_path</code> <code>PathStr</code> <p>The path to the folder where the status is stored</p> <code>results_path</code> <code>PathStr</code> <p>The path to the folder where the results are stored</p> <code>pks_path</code> <code>PathStr</code> <p>The path to the folder where the public keys are stored</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>class DropboxProviderExtended(StorageProvider, DropboxCore):\n    \"\"\"\n    The class that implements the dropbox storage provider.\n\n    Attributes:\n        configs_path: The path to the folder where the configurations are stored\n        queue_path: The path to the folder where the jobs are stored\n        running_path: The path to the folder where the running jobs are stored\n        finished_path: The path to the folder where the finished jobs are stored\n        deleted_path: The path to the folder where the deleted jobs are stored\n        status_path: The path to the folder where the status is stored\n        results_path: The path to the folder where the results are stored\n        pks_path: The path to the folder where the public keys are stored\n\n    \"\"\"\n\n    configs_path: PathStr = \"Backend_files/Config\"\n    queue_path: PathStr = \"Backend_files/Queued_Jobs\"\n    running_path: PathStr = \"Backend_files/Running_Jobs\"\n    finished_path: PathStr = \"Backend_files/Finished_Jobs\"\n    deleted_path: PathStr = \"Backend_files/Deleted_Jobs\"\n    status_path: PathStr = \"Backend_files/Status\"\n    results_path: PathStr = \"Backend_files/Result\"\n    pks_path: PathStr = \"Backend_files/public_keys\"\n\n    def get_internal_job_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the internal job id from the job_id.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The internal job id\n        \"\"\"\n        return f\"job-{job_id}\"\n\n    def get_configs_path(self, display_name: Optional[DisplayNameStr] = None) -&gt; str:\n        \"\"\"\n        Get the path to the configs.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The path to the configs.\n        \"\"\"\n        # here we really need to have the display_name\n        if display_name is None:\n            raise ValueError(\"The display_name must be set.\")\n        return f\"{self.configs_path}/{display_name}\"\n\n    def get_attribute_path(\n        self,\n        attribute_name: str,\n        display_name: Optional[DisplayNameStr] = None,\n        job_id: Optional[str] = None,\n    ) -&gt; str:\n        \"\"\"\n        Get the path to the results of the device.\n\n        Args:\n            display_name: The name of the backend\n            attribute_name: The name of the attribute\n            job_id: The job_id of the job\n\n        Returns:\n            The path to the results of the device.\n        \"\"\"\n\n        match attribute_name:\n            case \"running\":\n                path = self.running_path\n            case \"queue\":\n                path = f\"/{self.queue_path}/{display_name}/\"\n            case _:\n                raise ValueError(f\"The attribute name {attribute_name} is not valid.\")\n        return path\n\n    def get_config_id(self, display_name: DisplayNameStr) -&gt; str:\n        \"\"\"\n        Get the name of the config json file.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The name of the config json file.\n        \"\"\"\n        return \"config\"\n\n    def update_config(\n        self,\n        config_dict: BackendConfigSchemaIn,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        The function that updates the spooler configuration to the storage.\n\n        All the configurations are stored in the Backend_files/Config folder.\n        For each backend there is a separate folder in which the configuration is stored as a json file.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            display_name : The name of the backend\n            private_jwk: The private JWK to sign the configuration with\n\n        Returns:\n            None\n        \"\"\"\n\n        config_dict = self._verify_config(config_dict, display_name)\n        # check that the file exists\n        config_path = self.get_configs_path(display_name)\n        old_config_jws = self.get(config_path, \"config\")\n\n        upload_dict = self._format_update_config(\n            old_config_jws, config_dict, private_jwk\n        )\n\n        self.update(upload_dict, config_path, \"config\")\n\n    def _delete_config(self, display_name: DisplayNameStr) -&gt; bool:\n        \"\"\"\n        Delete a config from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n\n        Raises:\n            FileNotFoundError: If the status does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        config_path = f\"{self.configs_path}/{display_name}\"\n\n        self.delete(storage_path=config_path, job_id=\"config\")\n        self.delete_folder(config_path)\n        return True\n\n    def upload_public_key(self, public_jwk: JWK, display_name: DisplayNameStr) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler public JWK to the storage.\n\n        Args:\n            public_jwk: The JWK that contains the public key\n            display_name : The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # first make sure that the public key is intended for verification\n        if not public_jwk.key_ops == \"verify\":\n            raise ValueError(\"The key is not intended for verification\")\n\n        # make sure that the key does not contain a private key\n        if public_jwk.d is not None:\n            raise ValueError(\"The key contains a private key\")\n\n        # make sure that the key has the correct kid\n        config_dict = self.get_config(display_name)\n        if public_jwk.kid != config_dict.kid:\n            raise ValueError(\"The key does not have the correct kid.\")\n\n        self.upload_string(public_jwk.model_dump_json(), self.pks_path, config_dict.kid)\n\n    def get_public_key(self, display_name: DisplayNameStr) -&gt; JWK:\n        \"\"\"\n        The function that gets the spooler public JWK for the device.\n\n        Args:\n            display_name : The name of the backend\n\n        Returns:\n            JWk : The public JWK object\n        \"\"\"\n\n        # now get the appropiate kid\n        config_dict = self.get_config(display_name)\n        if config_dict.kid is None:\n            raise ValueError(\"The kid is not set in the backend configuration.\")\n\n        public_jwk_dict = self.get(storage_path=self.pks_path, job_id=config_dict.kid)\n        return JWK(**public_jwk_dict)\n\n    def _delete_public_key(self, kid: str) -&gt; bool:\n        \"\"\"\n        Delete a public key from the storage. This is only intended for test purposes.\n\n        Args:\n            kid: The key id of the public key\n\n        Raises:\n            FileNotFoundError: If the status does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        self.delete(storage_path=self.pks_path, job_id=kid)\n        return True\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict,\n        status_msg_dict: StatusMsgDict,\n        job_id: str,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the dropbox.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            display_name: the name of the backend\n            private_jwk: the private JWK to sign the result with\n\n        Returns:\n            None\n        \"\"\"\n        # this should become part of the json file instead of its name in the future\n        extracted_username = job_id.split(\"-\")[2]\n\n        status_json_dir = self.get_device_status_path(display_name, extracted_username)\n\n        status_json_name = \"status-\" + job_id\n\n        job_json_name = \"job-\" + job_id\n        job_json_start_dir = self.running_path\n\n        if status_msg_dict.status == \"DONE\":\n            self.upload_result(\n                result_dict,\n                display_name,\n                job_id,\n                private_jwk,\n            )\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = (\n                f\"/{self.finished_path}/{display_name}/{extracted_username}/\"\n            )\n\n            self.move(job_json_start_dir, job_finished_json_dir, job_json_name)\n\n        elif status_msg_dict.status == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            self.move(job_json_start_dir, self.deleted_path, job_json_name)\n\n        try:\n            self.update(status_msg_dict.model_dump(), status_json_dir, status_json_name)\n        except FileNotFoundError:\n            logging.warning(\n                \"The status file was missing for %s with job_id %s was missing.\",\n                display_name,\n                job_id,\n            )\n            self.upload_status(display_name, username=extracted_username, job_id=job_id)\n            self.update(status_msg_dict.model_dump(), status_json_dir, status_json_name)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of files. Typically we are looking for the queued jobs of a backend here.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n        # strip trailing and leading slashes from the paths\n        storage_path = storage_path.strip(\"/\")\n\n        storage_path = \"/\" + storage_path.strip(\"/\") + \"/\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        names: list[str] = []\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n            # We should really handle these exceptions cleaner, but this seems a bit\n            # complicated right now\n            # pylint: disable=W0703\n            try:\n                response = dbx.files_list_folder(path=storage_path)\n                file_list = response.entries\n                file_list = [item.name for item in file_list]\n                json_files = [item for item in file_list if item.endswith(\".json\")]\n\n                # Get the backend names\n                names = [file_name.split(\".\")[0] for file_name in json_files]\n\n            except ApiError:\n                print(f\"Could not obtain job queue for {storage_path}\")\n            except Exception as err:\n                print(err)\n        return names\n\n    @validate_active\n    def get_backends(self) -&gt; list[str]:\n        \"\"\"\n        Get a list of all the backends that the provider offers.\n        \"\"\"\n\n        # strip possible trailing and leading slashes from the path\n        config_path = self.configs_path.strip(\"/\")\n\n        # and now add them nicely\n        full_config_path = f\"/{config_path}/\"\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n\n            folders_results = dbx.files_list_folder(path=full_config_path)\n            entries = folders_results.entries\n            backend_names = []\n            for entry in entries:\n                backend_names.append(entry.name)\n        return backend_names\n\n    def get_config(self, display_name: DisplayNameStr) -&gt; BackendConfigSchemaIn:\n        \"\"\"\n        The function that downloads the spooler configuration to the storage.\n\n        Args:\n            display_name : The name of the backend\n\n        Raises:\n            FileNotFoundError: If the backend does not exist\n\n        Returns:\n            The configuration of the backend in complete form.\n        \"\"\"\n        backend_json_path = f\"{self.configs_path}/{display_name}\"\n        backend_config_dict = self.get(storage_path=backend_json_path, job_id=\"config\")\n        typed_config = self._adapt_get_config(backend_config_dict)\n        return typed_config\n\n    def create_job_id(self, display_name: DisplayNameStr, username: str) -&gt; str:\n        \"\"\"\n        Create a job id for the job.\n\n        Args:\n            display_name: The name of the backend\n            username: The username of the user that is uploading the job\n\n        Returns:\n            The job id\n        \"\"\"\n        job_id = (\n            (datetime.datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\"))\n            + \"-\"\n            + display_name\n            + \"-\"\n            + username\n            + \"-\"\n            + (uuid.uuid4().hex)[:5]\n        )\n        return job_id\n\n    def get_device_status_path(\n        self, display_name: DisplayNameStr, username: str\n    ) -&gt; str:\n        \"\"\"\n        Get the path to the status of the device.\n\n        Args:\n            display_name: The name of the backend\n            username: The username of the user that is uploading the job\n\n        Returns:\n            The path to the status of the device.\n        \"\"\"\n        return f\"/{self.status_path}/{display_name}/{username}/\"\n\n    def get_device_results_path(self, display_name: DisplayNameStr, job_id: str) -&gt; str:\n        \"\"\"\n        Get the path to the results of the device.\n\n        Args:\n            display_name: The name of the backend\n            job_id: The job_id of the job\n\n        Returns:\n            The path to the results of the device.\"\"\"\n\n        extracted_username = job_id.split(\"-\")[2]\n        result_json_dir = f\"/{self.results_path}/{display_name}/{extracted_username}/\"\n        return result_json_dir\n\n    def get_status_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the name of the status json file.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The name of the status json file.\n        \"\"\"\n        return \"status-\" + job_id\n\n    def get_result_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the name of the result json file.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The name of the result json file.\n        \"\"\"\n        return \"result-\" + job_id\n\n    def _delete_status(\n        self, display_name: DisplayNameStr, username: str, job_id: str\n    ) -&gt; bool:\n        \"\"\"\n        Delete a status from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Raises:\n            FileNotFoundError: If the status does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n\n        status_json_dir = self.get_device_status_path(display_name, username)\n\n        status_json_name = self.get_status_id(job_id)\n\n        self.delete(storage_path=status_json_dir, job_id=status_json_name)\n        self.delete_folder(status_json_dir)\n        return True\n\n    def _delete_result(self, display_name: DisplayNameStr, job_id: str) -&gt; bool:\n        \"\"\"\n        Delete a result from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Raises:\n            FileNotFoundError: If the result does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        result_device_dir = self.get_device_results_path(display_name, job_id)\n        self.delete_folder(result_device_dir)\n        return True\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.create_job_id","title":"<code>create_job_id(display_name, username)</code>","text":"<p>Create a job id for the job.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job id</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def create_job_id(self, display_name: DisplayNameStr, username: str) -&gt; str:\n    \"\"\"\n    Create a job id for the job.\n\n    Args:\n        display_name: The name of the backend\n        username: The username of the user that is uploading the job\n\n    Returns:\n        The job id\n    \"\"\"\n    job_id = (\n        (datetime.datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\"))\n        + \"-\"\n        + display_name\n        + \"-\"\n        + username\n        + \"-\"\n        + (uuid.uuid4().hex)[:5]\n    )\n    return job_id\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_attribute_path","title":"<code>get_attribute_path(attribute_name, display_name=None, job_id=None)</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <code>attribute_name</code> <code>str</code> <p>The name of the attribute</p> required <code>job_id</code> <code>Optional[str]</code> <p>The job_id of the job</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_attribute_path(\n    self,\n    attribute_name: str,\n    display_name: Optional[DisplayNameStr] = None,\n    job_id: Optional[str] = None,\n) -&gt; str:\n    \"\"\"\n    Get the path to the results of the device.\n\n    Args:\n        display_name: The name of the backend\n        attribute_name: The name of the attribute\n        job_id: The job_id of the job\n\n    Returns:\n        The path to the results of the device.\n    \"\"\"\n\n    match attribute_name:\n        case \"running\":\n            path = self.running_path\n        case \"queue\":\n            path = f\"/{self.queue_path}/{display_name}/\"\n        case _:\n            raise ValueError(f\"The attribute name {attribute_name} is not valid.\")\n    return path\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_backends","title":"<code>get_backends()</code>","text":"<p>Get a list of all the backends that the provider offers.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>@validate_active\ndef get_backends(self) -&gt; list[str]:\n    \"\"\"\n    Get a list of all the backends that the provider offers.\n    \"\"\"\n\n    # strip possible trailing and leading slashes from the path\n    config_path = self.configs_path.strip(\"/\")\n\n    # and now add them nicely\n    full_config_path = f\"/{config_path}/\"\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n\n        folders_results = dbx.files_list_folder(path=full_config_path)\n        entries = folders_results.entries\n        backend_names = []\n        for entry in entries:\n            backend_names.append(entry.name)\n    return backend_names\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_config","title":"<code>get_config(display_name)</code>","text":"<p>The function that downloads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p> <p>Returns:</p> Type Description <code>BackendConfigSchemaIn</code> <p>The configuration of the backend in complete form.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_config(self, display_name: DisplayNameStr) -&gt; BackendConfigSchemaIn:\n    \"\"\"\n    The function that downloads the spooler configuration to the storage.\n\n    Args:\n        display_name : The name of the backend\n\n    Raises:\n        FileNotFoundError: If the backend does not exist\n\n    Returns:\n        The configuration of the backend in complete form.\n    \"\"\"\n    backend_json_path = f\"{self.configs_path}/{display_name}\"\n    backend_config_dict = self.get(storage_path=backend_json_path, job_id=\"config\")\n    typed_config = self._adapt_get_config(backend_config_dict)\n    return typed_config\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_config_id","title":"<code>get_config_id(display_name)</code>","text":"<p>Get the name of the config json file.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the config json file.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_config_id(self, display_name: DisplayNameStr) -&gt; str:\n    \"\"\"\n    Get the name of the config json file.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The name of the config json file.\n    \"\"\"\n    return \"config\"\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_configs_path","title":"<code>get_configs_path(display_name=None)</code>","text":"<p>Get the path to the configs.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the configs.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_configs_path(self, display_name: Optional[DisplayNameStr] = None) -&gt; str:\n    \"\"\"\n    Get the path to the configs.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The path to the configs.\n    \"\"\"\n    # here we really need to have the display_name\n    if display_name is None:\n        raise ValueError(\"The display_name must be set.\")\n    return f\"{self.configs_path}/{display_name}\"\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_device_results_path","title":"<code>get_device_results_path(display_name, job_id)</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_device_results_path(self, display_name: DisplayNameStr, job_id: str) -&gt; str:\n    \"\"\"\n    Get the path to the results of the device.\n\n    Args:\n        display_name: The name of the backend\n        job_id: The job_id of the job\n\n    Returns:\n        The path to the results of the device.\"\"\"\n\n    extracted_username = job_id.split(\"-\")[2]\n    result_json_dir = f\"/{self.results_path}/{display_name}/{extracted_username}/\"\n    return result_json_dir\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_device_status_path","title":"<code>get_device_status_path(display_name, username)</code>","text":"<p>Get the path to the status of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the status of the device.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_device_status_path(\n    self, display_name: DisplayNameStr, username: str\n) -&gt; str:\n    \"\"\"\n    Get the path to the status of the device.\n\n    Args:\n        display_name: The name of the backend\n        username: The username of the user that is uploading the job\n\n    Returns:\n        The path to the status of the device.\n    \"\"\"\n    return f\"/{self.status_path}/{display_name}/{username}/\"\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of files. Typically we are looking for the queued jobs of a backend here.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of files. Typically we are looking for the queued jobs of a backend here.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n\n    # strip trailing and leading slashes from the paths\n    storage_path = storage_path.strip(\"/\")\n\n    storage_path = \"/\" + storage_path.strip(\"/\") + \"/\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    names: list[str] = []\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n        # We should really handle these exceptions cleaner, but this seems a bit\n        # complicated right now\n        # pylint: disable=W0703\n        try:\n            response = dbx.files_list_folder(path=storage_path)\n            file_list = response.entries\n            file_list = [item.name for item in file_list]\n            json_files = [item for item in file_list if item.endswith(\".json\")]\n\n            # Get the backend names\n            names = [file_name.split(\".\")[0] for file_name in json_files]\n\n        except ApiError:\n            print(f\"Could not obtain job queue for {storage_path}\")\n        except Exception as err:\n            print(err)\n    return names\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_internal_job_id","title":"<code>get_internal_job_id(job_id)</code>","text":"<p>Get the internal job id from the job_id.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The internal job id</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_internal_job_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the internal job id from the job_id.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The internal job id\n    \"\"\"\n    return f\"job-{job_id}\"\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_public_key","title":"<code>get_public_key(display_name)</code>","text":"<p>The function that gets the spooler public JWK for the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Name Type Description <code>JWk</code> <code>JWK</code> <p>The public JWK object</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_public_key(self, display_name: DisplayNameStr) -&gt; JWK:\n    \"\"\"\n    The function that gets the spooler public JWK for the device.\n\n    Args:\n        display_name : The name of the backend\n\n    Returns:\n        JWk : The public JWK object\n    \"\"\"\n\n    # now get the appropiate kid\n    config_dict = self.get_config(display_name)\n    if config_dict.kid is None:\n        raise ValueError(\"The kid is not set in the backend configuration.\")\n\n    public_jwk_dict = self.get(storage_path=self.pks_path, job_id=config_dict.kid)\n    return JWK(**public_jwk_dict)\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_result_id","title":"<code>get_result_id(job_id)</code>","text":"<p>Get the name of the result json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the result json file.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_result_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the name of the result json file.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The name of the result json file.\n    \"\"\"\n    return \"result-\" + job_id\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.get_status_id","title":"<code>get_status_id(job_id)</code>","text":"<p>Get the name of the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the status json file.</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def get_status_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the name of the status json file.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The name of the status json file.\n    \"\"\"\n    return \"status-\" + job_id\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.update_config","title":"<code>update_config(config_dict, display_name, private_jwk=None)</code>","text":"<p>The function that updates the spooler configuration to the storage.</p> <p>All the configurations are stored in the Backend_files/Config folder. For each backend there is a separate folder in which the configuration is stored as a json file.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private JWK to sign the configuration with</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def update_config(\n    self,\n    config_dict: BackendConfigSchemaIn,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    The function that updates the spooler configuration to the storage.\n\n    All the configurations are stored in the Backend_files/Config folder.\n    For each backend there is a separate folder in which the configuration is stored as a json file.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        display_name : The name of the backend\n        private_jwk: The private JWK to sign the configuration with\n\n    Returns:\n        None\n    \"\"\"\n\n    config_dict = self._verify_config(config_dict, display_name)\n    # check that the file exists\n    config_path = self.get_configs_path(display_name)\n    old_config_jws = self.get(config_path, \"config\")\n\n    upload_dict = self._format_update_config(\n        old_config_jws, config_dict, private_jwk\n    )\n\n    self.update(upload_dict, config_path, \"config\")\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, display_name, private_jwk=None)</code>","text":"<p>Upload the status and result to the dropbox.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>display_name</code> <code>DisplayNameStr</code> <p>the name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>the private JWK to sign the result with</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict,\n    status_msg_dict: StatusMsgDict,\n    job_id: str,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the dropbox.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        display_name: the name of the backend\n        private_jwk: the private JWK to sign the result with\n\n    Returns:\n        None\n    \"\"\"\n    # this should become part of the json file instead of its name in the future\n    extracted_username = job_id.split(\"-\")[2]\n\n    status_json_dir = self.get_device_status_path(display_name, extracted_username)\n\n    status_json_name = \"status-\" + job_id\n\n    job_json_name = \"job-\" + job_id\n    job_json_start_dir = self.running_path\n\n    if status_msg_dict.status == \"DONE\":\n        self.upload_result(\n            result_dict,\n            display_name,\n            job_id,\n            private_jwk,\n        )\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = (\n            f\"/{self.finished_path}/{display_name}/{extracted_username}/\"\n        )\n\n        self.move(job_json_start_dir, job_finished_json_dir, job_json_name)\n\n    elif status_msg_dict.status == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        self.move(job_json_start_dir, self.deleted_path, job_json_name)\n\n    try:\n        self.update(status_msg_dict.model_dump(), status_json_dir, status_json_name)\n    except FileNotFoundError:\n        logging.warning(\n            \"The status file was missing for %s with job_id %s was missing.\",\n            display_name,\n            job_id,\n        )\n        self.upload_status(display_name, username=extracted_username, job_id=job_id)\n        self.update(status_msg_dict.model_dump(), status_json_dir, status_json_name)\n</code></pre>"},{"location":"storage_providers/dropbox/#src.sqooler.storage_providers.dropbox.DropboxProviderExtended.upload_public_key","title":"<code>upload_public_key(public_jwk, display_name)</code>","text":"<p>The function that uploads the spooler public JWK to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>public_jwk</code> <code>JWK</code> <p>The JWK that contains the public key</p> required <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/dropbox.py</code> <pre><code>def upload_public_key(self, public_jwk: JWK, display_name: DisplayNameStr) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler public JWK to the storage.\n\n    Args:\n        public_jwk: The JWK that contains the public key\n        display_name : The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # first make sure that the public key is intended for verification\n    if not public_jwk.key_ops == \"verify\":\n        raise ValueError(\"The key is not intended for verification\")\n\n    # make sure that the key does not contain a private key\n    if public_jwk.d is not None:\n        raise ValueError(\"The key contains a private key\")\n\n    # make sure that the key has the correct kid\n    config_dict = self.get_config(display_name)\n    if public_jwk.kid != config_dict.kid:\n        raise ValueError(\"The key does not have the correct kid.\")\n\n    self.upload_string(public_jwk.model_dump_json(), self.pks_path, config_dict.kid)\n</code></pre>"},{"location":"storage_providers/local/","title":"API documentation of the local storage provider","text":"<p>The module that contains all the necessary logic for communication with the local storage providers.</p>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalCore","title":"<code>LocalCore</code>","text":"<p>               Bases: <code>StorageCore</code></p> <p>Base class that creates the most important functions for the local storage provider.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>class LocalCore(StorageCore):\n    \"\"\"\n    Base class that creates the most important functions for the local storage provider.\n    \"\"\"\n\n    def __init__(\n        self, login_dict: LocalLoginInformation, name: str, is_active: bool = True\n    ) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n\n        Args:\n            login_dict: The login dict that contains the neccessary\n                        information to connect to the local storage\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n\n        Raises:\n            ValidationError: If the login_dict is not valid\n        \"\"\"\n        super().__init__(name, is_active)\n        self.base_path = login_dict.base_path\n\n    @validate_active\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n\n        Args:\n            content_dict: The dictionary containing the content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # json folder\n        folder_path = self.base_path + \"/\" + storage_path\n        if not os.path.exists(folder_path):\n            os.makedirs(folder_path)\n\n        # create the full path\n        file_name = job_id + \".json\"\n        full_json_path = os.path.join(folder_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n        # test if the file already exists and raise a warning if it does\n        if os.path.exists(secure_path):\n            raise FileExistsError(\n                f\"The file {secure_path} already exists and should not be overwritten.\"\n            )\n\n        with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n            json.dump(content_dict, json_file, default=datetime_handler)\n\n    @validate_active\n    def get(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        file_name = job_id + \".json\"\n        full_json_path = os.path.join(self.base_path, storage_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n\n        # does the file already exist ?\n        if not os.path.exists(secure_path):\n            raise FileNotFoundError(\n                f\"The file {secure_path} does not exist and cannot be loaded.\"\n            )\n        with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n            loaded_data_dict = json.load(json_file)\n        return loaded_data_dict\n\n    @validate_active\n    def update(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n\n        Raises:\n            FileNotFoundError: If the file is not found\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # json folder\n        file_name = job_id + \".json\"\n        full_json_path = os.path.join(self.base_path, storage_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n\n        # does the file already exist ?\n        if not os.path.exists(secure_path):\n            raise FileNotFoundError(\n                f\"The file {secure_path} does not exist and cannot be updated.\"\n            )\n        with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n            json.dump(content_dict, json_file, default=datetime_handler)\n\n    @validate_active\n    def move(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from `start_path` to `final_path`\n        \"\"\"\n        start_path = start_path.strip(\"/\")\n\n        source_file = self.base_path + \"/\" + start_path + \"/\" + job_id + \".json\"\n\n        final_path = self.base_path + \"/\" + final_path + \"/\"\n        if not os.path.exists(final_path):\n            os.makedirs(final_path)\n\n        # Move the file\n        shutil.move(source_file, final_path)\n\n    @validate_active\n    def delete(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Delete the file from the storage\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n            job_id: the name of the file\n\n        Raises:\n            FileNotFoundError: If the file is not found\n\n        Returns:\n            None\n        \"\"\"\n        storage_path = storage_path.strip(\"/\")\n        source_file = self.base_path + \"/\" + storage_path + \"/\" + job_id + \".json\"\n        os.remove(source_file)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalCore.__init__","title":"<code>__init__(login_dict, name, is_active=True)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> <p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>LocalLoginInformation</code> <p>The login dict that contains the neccessary         information to connect to the local storage</p> required <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the login_dict is not valid</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def __init__(\n    self, login_dict: LocalLoginInformation, name: str, is_active: bool = True\n) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n\n    Args:\n        login_dict: The login dict that contains the neccessary\n                    information to connect to the local storage\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n\n    Raises:\n        ValidationError: If the login_dict is not valid\n    \"\"\"\n    super().__init__(name, is_active)\n    self.base_path = login_dict.base_path\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalCore.delete","title":"<code>delete(storage_path, job_id)</code>","text":"<p>Delete the file from the storage</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file is currently stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>@validate_active\ndef delete(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Delete the file from the storage\n\n    Args:\n        storage_path: the path where the file is currently stored, but excluding the file name\n        job_id: the name of the file\n\n    Raises:\n        FileNotFoundError: If the file is not found\n\n    Returns:\n        None\n    \"\"\"\n    storage_path = storage_path.strip(\"/\")\n    source_file = self.base_path + \"/\" + storage_path + \"/\" + job_id + \".json\"\n    os.remove(source_file)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalCore.get","title":"<code>get(storage_path, job_id)</code>","text":"<p>Get the file content from the storage</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>@validate_active\ndef get(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    file_name = job_id + \".json\"\n    full_json_path = os.path.join(self.base_path, storage_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n\n    # does the file already exist ?\n    if not os.path.exists(secure_path):\n        raise FileNotFoundError(\n            f\"The file {secure_path} does not exist and cannot be loaded.\"\n        )\n    with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n        loaded_data_dict = json.load(json_file)\n    return loaded_data_dict\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalCore.move","title":"<code>move(start_path, final_path, job_id)</code>","text":"<p>Move the file from <code>start_path</code> to <code>final_path</code></p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>@validate_active\ndef move(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from `start_path` to `final_path`\n    \"\"\"\n    start_path = start_path.strip(\"/\")\n\n    source_file = self.base_path + \"/\" + start_path + \"/\" + job_id + \".json\"\n\n    final_path = self.base_path + \"/\" + final_path + \"/\"\n    if not os.path.exists(final_path):\n        os.makedirs(final_path)\n\n    # Move the file\n    shutil.move(source_file, final_path)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalCore.update","title":"<code>update(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>@validate_active\ndef update(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n\n    Raises:\n        FileNotFoundError: If the file is not found\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # json folder\n    file_name = job_id + \".json\"\n    full_json_path = os.path.join(self.base_path, storage_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n\n    # does the file already exist ?\n    if not os.path.exists(secure_path):\n        raise FileNotFoundError(\n            f\"The file {secure_path} does not exist and cannot be updated.\"\n        )\n    with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n        json.dump(content_dict, json_file, default=datetime_handler)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalCore.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the file to the storage</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>Mapping</code> <p>The dictionary containing the content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>@validate_active\ndef upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n\n    Args:\n        content_dict: The dictionary containing the content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # json folder\n    folder_path = self.base_path + \"/\" + storage_path\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n\n    # create the full path\n    file_name = job_id + \".json\"\n    full_json_path = os.path.join(folder_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n    # test if the file already exists and raise a warning if it does\n    if os.path.exists(secure_path):\n        raise FileExistsError(\n            f\"The file {secure_path} already exists and should not be overwritten.\"\n        )\n\n    with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n        json.dump(content_dict, json_file, default=datetime_handler)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProvider","title":"<code>LocalProvider</code>","text":"<p>               Bases: <code>LocalProviderExtended</code></p> <p>Create a file storage that works on the local machine.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>class LocalProvider(LocalProviderExtended):\n    \"\"\"\n    Create a file storage that works on the local machine.\n    \"\"\"\n\n    def __init__(self, login_dict: LocalLoginInformation) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n        \"\"\"\n        super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def __init__(self, login_dict: LocalLoginInformation) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n    \"\"\"\n    super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended","title":"<code>LocalProviderExtended</code>","text":"<p>               Bases: <code>StorageProvider</code>, <code>LocalCore</code></p> <p>Create a file storage that works on the local machine.</p> <p>Attributes:</p> Name Type Description <code>configs_path</code> <code>PathStr</code> <p>The path to the folder where the configurations are stored</p> <code>queue_path</code> <code>PathStr</code> <p>The path to the folder where the jobs are stored</p> <code>running_path</code> <code>PathStr</code> <p>The path to the folder where the running jobs are stored</p> <code>finished_path</code> <code>PathStr</code> <p>The path to the folder where the finished jobs are stored</p> <code>deleted_path</code> <code>PathStr</code> <p>The path to the folder where the deleted jobs are stored</p> <code>status_path</code> <code>PathStr</code> <p>The path to the folder where the status is stored</p> <code>results_path</code> <code>PathStr</code> <p>The path to the folder where the results are stored</p> <code>pks_path</code> <code>PathStr</code> <p>The path to the folder where the public keys are stored</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>class LocalProviderExtended(StorageProvider, LocalCore):\n    \"\"\"\n    Create a file storage that works on the local machine.\n\n    Attributes:\n        configs_path: The path to the folder where the configurations are stored\n        queue_path: The path to the folder where the jobs are stored\n        running_path: The path to the folder where the running jobs are stored\n        finished_path: The path to the folder where the finished jobs are stored\n        deleted_path: The path to the folder where the deleted jobs are stored\n        status_path: The path to the folder where the status is stored\n        results_path: The path to the folder where the results are stored\n        pks_path: The path to the folder where the public keys are stored\n    \"\"\"\n\n    configs_path: PathStr = \"backends/configs\"\n    queue_path: PathStr = \"jobs/queued\"\n    running_path: PathStr = \"jobs/running\"\n    finished_path: PathStr = \"jobs/finished\"\n    deleted_path: PathStr = \"jobs/deleted\"\n    status_path: PathStr = \"status\"\n    results_path: PathStr = \"results\"\n    pks_path: PathStr = \"backends/public_keys\"\n\n    def get_device_status_path(\n        self, display_name: DisplayNameStr, username: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"\n        Get the path to the status of the device.\n\n        Args:\n            display_name: The name of the backend\n            username: The username of the user\n\n        Returns:\n            The path to the status of the device.\n        \"\"\"\n        return f\"{self.status_path}/{display_name}\"\n\n    def get_device_results_path(self, display_name: DisplayNameStr, job_id: str) -&gt; str:\n        \"\"\"\n        Get the path to the results of the device.\n\n        Args:\n            display_name: The name of the backend\n            job_id: The job_id of the job\n\n        Returns:\n            The path to the results of the device.\n        \"\"\"\n        return f\"{self.results_path}/{display_name}\"\n\n    def get_configs_path(self, display_name: Optional[DisplayNameStr] = None) -&gt; str:\n        \"\"\"\n        Get the path to the configs.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The path to the configs.\n        \"\"\"\n        return self.configs_path\n\n    def get_attribute_path(\n        self,\n        attribute_name: str,\n        display_name: Optional[DisplayNameStr] = None,\n        job_id: Optional[str] = None,\n    ) -&gt; str:\n        \"\"\"\n        Get the path to the results of the device.\n\n        Args:\n            display_name: The name of the backend\n            attribute_name: The name of the attribute\n            job_id: The job_id of the job\n\n        Returns:\n            The path to the results of the device.\n        \"\"\"\n\n        match attribute_name:\n            case \"running\":\n                path = self.running_path\n            case \"queue\":\n                path = f\"{self.queue_path}/{display_name}\"\n            case _:\n                raise ValueError(f\"The attribute name {attribute_name} is not valid.\")\n        return path\n\n    def get_status_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the name of the status json file.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The name of the status json file.\n        \"\"\"\n        return job_id\n\n    def get_result_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the name of the result json file.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The name of the result json file.\n        \"\"\"\n        return job_id\n\n    def get_config_id(self, display_name: DisplayNameStr) -&gt; str:\n        \"\"\"\n        Get the name of the config json file.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The name of the config json file.\n        \"\"\"\n        return display_name\n\n    def get_internal_job_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the internal job id from the job_id.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The internal job id\n        \"\"\"\n        return job_id\n\n    def get_backends(self) -&gt; list[DisplayNameStr]:\n        \"\"\"\n        Get a list of all the backends that the provider offers.\n        \"\"\"\n        return self.get_file_queue(self.configs_path)\n\n    def create_job_id(self, display_name: DisplayNameStr, username: str) -&gt; str:\n        \"\"\"\n        Create a job id for the job.\n\n        Returns:\n            The job id\n        \"\"\"\n        return (uuid.uuid4().hex)[:24]\n\n    def _delete_status(\n        self, display_name: DisplayNameStr, username: str, job_id: str\n    ) -&gt; bool:\n        \"\"\"\n        Delete a status from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Raises:\n            FileNotFoundError: If the status does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        status_json_dir = self.get_device_status_path(display_name)\n\n        self.delete(storage_path=status_json_dir, job_id=job_id)\n        return True\n\n    def _delete_result(self, display_name: DisplayNameStr, job_id: str) -&gt; bool:\n        \"\"\"\n        Delete a result from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Raises:\n            FileNotFoundError: If the result does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n\n        result_json_dir = self.get_device_results_path(display_name, job_id)\n        self.delete(storage_path=result_json_dir, job_id=job_id)\n        return True\n\n    def update_config(\n        self,\n        config_dict: BackendConfigSchemaIn,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        The function that updates the spooler configuration on the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            display_name : The name of the backend\n            private_jwk: The private key of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n        config_dict = self._verify_config(config_dict, display_name)\n        # path of the configs\n        config_path = os.path.join(self.base_path, self.configs_path)\n        config_path = os.path.normpath(config_path)\n\n        file_name = display_name + \".json\"\n        full_json_path = os.path.join(config_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n\n        # check if the file already exists\n        if not os.path.exists(secure_path):\n            raise FileNotFoundError(\n                (\n                    f\"The file {secure_path} does not exist and should not be updated.\"\n                    \"Use the upload_config method instead.\"\n                )\n            )\n\n        # now read the old config\n        with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n            old_config_jws = json.load(json_file)\n\n        upload_dict = self._format_update_config(\n            old_config_jws, config_dict, private_jwk\n        )\n\n        self.update(\n            content_dict=upload_dict,\n            storage_path=self.configs_path,\n            job_id=display_name,\n        )\n\n    def get_config(self, display_name: DisplayNameStr) -&gt; BackendConfigSchemaIn:\n        \"\"\"\n        The function that downloads the spooler configuration to the storage.\n\n        Args:\n            display_name : The name of the backend\n\n        Raises:\n            FileNotFoundError: If the backend does not exist\n\n        Returns:\n            The configuration of the backend in complete form.\n        \"\"\"\n        # path of the configs\n        backend_config_dict = self.get(self.configs_path, job_id=display_name)\n        typed_config = self._adapt_get_config(backend_config_dict)\n        return typed_config\n\n    def _delete_config(self, display_name: DisplayNameStr) -&gt; bool:\n        \"\"\"\n        Delete a config from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n\n        Raises:\n            FileNotFoundError: If the status does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n\n        self.delete(storage_path=self.configs_path, job_id=display_name)\n        return True\n\n    def upload_public_key(self, public_jwk: JWK, display_name: DisplayNameStr) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler public JWK to the storage. It should\n        only be used after `upload_config` as the kid is set there.\n\n        Args:\n            public_jwk: The JWK that contains the public key\n            display_name : The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # first make sure that the public key is intended for verification\n        if not public_jwk.key_ops == \"verify\":\n            raise ValueError(\"The key is not intended for verification\")\n\n        # make sure that the key does not contain a private key\n        if public_jwk.d is not None:\n            raise ValueError(\"The key contains a private key\")\n\n        # make sure that the key has the correct kid\n        config_dict = self.get_config(display_name)\n        if public_jwk.kid != config_dict.kid:\n            raise ValueError(\"The key does not have the correct kid.\")\n\n        # path of the public keys\n        key_path = os.path.join(self.base_path, self.pks_path)\n        key_path = os.path.normpath(key_path)\n        # test if the config path already exists. If it does not, create it\n        if not os.path.exists(key_path):\n            os.makedirs(key_path)\n\n        # this should most likely depend on the kid at some point\n        file_name = f\"{public_jwk.kid}.json\"\n        full_json_path = os.path.join(key_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n        with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n            json_file.write(public_jwk.model_dump_json())\n\n    def get_public_key(self, display_name: DisplayNameStr) -&gt; JWK:\n        \"\"\"\n        The function that gets the spooler public JWK for the device.\n\n        Args:\n            display_name : The name of the backend\n\n        Returns:\n            JWk : The public JWK object\n        \"\"\"\n\n        # first we have to get the kid\n        config_info = self.get_config(display_name)\n\n        # path of the configs\n        key_path = os.path.join(self.base_path, self.pks_path)\n        file_name = f\"{config_info.kid}.json\"\n        full_json_path = os.path.join(key_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n        with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n            public_key_dict = json.load(json_file)\n\n        if not public_key_dict:\n            raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n        return JWK(**public_key_dict)\n\n    def _delete_public_key(self, kid: str) -&gt; bool:\n        \"\"\"\n        Delete a public key from the storage. This is only intended for test purposes.\n\n        Args:\n            kid: The key id of the public key\n\n        Raises:\n            FileNotFoundError: If the status does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        self.delete(storage_path=self.pks_path, job_id=kid)\n        return True\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict,\n        status_msg_dict: StatusMsgDict,\n        job_id: str,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            display_name: the name of the backend\n            private_jwk: the private key of the backend\n\n        Returns:\n            None\n        \"\"\"\n        job_json_start_dir = self.running_path\n        # check if the job is done or had an error\n        if status_msg_dict.status == \"DONE\":\n            # test if the result dict is None\n            if result_dict is None:\n                raise ValueError(\n                    \"The 'result_dict' argument cannot be None if the job is done.\"\n                )\n            result_uploaded = self.upload_result(\n                result_dict, display_name, job_id, private_jwk\n            )\n            if not result_uploaded:\n                raise ValueError(\"The result was not uploaded successfully.\")\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = f\"{self.finished_path}/{display_name}\"\n\n            self.move(job_json_start_dir, job_finished_json_dir, job_id)\n\n        elif status_msg_dict.status == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            self.move(job_json_start_dir, self.deleted_path, job_id)\n\n        # and create the status json file\n        status_json_dir = self.get_device_status_path(display_name)\n        try:\n            self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n        except FileNotFoundError:\n            logging.warning(\n                \"The status file was missing for %s with job_id %s was missing.\",\n                display_name,\n                job_id,\n            )\n            self.upload_status(display_name, \"\", job_id)\n            self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of files. Only json files are considered. And the ending of\n        the file is removed.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n        # get a list of files in the folder\n        full_path = self.base_path + \"/\" + storage_path\n        # test if the path exists. Otherwise simply return an empty list\n        if not os.path.exists(full_path):\n            return []\n\n        all_items = os.listdir(full_path)\n        # Filter out only the JSON files\n        json_files = [item for item in all_items if item.endswith(\".json\")]\n\n        # Get the backend names\n        names = [os.path.splitext(file_name)[0] for file_name in json_files]\n\n        return names\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.create_job_id","title":"<code>create_job_id(display_name, username)</code>","text":"<p>Create a job id for the job.</p> <p>Returns:</p> Type Description <code>str</code> <p>The job id</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def create_job_id(self, display_name: DisplayNameStr, username: str) -&gt; str:\n    \"\"\"\n    Create a job id for the job.\n\n    Returns:\n        The job id\n    \"\"\"\n    return (uuid.uuid4().hex)[:24]\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_attribute_path","title":"<code>get_attribute_path(attribute_name, display_name=None, job_id=None)</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <code>attribute_name</code> <code>str</code> <p>The name of the attribute</p> required <code>job_id</code> <code>Optional[str]</code> <p>The job_id of the job</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_attribute_path(\n    self,\n    attribute_name: str,\n    display_name: Optional[DisplayNameStr] = None,\n    job_id: Optional[str] = None,\n) -&gt; str:\n    \"\"\"\n    Get the path to the results of the device.\n\n    Args:\n        display_name: The name of the backend\n        attribute_name: The name of the attribute\n        job_id: The job_id of the job\n\n    Returns:\n        The path to the results of the device.\n    \"\"\"\n\n    match attribute_name:\n        case \"running\":\n            path = self.running_path\n        case \"queue\":\n            path = f\"{self.queue_path}/{display_name}\"\n        case _:\n            raise ValueError(f\"The attribute name {attribute_name} is not valid.\")\n    return path\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_backends","title":"<code>get_backends()</code>","text":"<p>Get a list of all the backends that the provider offers.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_backends(self) -&gt; list[DisplayNameStr]:\n    \"\"\"\n    Get a list of all the backends that the provider offers.\n    \"\"\"\n    return self.get_file_queue(self.configs_path)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_config","title":"<code>get_config(display_name)</code>","text":"<p>The function that downloads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p> <p>Returns:</p> Type Description <code>BackendConfigSchemaIn</code> <p>The configuration of the backend in complete form.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_config(self, display_name: DisplayNameStr) -&gt; BackendConfigSchemaIn:\n    \"\"\"\n    The function that downloads the spooler configuration to the storage.\n\n    Args:\n        display_name : The name of the backend\n\n    Raises:\n        FileNotFoundError: If the backend does not exist\n\n    Returns:\n        The configuration of the backend in complete form.\n    \"\"\"\n    # path of the configs\n    backend_config_dict = self.get(self.configs_path, job_id=display_name)\n    typed_config = self._adapt_get_config(backend_config_dict)\n    return typed_config\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_config_id","title":"<code>get_config_id(display_name)</code>","text":"<p>Get the name of the config json file.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the config json file.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_config_id(self, display_name: DisplayNameStr) -&gt; str:\n    \"\"\"\n    Get the name of the config json file.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The name of the config json file.\n    \"\"\"\n    return display_name\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_configs_path","title":"<code>get_configs_path(display_name=None)</code>","text":"<p>Get the path to the configs.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the configs.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_configs_path(self, display_name: Optional[DisplayNameStr] = None) -&gt; str:\n    \"\"\"\n    Get the path to the configs.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The path to the configs.\n    \"\"\"\n    return self.configs_path\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_device_results_path","title":"<code>get_device_results_path(display_name, job_id)</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_device_results_path(self, display_name: DisplayNameStr, job_id: str) -&gt; str:\n    \"\"\"\n    Get the path to the results of the device.\n\n    Args:\n        display_name: The name of the backend\n        job_id: The job_id of the job\n\n    Returns:\n        The path to the results of the device.\n    \"\"\"\n    return f\"{self.results_path}/{display_name}\"\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_device_status_path","title":"<code>get_device_status_path(display_name, username=None)</code>","text":"<p>Get the path to the status of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>username</code> <code>Optional[str]</code> <p>The username of the user</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the status of the device.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_device_status_path(\n    self, display_name: DisplayNameStr, username: Optional[str] = None\n) -&gt; str:\n    \"\"\"\n    Get the path to the status of the device.\n\n    Args:\n        display_name: The name of the backend\n        username: The username of the user\n\n    Returns:\n        The path to the status of the device.\n    \"\"\"\n    return f\"{self.status_path}/{display_name}\"\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of files. Only json files are considered. And the ending of the file is removed.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of files. Only json files are considered. And the ending of\n    the file is removed.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n    # get a list of files in the folder\n    full_path = self.base_path + \"/\" + storage_path\n    # test if the path exists. Otherwise simply return an empty list\n    if not os.path.exists(full_path):\n        return []\n\n    all_items = os.listdir(full_path)\n    # Filter out only the JSON files\n    json_files = [item for item in all_items if item.endswith(\".json\")]\n\n    # Get the backend names\n    names = [os.path.splitext(file_name)[0] for file_name in json_files]\n\n    return names\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_internal_job_id","title":"<code>get_internal_job_id(job_id)</code>","text":"<p>Get the internal job id from the job_id.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The internal job id</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_internal_job_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the internal job id from the job_id.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The internal job id\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_public_key","title":"<code>get_public_key(display_name)</code>","text":"<p>The function that gets the spooler public JWK for the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Name Type Description <code>JWk</code> <code>JWK</code> <p>The public JWK object</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_public_key(self, display_name: DisplayNameStr) -&gt; JWK:\n    \"\"\"\n    The function that gets the spooler public JWK for the device.\n\n    Args:\n        display_name : The name of the backend\n\n    Returns:\n        JWk : The public JWK object\n    \"\"\"\n\n    # first we have to get the kid\n    config_info = self.get_config(display_name)\n\n    # path of the configs\n    key_path = os.path.join(self.base_path, self.pks_path)\n    file_name = f\"{config_info.kid}.json\"\n    full_json_path = os.path.join(key_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n    with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n        public_key_dict = json.load(json_file)\n\n    if not public_key_dict:\n        raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n    return JWK(**public_key_dict)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_result_id","title":"<code>get_result_id(job_id)</code>","text":"<p>Get the name of the result json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the result json file.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_result_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the name of the result json file.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The name of the result json file.\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.get_status_id","title":"<code>get_status_id(job_id)</code>","text":"<p>Get the name of the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the status json file.</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def get_status_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the name of the status json file.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The name of the status json file.\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.update_config","title":"<code>update_config(config_dict, display_name, private_jwk=None)</code>","text":"<p>The function that updates the spooler configuration on the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private key of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def update_config(\n    self,\n    config_dict: BackendConfigSchemaIn,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    The function that updates the spooler configuration on the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        display_name : The name of the backend\n        private_jwk: The private key of the backend\n\n    Returns:\n        None\n    \"\"\"\n\n    config_dict = self._verify_config(config_dict, display_name)\n    # path of the configs\n    config_path = os.path.join(self.base_path, self.configs_path)\n    config_path = os.path.normpath(config_path)\n\n    file_name = display_name + \".json\"\n    full_json_path = os.path.join(config_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n\n    # check if the file already exists\n    if not os.path.exists(secure_path):\n        raise FileNotFoundError(\n            (\n                f\"The file {secure_path} does not exist and should not be updated.\"\n                \"Use the upload_config method instead.\"\n            )\n        )\n\n    # now read the old config\n    with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n        old_config_jws = json.load(json_file)\n\n    upload_dict = self._format_update_config(\n        old_config_jws, config_dict, private_jwk\n    )\n\n    self.update(\n        content_dict=upload_dict,\n        storage_path=self.configs_path,\n        job_id=display_name,\n    )\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, display_name, private_jwk=None)</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>display_name</code> <code>DisplayNameStr</code> <p>the name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>the private key of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict,\n    status_msg_dict: StatusMsgDict,\n    job_id: str,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        display_name: the name of the backend\n        private_jwk: the private key of the backend\n\n    Returns:\n        None\n    \"\"\"\n    job_json_start_dir = self.running_path\n    # check if the job is done or had an error\n    if status_msg_dict.status == \"DONE\":\n        # test if the result dict is None\n        if result_dict is None:\n            raise ValueError(\n                \"The 'result_dict' argument cannot be None if the job is done.\"\n            )\n        result_uploaded = self.upload_result(\n            result_dict, display_name, job_id, private_jwk\n        )\n        if not result_uploaded:\n            raise ValueError(\"The result was not uploaded successfully.\")\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = f\"{self.finished_path}/{display_name}\"\n\n        self.move(job_json_start_dir, job_finished_json_dir, job_id)\n\n    elif status_msg_dict.status == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        self.move(job_json_start_dir, self.deleted_path, job_id)\n\n    # and create the status json file\n    status_json_dir = self.get_device_status_path(display_name)\n    try:\n        self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n    except FileNotFoundError:\n        logging.warning(\n            \"The status file was missing for %s with job_id %s was missing.\",\n            display_name,\n            job_id,\n        )\n        self.upload_status(display_name, \"\", job_id)\n        self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n</code></pre>"},{"location":"storage_providers/local/#src.sqooler.storage_providers.local.LocalProviderExtended.upload_public_key","title":"<code>upload_public_key(public_jwk, display_name)</code>","text":"<p>The function that uploads the spooler public JWK to the storage. It should only be used after <code>upload_config</code> as the kid is set there.</p> <p>Parameters:</p> Name Type Description Default <code>public_jwk</code> <code>JWK</code> <p>The JWK that contains the public key</p> required <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/local.py</code> <pre><code>def upload_public_key(self, public_jwk: JWK, display_name: DisplayNameStr) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler public JWK to the storage. It should\n    only be used after `upload_config` as the kid is set there.\n\n    Args:\n        public_jwk: The JWK that contains the public key\n        display_name : The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # first make sure that the public key is intended for verification\n    if not public_jwk.key_ops == \"verify\":\n        raise ValueError(\"The key is not intended for verification\")\n\n    # make sure that the key does not contain a private key\n    if public_jwk.d is not None:\n        raise ValueError(\"The key contains a private key\")\n\n    # make sure that the key has the correct kid\n    config_dict = self.get_config(display_name)\n    if public_jwk.kid != config_dict.kid:\n        raise ValueError(\"The key does not have the correct kid.\")\n\n    # path of the public keys\n    key_path = os.path.join(self.base_path, self.pks_path)\n    key_path = os.path.normpath(key_path)\n    # test if the config path already exists. If it does not, create it\n    if not os.path.exists(key_path):\n        os.makedirs(key_path)\n\n    # this should most likely depend on the kid at some point\n    file_name = f\"{public_jwk.kid}.json\"\n    full_json_path = os.path.join(key_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n    with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n        json_file.write(public_jwk.model_dump_json())\n</code></pre>"},{"location":"storage_providers/mongodb/","title":"API documentation of the mongodb provider","text":"<p>The module that contains all the necessary logic for communication with the MongoDb storage providers.</p>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbCore","title":"<code>MongodbCore</code>","text":"<p>               Bases: <code>StorageCore</code></p> <p>Base class that creates the most important functions for the mongodb storage provider.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>class MongodbCore(StorageCore):\n    \"\"\"\n    Base class that creates the most important functions for the mongodb storage provider.\n    \"\"\"\n\n    def __init__(\n        self, login_dict: MongodbLoginInformation, name: str, is_active: bool = True\n    ) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n\n        Args:\n            login_dict: The login dict that contains the neccessary\n                        information to connect to the mongodb\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n\n\n        Raises:\n            ValidationError: If the login_dict is not valid\n        \"\"\"\n        super().__init__(name, is_active)\n        mongodb_username = login_dict.mongodb_username\n        mongodb_password = login_dict.mongodb_password\n        mongodb_database_url = login_dict.mongodb_database_url\n\n        uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n        uri = uri + \"/?retryWrites=true&amp;w=majority\"\n        # Create a new client and connect to the server\n        self.client: MongoClient = MongoClient(uri)\n\n        # Send a ping to confirm a successful connection\n        self.client.admin.command(\"ping\")\n\n    @validate_active\n    def upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n\n        content_dict: the content that should be uploaded onto the mongodb base\n        storage_path: the access path towards the mongodb collection\n        job_id: the id of the file we are about to create\n        \"\"\"\n\n        _, collection = self._get_database_and_collection(storage_path)\n\n        content_dict[\"_id\"] = ObjectId(job_id)\n\n        try:\n            collection.insert_one(content_dict)\n        except DuplicateKeyError as err:\n            raise FileExistsError(\n                f\"The file with the id {job_id} already exists in the collection {storage_path}.\"\n            ) from err\n        # remove the id from the content dict for further use\n        content_dict.pop(\"_id\", None)\n\n    @validate_active\n    def get(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n\n        Args:\n            storage_path: the path towards the file, excluding the filename / id\n            job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the file\n        \"\"\"\n        try:\n            document_to_find = {\"_id\": ObjectId(job_id)}\n        except InvalidId as err:\n            raise FileNotFoundError(\n                f\"The job_id {job_id} is not valid. Please check the job_id.\"\n            ) from err\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n\n        _, collection = self._get_database_and_collection(storage_path)\n\n        result_found = collection.find_one(document_to_find)\n\n        if not result_found:\n            raise FileNotFoundError(\n                f\"Could not find a file under {storage_path} with the id {job_id}.\"\n            )\n\n        # remove the id from the result dict for further use\n        result_found.pop(\"_id\", None)\n        return result_found\n\n    @validate_active\n    def update(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content. It replaces the old content with the new content.\n\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n\n        Raises:\n            FileNotFoundError: If the file is not found\n        \"\"\"\n\n        _, collection = self._get_database_and_collection(storage_path)\n\n        filter_dict = {\"_id\": ObjectId(job_id)}\n        result = collection.replace_one(filter_dict, content_dict)\n\n        if result.matched_count == 0:\n            raise FileNotFoundError(f\"Could not update file under {storage_path}\")\n\n    @validate_active\n    def move(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n\n        # delete the old file\n        _, collection = self._get_database_and_collection(start_path)\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n        result_found = collection.find_one(document_to_find)\n\n        collection.delete_one(document_to_find)\n\n        # add the document to the new collection\n        _, collection = self._get_database_and_collection(final_path)\n\n        collection.insert_one(result_found)\n\n    @validate_active\n    def delete(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Remove the file from the mongodb database\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n            job_id: the name of the file\n\n        Returns:\n            None\n        \"\"\"\n        _, collection = self._get_database_and_collection(storage_path)\n\n        try:\n            document_to_find = {\"_id\": ObjectId(job_id)}\n        except InvalidId as err:\n            raise FileNotFoundError(\n                f\"The job_id {job_id} is not valid. Please check the job_id.\"\n            ) from err\n        result = collection.delete_one(document_to_find)\n        if result.deleted_count == 0:\n            raise FileNotFoundError(\n                f\"Could not find a file under {storage_path} with the id {job_id}.\"\n            )\n\n    def _get_database_and_collection(\n        self, storage_path: str\n    ) -&gt; tuple[Database, Collection]:\n        \"\"\"\n        Get the database and the collection on which we work.\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n\n        Returns:\n            The database and the collection on which we work\n        \"\"\"\n        # strip the path from leading and trailing slashes\n        storage_path = storage_path.strip(\"/\")\n\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n        return database, collection\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbCore.__init__","title":"<code>__init__(login_dict, name, is_active=True)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> <p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>MongodbLoginInformation</code> <p>The login dict that contains the neccessary         information to connect to the mongodb</p> required <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the login_dict is not valid</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def __init__(\n    self, login_dict: MongodbLoginInformation, name: str, is_active: bool = True\n) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n\n    Args:\n        login_dict: The login dict that contains the neccessary\n                    information to connect to the mongodb\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n\n\n    Raises:\n        ValidationError: If the login_dict is not valid\n    \"\"\"\n    super().__init__(name, is_active)\n    mongodb_username = login_dict.mongodb_username\n    mongodb_password = login_dict.mongodb_password\n    mongodb_database_url = login_dict.mongodb_database_url\n\n    uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n    uri = uri + \"/?retryWrites=true&amp;w=majority\"\n    # Create a new client and connect to the server\n    self.client: MongoClient = MongoClient(uri)\n\n    # Send a ping to confirm a successful connection\n    self.client.admin.command(\"ping\")\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbCore.delete","title":"<code>delete(storage_path, job_id)</code>","text":"<p>Remove the file from the mongodb database</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file is currently stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef delete(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Remove the file from the mongodb database\n\n    Args:\n        storage_path: the path where the file is currently stored, but excluding the file name\n        job_id: the name of the file\n\n    Returns:\n        None\n    \"\"\"\n    _, collection = self._get_database_and_collection(storage_path)\n\n    try:\n        document_to_find = {\"_id\": ObjectId(job_id)}\n    except InvalidId as err:\n        raise FileNotFoundError(\n            f\"The job_id {job_id} is not valid. Please check the job_id.\"\n        ) from err\n    result = collection.delete_one(document_to_find)\n    if result.deleted_count == 0:\n        raise FileNotFoundError(\n            f\"Could not find a file under {storage_path} with the id {job_id}.\"\n        )\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbCore.get","title":"<code>get(storage_path, job_id)</code>","text":"<p>Get the file content from the storage</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path towards the file, excluding the filename / id</p> required <code>job_id</code> <code>str</code> <p>the id of the file we are about to look up</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The content of the file</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef get(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n\n    Args:\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the file\n    \"\"\"\n    try:\n        document_to_find = {\"_id\": ObjectId(job_id)}\n    except InvalidId as err:\n        raise FileNotFoundError(\n            f\"The job_id {job_id} is not valid. Please check the job_id.\"\n        ) from err\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n\n    _, collection = self._get_database_and_collection(storage_path)\n\n    result_found = collection.find_one(document_to_find)\n\n    if not result_found:\n        raise FileNotFoundError(\n            f\"Could not find a file under {storage_path} with the id {job_id}.\"\n        )\n\n    # remove the id from the result dict for further use\n    result_found.pop(\"_id\", None)\n    return result_found\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbCore.move","title":"<code>move(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef move(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n\n    # delete the old file\n    _, collection = self._get_database_and_collection(start_path)\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n    result_found = collection.find_one(document_to_find)\n\n    collection.delete_one(document_to_find)\n\n    # add the document to the new collection\n    _, collection = self._get_database_and_collection(final_path)\n\n    collection.insert_one(result_found)\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbCore.update","title":"<code>update(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content. It replaces the old content with the new content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef update(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content. It replaces the old content with the new content.\n\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n\n    Raises:\n        FileNotFoundError: If the file is not found\n    \"\"\"\n\n    _, collection = self._get_database_and_collection(storage_path)\n\n    filter_dict = {\"_id\": ObjectId(job_id)}\n    result = collection.replace_one(filter_dict, content_dict)\n\n    if result.matched_count == 0:\n        raise FileNotFoundError(f\"Could not update file under {storage_path}\")\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbCore.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the file to the storage</p> <p>content_dict: the content that should be uploaded onto the mongodb base storage_path: the access path towards the mongodb collection job_id: the id of the file we are about to create</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n\n    content_dict: the content that should be uploaded onto the mongodb base\n    storage_path: the access path towards the mongodb collection\n    job_id: the id of the file we are about to create\n    \"\"\"\n\n    _, collection = self._get_database_and_collection(storage_path)\n\n    content_dict[\"_id\"] = ObjectId(job_id)\n\n    try:\n        collection.insert_one(content_dict)\n    except DuplicateKeyError as err:\n        raise FileExistsError(\n            f\"The file with the id {job_id} already exists in the collection {storage_path}.\"\n        ) from err\n    # remove the id from the content dict for further use\n    content_dict.pop(\"_id\", None)\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProvider","title":"<code>MongodbProvider</code>","text":"<p>               Bases: <code>MongodbProviderExtended</code></p> <p>The access to the mongodb. This is the simplified version for people that are running devices.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>class MongodbProvider(MongodbProviderExtended):\n    \"\"\"\n    The access to the mongodb. This is the simplified version for people that are running devices.\n    \"\"\"\n\n    def __init__(self, login_dict: MongodbLoginInformation) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n        \"\"\"\n        super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def __init__(self, login_dict: MongodbLoginInformation) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n    \"\"\"\n    super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended","title":"<code>MongodbProviderExtended</code>","text":"<p>               Bases: <code>StorageProvider</code>, <code>MongodbCore</code></p> <p>The access to the mongodb</p> <p>Attributes:</p> Name Type Description <code>configs_path</code> <code>PathStr</code> <p>The path to the folder where the configurations are stored</p> <code>queue_path</code> <code>PathStr</code> <p>The path to the folder where the jobs are stored</p> <code>running_path</code> <code>PathStr</code> <p>The path to the folder where the running jobs are stored</p> <code>finished_path</code> <code>PathStr</code> <p>The path to the folder where the finished jobs are stored</p> <code>deleted_path</code> <code>PathStr</code> <p>The path to the folder where the deleted jobs are stored</p> <code>status_path</code> <code>PathStr</code> <p>The path to the folder where the status is stored</p> <code>results_path</code> <code>PathStr</code> <p>The path to the folder where the results are stored</p> <code>pks_path</code> <code>PathStr</code> <p>The path to the folder where the public keys are stored</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>class MongodbProviderExtended(StorageProvider, MongodbCore):\n    \"\"\"\n    The access to the mongodb\n\n    Attributes:\n        configs_path: The path to the folder where the configurations are stored\n        queue_path: The path to the folder where the jobs are stored\n        running_path: The path to the folder where the running jobs are stored\n        finished_path: The path to the folder where the finished jobs are stored\n        deleted_path: The path to the folder where the deleted jobs are stored\n        status_path: The path to the folder where the status is stored\n        results_path: The path to the folder where the results are stored\n        pks_path: The path to the folder where the public keys are stored\n    \"\"\"\n\n    configs_path: PathStr = \"backends/configs\"\n    queue_path: PathStr = \"jobs/queued\"\n    running_path: PathStr = \"jobs/running\"\n    finished_path: PathStr = \"jobs/finished\"\n    deleted_path: PathStr = \"jobs/deleted\"\n    status_path: PathStr = \"status\"\n    results_path: PathStr = \"results\"\n    pks_path: PathStr = \"backends/public_keys\"\n\n    def get_configs_path(self, display_name: Optional[DisplayNameStr] = None) -&gt; str:\n        \"\"\"\n        Get the path to the configs.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The path to the configs.\n        \"\"\"\n        return self.configs_path\n\n    def get_attribute_path(\n        self,\n        attribute_name: str,\n        display_name: Optional[DisplayNameStr] = None,\n        job_id: Optional[str] = None,\n    ) -&gt; str:\n        \"\"\"\n        Get the path to the results of the device.\n\n        Args:\n            display_name: The name of the backend\n            attribute_name: The name of the attribute\n            job_id: The job_id of the job\n\n        Returns:\n            The path to the results of the device.\n        \"\"\"\n\n        match attribute_name:\n            case \"running\":\n                path = self.running_path\n            case \"queue\":\n                path = f\"{self.queue_path}/{display_name}\"\n            case _:\n                raise ValueError(f\"The attribute name {attribute_name} is not valid.\")\n        return path\n\n    def get_internal_job_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the internal job id from the job_id.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The internal job id\n        \"\"\"\n        return job_id\n\n    def get_config_id(self, display_name: DisplayNameStr) -&gt; str:\n        \"\"\"\n        Get the name of the config json file.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The name of the config json file.\n        \"\"\"\n        raise NotImplementedError(\"This function is not implemented.\")\n\n    @validate_active\n    def get_backends(self) -&gt; list[DisplayNameStr]:\n        \"\"\"\n        Get a list of all the backends that the provider offers.\n        \"\"\"\n\n        # get the collection on which we work\n        _, config_collection = self._get_database_and_collection(self.configs_path)\n\n        # get all the documents in the collection configs and save the disply_name in a list\n        backend_names: list[DisplayNameStr] = []\n        for config_dict in config_collection.find():\n            config_dict.pop(\"_id\")\n            expected_keys_for_jws = {\"header\", \"payload\", \"signature\"}\n            if set(config_dict.keys()) == expected_keys_for_jws:\n                backend_names.append(config_dict[\"payload\"][\"display_name\"])\n            else:\n                backend_names.append(config_dict[\"display_name\"])\n        return backend_names\n\n    def upload_config(\n        self,\n        config_dict: BackendConfigSchemaIn,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            display_name : The name of the backend\n            private_jwk: The private JWK to sign the configuration with\n\n        Returns:\n            None\n        \"\"\"\n        config_dict = self._verify_config(config_dict, display_name)\n\n        # first we have to check if the device already exists in the database\n\n        document_to_find = {\"display_name\": display_name}\n\n        # get the collection on which we work\n        _, collection = self._get_database_and_collection(self.configs_path)\n\n        document_to_find = {\"display_name\": display_name}\n        result_found = collection.find_one(document_to_find)\n        if result_found:\n            raise FileExistsError(\n                f\"The configuration for {display_name} already exists and should not be overwritten.\"\n            )\n\n        # now also look for signed configurations\n        signed_document_to_find = {\"payload.display_name\": display_name}\n        result_found = collection.find_one(signed_document_to_find)\n        if result_found:\n            raise FileExistsError(\n                f\"The configuration for {display_name} already exists and should not be overwritten.\"\n            )\n\n        upload_dict = self._format_config_dict(config_dict, private_jwk)\n        config_id = uuid.uuid4().hex[:24]\n        self.upload(upload_dict, self.configs_path, config_id)\n\n    def update_config(\n        self,\n        config_dict: BackendConfigSchemaIn,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        The function that updates the spooler configuration on the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            display_name : The name of the backend\n            private_jwk: The private key of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n        config_dict = self._verify_config(config_dict, display_name)\n\n        _, collection = self._get_database_and_collection(self.configs_path)\n\n        # now make sure that we add the timezone as we open the file\n        collection_with_tz = collection.with_options(\n            codec_options=CodecOptions(tz_aware=True, tzinfo=timezone.utc)\n        )\n        # first we have to check if the device already exists in the database\n        document_to_find = {\"display_name\": display_name}\n        result_found = collection_with_tz.find_one(document_to_find)\n\n        signed_document_to_find = {\"payload.display_name\": display_name}\n        signed_backend_config_dict = collection_with_tz.find_one(\n            signed_document_to_find\n        )\n\n        if result_found:\n            old_config_jws = result_found\n            job_id = result_found[\"_id\"]\n        elif signed_backend_config_dict:\n            old_config_jws = signed_backend_config_dict\n            job_id = signed_backend_config_dict[\"_id\"]\n            old_config_jws.pop(\"_id\")\n        else:\n            raise FileNotFoundError(\n                (\n                    f\"The config for {display_name} does not exist and should not be updated.\"\n                    \"Use the upload_config method instead.\"\n                )\n            )\n        upload_dict = self._format_update_config(\n            old_config_jws, config_dict, private_jwk\n        )\n\n        self.update(\n            content_dict=upload_dict,\n            storage_path=self.configs_path,\n            job_id=job_id,\n        )\n\n    @validate_active\n    def get_config(self, display_name: DisplayNameStr) -&gt; BackendConfigSchemaIn:\n        \"\"\"\n        The function that downloads the spooler configuration to the storage.\n\n        Args:\n            display_name : The name of the backend\n\n        Raises:\n            FileNotFoundError: If the backend does not exist\n\n        Returns:\n            The configuration of the backend in complete form.\n        \"\"\"\n        # get the collection on which we work\n        _, config_collection = self._get_database_and_collection(self.configs_path)\n\n        # create the filter for the document with display_name that is equal to display_name\n        document_to_find = {\"display_name\": display_name}\n        backend_config_dict = config_collection.find_one(document_to_find)\n\n        signed_document_to_find = {\"payload.display_name\": display_name}\n        signed_backend_config_dict = config_collection.find_one(signed_document_to_find)\n\n        # work with the unsigned backend\n        if backend_config_dict:\n            backend_config_dict.pop(\"_id\")\n            return BackendConfigSchemaIn(**backend_config_dict)\n\n        # work with the signed backend this is working normally due to the mongodb API, but to make\n        # mypy happy, we have to check if the signed_backend_config_dict is not None\n        elif signed_backend_config_dict:\n            payload = signed_backend_config_dict[\"payload\"]\n            return BackendConfigSchemaIn(**payload)\n\n        raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n    def _delete_config(self, display_name: DisplayNameStr) -&gt; bool:\n        \"\"\"\n        Delete a config from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n\n        Raises:\n            FileNotFoundError: If the config does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n\n        config_dict = self.get_config(display_name)\n        _, collection = self._get_database_and_collection(self.configs_path)\n\n        if not config_dict.sign:\n            document_to_find = {\"display_name\": display_name}\n        else:\n            document_to_find = {\"payload.display_name\": display_name}\n\n        result_found = collection.find_one(document_to_find)\n        if result_found is None:\n            raise FileNotFoundError(f\"the config for {display_name} does not exist.\")\n        self.delete(self.configs_path, str(result_found[\"_id\"]))\n\n        return True\n\n    def create_job_id(self, display_name: DisplayNameStr, username: str) -&gt; str:\n        \"\"\"\n        Create a job id for the job.\n\n        Returns:\n            The job id\n        \"\"\"\n        return (uuid.uuid4().hex)[:24]\n\n    def get_device_status_path(\n        self, display_name: DisplayNameStr, username: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"\n        Get the path to the status of the device.\n\n        Args:\n            display_name: The name of the backend\n            username: The username of the user\n\n        Returns:\n            The path to the status of the device.\n        \"\"\"\n        return f\"{self.status_path}/{display_name}\"\n\n    def get_status_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the name of the status json file.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The name of the status json file.\n        \"\"\"\n        return job_id\n\n    def get_device_results_path(self, display_name: DisplayNameStr, job_id: str) -&gt; str:\n        \"\"\"\n        Get the path to the results of the device.\n\n        Args:\n            display_name: The name of the backend\n            job_id: The job_id of the job\n\n        Returns:\n            The path to the results of the device.\n        \"\"\"\n        return f\"{self.results_path}/{display_name}\"\n\n    def get_result_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the name of the result json file.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The name of the result json file.\n        \"\"\"\n        return job_id\n\n    def _delete_status(\n        self, display_name: DisplayNameStr, username: str, job_id: str\n    ) -&gt; bool:\n        \"\"\"\n        Delete a status from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Raises:\n            FileNotFoundError: If the status does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        status_json_dir = self.get_device_status_path(display_name)\n\n        self.delete(storage_path=status_json_dir, job_id=job_id)\n        return True\n\n    def _delete_result(self, display_name: DisplayNameStr, job_id: str) -&gt; bool:\n        \"\"\"\n        Delete a result from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Raises:\n            FileNotFoundError: If the result does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        result_json_dir = self.get_device_results_path(display_name, job_id)\n\n        self.delete(storage_path=result_json_dir, job_id=job_id)\n        return True\n\n    def upload_public_key(self, public_jwk: JWK, display_name: DisplayNameStr) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler public JWK to the storage.\n\n        Args:\n            public_jwk: The JWK that contains the public key\n            display_name : The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # first make sure that the public key is intended for verification\n        if not public_jwk.key_ops == \"verify\":\n            raise ValueError(\"The key is not intended for verification\")\n\n        # make sure that the key does not contain a private key\n        if public_jwk.d is not None:\n            raise ValueError(\"The key contains a private key\")\n\n        # make sure that the key has the correct kid\n        config_dict = self.get_config(display_name)\n        if public_jwk.kid != config_dict.kid:\n            raise ValueError(\"The key does not have the correct kid.\")\n\n        _, collection = self._get_database_and_collection(self.pks_path)\n\n        # first we have to check if the device already exists in the database\n        document_to_find = {\"kid\": config_dict.kid}\n\n        result_found = collection.find_one(document_to_find)\n        if result_found:\n            # update the file\n            self.update(\n                content_dict=public_jwk.model_dump(),\n                storage_path=self.pks_path,\n                job_id=result_found[\"_id\"],\n            )\n            return\n\n        # if the device does not exist, we have to create it\n        config_id = uuid.uuid4().hex[:24]\n        self.upload(public_jwk.model_dump(), self.pks_path, config_id)\n\n    def get_public_key(self, display_name: DisplayNameStr) -&gt; JWK:\n        \"\"\"\n        The function that gets the spooler public JWK for the device.\n\n        Args:\n            display_name : The name of the backend\n\n        Returns:\n            JWk : The public JWK object\n        \"\"\"\n\n        # get the database on which we work\n        _, collection = self._get_database_and_collection(self.pks_path)\n\n        # now get the appropiate kid\n        config_dict = self.get_config(display_name)\n        if config_dict.kid is None:\n            raise ValueError(\"The kid is not set in the backend configuration.\")\n\n        # create the filter for the document with display_name that is equal to display_name\n        document_to_find = {\"kid\": config_dict.kid}\n        public_jwk_dict = collection.find_one(document_to_find)\n\n        if not public_jwk_dict:\n            raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n        public_jwk_dict.pop(\"_id\")\n        return JWK(**public_jwk_dict)\n\n    def _delete_public_key(self, kid: str) -&gt; bool:\n        \"\"\"\n        Delete a public key from the storage. This is only intended for test purposes.\n\n        Args:\n            kid: The key id of the public key\n\n        Raises:\n            FileNotFoundError: If the public key does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        document_to_find = {\"kid\": kid}\n        # get the database on which we work\n        _, collection = self._get_database_and_collection(self.pks_path)\n\n        result_found = collection.find_one(document_to_find)\n        if result_found is None:\n            raise FileNotFoundError(f\"The public key with kid {kid} does not exist\")\n        self.delete(self.pks_path, str(result_found[\"_id\"]))\n        return True\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict | None,\n        status_msg_dict: StatusMsgDict,\n        job_id: str,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        The function checks if the reported status of the job has changed to DONE. If so, it will create\n        a result json file and move the job json file to the finished folder. It will also update the\n        status json file.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            display_name: the name of the backend\n            private_jwk: the private JWK to sign the result with\n\n        Returns:\n            None\n\n        Raises:\n\n        \"\"\"\n\n        job_json_start_dir = self.running_path\n        # check if the job is done or had an error\n        if status_msg_dict.status == \"DONE\":\n            # test if the result dict is None\n            if result_dict is None:\n                raise ValueError(\n                    \"The 'result_dict' argument cannot be None if the job is done.\"\n                )\n            result_uploaded = self.upload_result(\n                result_dict, display_name, job_id, private_jwk\n            )\n            if not result_uploaded:\n                raise ValueError(\"The result was not uploaded successfully.\")\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = f\"{self.finished_path}/{display_name}\"\n            self.move(job_json_start_dir, job_finished_json_dir, job_id)\n\n        elif status_msg_dict.status == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = self.deleted_path\n            self.move(job_json_start_dir, deleted_json_dir, job_id)\n\n        # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n        # and create the status json file\n        status_json_dir = self.get_device_status_path(display_name)\n\n        try:\n            self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n        except FileNotFoundError:\n            logging.warning(\n                \"The status file was missing for %s with job_id %s was missing.\",\n                display_name,\n                job_id,\n            )\n            self.upload_status(display_name, \"\", job_id)\n            self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of documents in the collection of all the queued jobs.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n        _, collection = self._get_database_and_collection(storage_path)\n\n        # now get the id of all the documents in the collection\n        results = collection.find({}, {\"_id\": 1})\n        file_list = []\n        for result in results:\n            file_list.append(str(result[\"_id\"]))\n        return file_list\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.create_job_id","title":"<code>create_job_id(display_name, username)</code>","text":"<p>Create a job id for the job.</p> <p>Returns:</p> Type Description <code>str</code> <p>The job id</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def create_job_id(self, display_name: DisplayNameStr, username: str) -&gt; str:\n    \"\"\"\n    Create a job id for the job.\n\n    Returns:\n        The job id\n    \"\"\"\n    return (uuid.uuid4().hex)[:24]\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_attribute_path","title":"<code>get_attribute_path(attribute_name, display_name=None, job_id=None)</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <code>attribute_name</code> <code>str</code> <p>The name of the attribute</p> required <code>job_id</code> <code>Optional[str]</code> <p>The job_id of the job</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_attribute_path(\n    self,\n    attribute_name: str,\n    display_name: Optional[DisplayNameStr] = None,\n    job_id: Optional[str] = None,\n) -&gt; str:\n    \"\"\"\n    Get the path to the results of the device.\n\n    Args:\n        display_name: The name of the backend\n        attribute_name: The name of the attribute\n        job_id: The job_id of the job\n\n    Returns:\n        The path to the results of the device.\n    \"\"\"\n\n    match attribute_name:\n        case \"running\":\n            path = self.running_path\n        case \"queue\":\n            path = f\"{self.queue_path}/{display_name}\"\n        case _:\n            raise ValueError(f\"The attribute name {attribute_name} is not valid.\")\n    return path\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_backends","title":"<code>get_backends()</code>","text":"<p>Get a list of all the backends that the provider offers.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef get_backends(self) -&gt; list[DisplayNameStr]:\n    \"\"\"\n    Get a list of all the backends that the provider offers.\n    \"\"\"\n\n    # get the collection on which we work\n    _, config_collection = self._get_database_and_collection(self.configs_path)\n\n    # get all the documents in the collection configs and save the disply_name in a list\n    backend_names: list[DisplayNameStr] = []\n    for config_dict in config_collection.find():\n        config_dict.pop(\"_id\")\n        expected_keys_for_jws = {\"header\", \"payload\", \"signature\"}\n        if set(config_dict.keys()) == expected_keys_for_jws:\n            backend_names.append(config_dict[\"payload\"][\"display_name\"])\n        else:\n            backend_names.append(config_dict[\"display_name\"])\n    return backend_names\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_config","title":"<code>get_config(display_name)</code>","text":"<p>The function that downloads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p> <p>Returns:</p> Type Description <code>BackendConfigSchemaIn</code> <p>The configuration of the backend in complete form.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef get_config(self, display_name: DisplayNameStr) -&gt; BackendConfigSchemaIn:\n    \"\"\"\n    The function that downloads the spooler configuration to the storage.\n\n    Args:\n        display_name : The name of the backend\n\n    Raises:\n        FileNotFoundError: If the backend does not exist\n\n    Returns:\n        The configuration of the backend in complete form.\n    \"\"\"\n    # get the collection on which we work\n    _, config_collection = self._get_database_and_collection(self.configs_path)\n\n    # create the filter for the document with display_name that is equal to display_name\n    document_to_find = {\"display_name\": display_name}\n    backend_config_dict = config_collection.find_one(document_to_find)\n\n    signed_document_to_find = {\"payload.display_name\": display_name}\n    signed_backend_config_dict = config_collection.find_one(signed_document_to_find)\n\n    # work with the unsigned backend\n    if backend_config_dict:\n        backend_config_dict.pop(\"_id\")\n        return BackendConfigSchemaIn(**backend_config_dict)\n\n    # work with the signed backend this is working normally due to the mongodb API, but to make\n    # mypy happy, we have to check if the signed_backend_config_dict is not None\n    elif signed_backend_config_dict:\n        payload = signed_backend_config_dict[\"payload\"]\n        return BackendConfigSchemaIn(**payload)\n\n    raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_config_id","title":"<code>get_config_id(display_name)</code>","text":"<p>Get the name of the config json file.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the config json file.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_config_id(self, display_name: DisplayNameStr) -&gt; str:\n    \"\"\"\n    Get the name of the config json file.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The name of the config json file.\n    \"\"\"\n    raise NotImplementedError(\"This function is not implemented.\")\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_configs_path","title":"<code>get_configs_path(display_name=None)</code>","text":"<p>Get the path to the configs.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the configs.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_configs_path(self, display_name: Optional[DisplayNameStr] = None) -&gt; str:\n    \"\"\"\n    Get the path to the configs.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The path to the configs.\n    \"\"\"\n    return self.configs_path\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_device_results_path","title":"<code>get_device_results_path(display_name, job_id)</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_device_results_path(self, display_name: DisplayNameStr, job_id: str) -&gt; str:\n    \"\"\"\n    Get the path to the results of the device.\n\n    Args:\n        display_name: The name of the backend\n        job_id: The job_id of the job\n\n    Returns:\n        The path to the results of the device.\n    \"\"\"\n    return f\"{self.results_path}/{display_name}\"\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_device_status_path","title":"<code>get_device_status_path(display_name, username=None)</code>","text":"<p>Get the path to the status of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>username</code> <code>Optional[str]</code> <p>The username of the user</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the status of the device.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_device_status_path(\n    self, display_name: DisplayNameStr, username: Optional[str] = None\n) -&gt; str:\n    \"\"\"\n    Get the path to the status of the device.\n\n    Args:\n        display_name: The name of the backend\n        username: The username of the user\n\n    Returns:\n        The path to the status of the device.\n    \"\"\"\n    return f\"{self.status_path}/{display_name}\"\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of documents in the collection of all the queued jobs.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of documents in the collection of all the queued jobs.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n\n    _, collection = self._get_database_and_collection(storage_path)\n\n    # now get the id of all the documents in the collection\n    results = collection.find({}, {\"_id\": 1})\n    file_list = []\n    for result in results:\n        file_list.append(str(result[\"_id\"]))\n    return file_list\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_internal_job_id","title":"<code>get_internal_job_id(job_id)</code>","text":"<p>Get the internal job id from the job_id.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The internal job id</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_internal_job_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the internal job id from the job_id.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The internal job id\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_public_key","title":"<code>get_public_key(display_name)</code>","text":"<p>The function that gets the spooler public JWK for the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Name Type Description <code>JWk</code> <code>JWK</code> <p>The public JWK object</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_public_key(self, display_name: DisplayNameStr) -&gt; JWK:\n    \"\"\"\n    The function that gets the spooler public JWK for the device.\n\n    Args:\n        display_name : The name of the backend\n\n    Returns:\n        JWk : The public JWK object\n    \"\"\"\n\n    # get the database on which we work\n    _, collection = self._get_database_and_collection(self.pks_path)\n\n    # now get the appropiate kid\n    config_dict = self.get_config(display_name)\n    if config_dict.kid is None:\n        raise ValueError(\"The kid is not set in the backend configuration.\")\n\n    # create the filter for the document with display_name that is equal to display_name\n    document_to_find = {\"kid\": config_dict.kid}\n    public_jwk_dict = collection.find_one(document_to_find)\n\n    if not public_jwk_dict:\n        raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n    public_jwk_dict.pop(\"_id\")\n    return JWK(**public_jwk_dict)\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_result_id","title":"<code>get_result_id(job_id)</code>","text":"<p>Get the name of the result json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the result json file.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_result_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the name of the result json file.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The name of the result json file.\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_status_id","title":"<code>get_status_id(job_id)</code>","text":"<p>Get the name of the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the status json file.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_status_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the name of the status json file.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The name of the status json file.\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.update_config","title":"<code>update_config(config_dict, display_name, private_jwk=None)</code>","text":"<p>The function that updates the spooler configuration on the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private key of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def update_config(\n    self,\n    config_dict: BackendConfigSchemaIn,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    The function that updates the spooler configuration on the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        display_name : The name of the backend\n        private_jwk: The private key of the backend\n\n    Returns:\n        None\n    \"\"\"\n\n    config_dict = self._verify_config(config_dict, display_name)\n\n    _, collection = self._get_database_and_collection(self.configs_path)\n\n    # now make sure that we add the timezone as we open the file\n    collection_with_tz = collection.with_options(\n        codec_options=CodecOptions(tz_aware=True, tzinfo=timezone.utc)\n    )\n    # first we have to check if the device already exists in the database\n    document_to_find = {\"display_name\": display_name}\n    result_found = collection_with_tz.find_one(document_to_find)\n\n    signed_document_to_find = {\"payload.display_name\": display_name}\n    signed_backend_config_dict = collection_with_tz.find_one(\n        signed_document_to_find\n    )\n\n    if result_found:\n        old_config_jws = result_found\n        job_id = result_found[\"_id\"]\n    elif signed_backend_config_dict:\n        old_config_jws = signed_backend_config_dict\n        job_id = signed_backend_config_dict[\"_id\"]\n        old_config_jws.pop(\"_id\")\n    else:\n        raise FileNotFoundError(\n            (\n                f\"The config for {display_name} does not exist and should not be updated.\"\n                \"Use the upload_config method instead.\"\n            )\n        )\n    upload_dict = self._format_update_config(\n        old_config_jws, config_dict, private_jwk\n    )\n\n    self.update(\n        content_dict=upload_dict,\n        storage_path=self.configs_path,\n        job_id=job_id,\n    )\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, display_name, private_jwk=None)</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>The function checks if the reported status of the job has changed to DONE. If so, it will create a result json file and move the job json file to the finished folder. It will also update the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict | None</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>display_name</code> <code>DisplayNameStr</code> <p>the name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>the private JWK to sign the result with</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict | None,\n    status_msg_dict: StatusMsgDict,\n    job_id: str,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    The function checks if the reported status of the job has changed to DONE. If so, it will create\n    a result json file and move the job json file to the finished folder. It will also update the\n    status json file.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        display_name: the name of the backend\n        private_jwk: the private JWK to sign the result with\n\n    Returns:\n        None\n\n    Raises:\n\n    \"\"\"\n\n    job_json_start_dir = self.running_path\n    # check if the job is done or had an error\n    if status_msg_dict.status == \"DONE\":\n        # test if the result dict is None\n        if result_dict is None:\n            raise ValueError(\n                \"The 'result_dict' argument cannot be None if the job is done.\"\n            )\n        result_uploaded = self.upload_result(\n            result_dict, display_name, job_id, private_jwk\n        )\n        if not result_uploaded:\n            raise ValueError(\"The result was not uploaded successfully.\")\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = f\"{self.finished_path}/{display_name}\"\n        self.move(job_json_start_dir, job_finished_json_dir, job_id)\n\n    elif status_msg_dict.status == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = self.deleted_path\n        self.move(job_json_start_dir, deleted_json_dir, job_id)\n\n    # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n    # and create the status json file\n    status_json_dir = self.get_device_status_path(display_name)\n\n    try:\n        self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n    except FileNotFoundError:\n        logging.warning(\n            \"The status file was missing for %s with job_id %s was missing.\",\n            display_name,\n            job_id,\n        )\n        self.upload_status(display_name, \"\", job_id)\n        self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.upload_config","title":"<code>upload_config(config_dict, display_name, private_jwk=None)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private JWK to sign the configuration with</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def upload_config(\n    self,\n    config_dict: BackendConfigSchemaIn,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        display_name : The name of the backend\n        private_jwk: The private JWK to sign the configuration with\n\n    Returns:\n        None\n    \"\"\"\n    config_dict = self._verify_config(config_dict, display_name)\n\n    # first we have to check if the device already exists in the database\n\n    document_to_find = {\"display_name\": display_name}\n\n    # get the collection on which we work\n    _, collection = self._get_database_and_collection(self.configs_path)\n\n    document_to_find = {\"display_name\": display_name}\n    result_found = collection.find_one(document_to_find)\n    if result_found:\n        raise FileExistsError(\n            f\"The configuration for {display_name} already exists and should not be overwritten.\"\n        )\n\n    # now also look for signed configurations\n    signed_document_to_find = {\"payload.display_name\": display_name}\n    result_found = collection.find_one(signed_document_to_find)\n    if result_found:\n        raise FileExistsError(\n            f\"The configuration for {display_name} already exists and should not be overwritten.\"\n        )\n\n    upload_dict = self._format_config_dict(config_dict, private_jwk)\n    config_id = uuid.uuid4().hex[:24]\n    self.upload(upload_dict, self.configs_path, config_id)\n</code></pre>"},{"location":"storage_providers/mongodb/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.upload_public_key","title":"<code>upload_public_key(public_jwk, display_name)</code>","text":"<p>The function that uploads the spooler public JWK to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>public_jwk</code> <code>JWK</code> <p>The JWK that contains the public key</p> required <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def upload_public_key(self, public_jwk: JWK, display_name: DisplayNameStr) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler public JWK to the storage.\n\n    Args:\n        public_jwk: The JWK that contains the public key\n        display_name : The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # first make sure that the public key is intended for verification\n    if not public_jwk.key_ops == \"verify\":\n        raise ValueError(\"The key is not intended for verification\")\n\n    # make sure that the key does not contain a private key\n    if public_jwk.d is not None:\n        raise ValueError(\"The key contains a private key\")\n\n    # make sure that the key has the correct kid\n    config_dict = self.get_config(display_name)\n    if public_jwk.kid != config_dict.kid:\n        raise ValueError(\"The key does not have the correct kid.\")\n\n    _, collection = self._get_database_and_collection(self.pks_path)\n\n    # first we have to check if the device already exists in the database\n    document_to_find = {\"kid\": config_dict.kid}\n\n    result_found = collection.find_one(document_to_find)\n    if result_found:\n        # update the file\n        self.update(\n            content_dict=public_jwk.model_dump(),\n            storage_path=self.pks_path,\n            job_id=result_found[\"_id\"],\n        )\n        return\n\n    # if the device does not exist, we have to create it\n    config_id = uuid.uuid4().hex[:24]\n    self.upload(public_jwk.model_dump(), self.pks_path, config_id)\n</code></pre>"},{"location":"storage_providers/storage_providers/","title":"API documentation of storage providers","text":"<p>The module that contains all the necessary logic for communication with the external storage for the jobs. It creates an abstract API layer for the storage providers.</p> <p>The module that contains all the necessary logic for communication with the MongoDb storage providers.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore","title":"<code>StorageCore</code>","text":"<p>               Bases: <code>ABC</code></p> <p>A base class that is necessary to manipulate files in a consistent way.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.__init__","title":"<code>__init__(name, is_active=True)</code>","text":"<p>Any storage provide must have a name that is not empty.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.delete","title":"<code>delete(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Delete the file from the storage</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Depreceated function. Use <code>delete</code> instead.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.get","title":"<code>get(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the file content from the storage.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The content of the file</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Depreceated function. Use <code>get</code> instead.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.move","title":"<code>move(start_path, final_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Move the file from <code>start_path</code> to <code>final_path</code></p> <p>Parameters:</p> Name Type Description Default <code>start_path</code> <code>str</code> <p>The orginal path to the file</p> required <code>final_path</code> <code>str</code> <p>The targe path for the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Depreceated function. Use <code>move</code> instead.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.update","title":"<code>update(content_dict, storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Update the file content. It replaces the old content with the new content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Depreceated function. Use <code>update</code> instead.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Upload the file to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>Mapping</code> <p>The dictionary containing the content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageCore.upload_file","title":"<code>upload_file(content_dict, storage_path, job_id)</code>","text":"<p>Depreceated function. Use <code>upload</code> instead.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider","title":"<code>StorageProvider</code>","text":"<p>               Bases: <code>StorageCore</code></p> <p>The template for accessing any storage providers like dropbox, mongodb, amazon S3 etc.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.backend_dict_to_qiskit","title":"<code>backend_dict_to_qiskit(backend_config_info)</code>","text":"<p>This function transforms the dictionary that is safed in the storage provider into a qiskit backend dictionnary.</p> <p>Parameters:</p> Name Type Description Default <code>backend_config_info</code> <code>BackendConfigSchemaIn</code> <p>The dictionary that contains the configuration of the backend</p> required <p>Returns:</p> Type Description <code>BackendConfigSchemaOut</code> <p>The qiskit backend dictionary</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.backend_dict_to_qiskit_status","title":"<code>backend_dict_to_qiskit_status(backend_dict)</code>","text":"<p>This function transforms the dictionary that is safed in the storage provider into a qiskit backend status dictionnary.</p> <p>Parameters:</p> Name Type Description Default <code>backend_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary that contains the configuration of the backend</p> required <p>Returns:</p> Type Description <code>BackendStatusSchemaOut</code> <p>The qiskit backend dictionary</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.create_job_id","title":"<code>create_job_id(display_name, username)</code>  <code>abstractmethod</code>","text":"<p>Create a job id for the job.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job id</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_attribute_path","title":"<code>get_attribute_path(attribute_name, display_name=None, job_id=None)</code>  <code>abstractmethod</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <code>attribute_name</code> <code>str</code> <p>The name of the attribute</p> required <code>job_id</code> <code>Optional[str]</code> <p>The job_id of the job</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_backend_dict","title":"<code>get_backend_dict(display_name)</code>","text":"<p>The configuration dictionary of the backend such that it can be sent out to the API to the common user. We make sure that it is compatible with QISKIT within this function.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The identifier of the backend</p> required <p>Returns:</p> Type Description <code>BackendConfigSchemaOut</code> <p>The full schema of the backend.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_backend_status","title":"<code>get_backend_status(display_name)</code>","text":"<p>Get the status of the backend. This follows the qiskit logic.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>BackendStatusSchemaOut</code> <p>The status dict of the backend</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_backends","title":"<code>get_backends()</code>  <code>abstractmethod</code>","text":"<p>Get a list of all the backends that the provider offers.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_config","title":"<code>get_config(display_name)</code>  <code>abstractmethod</code>","text":"<p>The function that downloads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>BackendConfigSchemaIn</code> <p>The configuration of the backend in complete form.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_config_id","title":"<code>get_config_id(display_name)</code>  <code>abstractmethod</code>","text":"<p>Get the name of the config json file.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the config json file.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_configs_path","title":"<code>get_configs_path(display_name=None)</code>  <code>abstractmethod</code>","text":"<p>Get the path to the configs.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the configs.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_device_results_path","title":"<code>get_device_results_path(display_name, job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_device_status_path","title":"<code>get_device_status_path(display_name, username)</code>  <code>abstractmethod</code>","text":"<p>Get the path to the status of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the status of the device.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>  <code>abstractmethod</code>","text":"<p>Get a list of files</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_internal_job_id","title":"<code>get_internal_job_id(job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the internal job id from the job_id.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The internal job id</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_job","title":"<code>get_job(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Depreceated function. Use <code>get_job</code> instead.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(display_name, private_jwk=None)</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private JWK to sign the job with</p> <code>None</code> <p>Returns:</p> Type Description <code>NextJobSchema</code> <p>the path towards the job</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_public_key","title":"<code>get_public_key(display_name)</code>  <code>abstractmethod</code>","text":"<p>The function that gets the spooler public JWK for the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Name Type Description <code>JWk</code> <code>JWK</code> <p>The public JWK object</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_result","title":"<code>get_result(display_name, username, job_id)</code>","text":"<p>This function gets the result file from the backend and returns the result dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>ResultDict</code> <p>The result dict of the job. If the information is not available, the result dict</p> <code>ResultDict</code> <p>has a status of \"ERROR\".</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_result_id","title":"<code>get_result_id(job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the name of the result json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the result json file.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_status","title":"<code>get_status(display_name, username, job_id)</code>","text":"<p>This function gets the status file from the backend and returns the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.get_status_id","title":"<code>get_status_id(job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the id of the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the status json file.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.long_backend_name","title":"<code>long_backend_name(display_name, simulator)</code>","text":"<p>This function returns the long name of the backend.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>simulator</code> <code>bool</code> <p>True if the backend is a simulator</p> required <p>Returns:</p> Type Description <code>BackendNameStr</code> <p>The long name of the backend</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.timestamp_queue","title":"<code>timestamp_queue(display_name, private_jwk=None)</code>","text":"<p>Updates the time stamp for when the system last looked into the file queue. This allows us to track if the system is actually online or not.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private JWK to sign the result with</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.update_config","title":"<code>update_config(config_dict, display_name, private_jwk=None)</code>  <code>abstractmethod</code>","text":"<p>The function that updates an existing spooler configuration for the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The model containing the configuration</p> required <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private JWK to sign the result with</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the configuration does not exist</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, display_name, private_jwk=None)</code>  <code>abstractmethod</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>display_name</code> <code>DisplayNameStr</code> <p>the name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>the private JWK to sign the result with</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.upload_config","title":"<code>upload_config(config_dict, display_name, private_jwk=None)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private key of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.upload_job","title":"<code>upload_job(job_dict, display_name, username)</code>","text":"<p>This function uploads a job to the backend and creates the job_id.</p> <p>Parameters:</p> Name Type Description Default <code>job_dict</code> <code>dict</code> <p>The job dictionary that should be uploaded</p> required <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job_id of the uploaded job</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.upload_public_key","title":"<code>upload_public_key(public_jwk, display_name)</code>  <code>abstractmethod</code>","text":"<p>The function that uploads the spooler public JWK to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>public_jwk</code> <code>JWK</code> <p>The JWK that contains the public key</p> required <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.upload_result","title":"<code>upload_result(result_dict, display_name, job_id, private_jwk=None)</code>","text":"<p>This function allows us to upload the result file .</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>The result dictionary</p> required <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend to which we want to upload the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private key of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>The success of the upload process</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.upload_status","title":"<code>upload_status(display_name, username, job_id, private_jwk=None)</code>","text":"<p>This function uploads a status file to the backend and creates the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private key of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.StorageProvider.verify_result","title":"<code>verify_result(display_name, job_id)</code>","text":"<p>This function verifies the result and returns the success. If the backend does not sign the result, we will reutrn <code>False</code> by default, given that we were not able to establish ownership.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend to which we want to upload the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>bool</code> <p>If it was possible to verify the result dict positively.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.datetime_handler","title":"<code>datetime_handler(in_var)</code>","text":"<p>Convert a datetime object to a string.</p> <p>Parameters:</p> Name Type Description Default <code>in_var</code> <p>The object to convert</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The string representation of the object</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.base.validate_active","title":"<code>validate_active(func)</code>","text":"<p>Decorator to check if the storage provider is active.</p>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbCore","title":"<code>MongodbCore</code>","text":"<p>               Bases: <code>StorageCore</code></p> <p>Base class that creates the most important functions for the mongodb storage provider.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>class MongodbCore(StorageCore):\n    \"\"\"\n    Base class that creates the most important functions for the mongodb storage provider.\n    \"\"\"\n\n    def __init__(\n        self, login_dict: MongodbLoginInformation, name: str, is_active: bool = True\n    ) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n\n        Args:\n            login_dict: The login dict that contains the neccessary\n                        information to connect to the mongodb\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n\n\n        Raises:\n            ValidationError: If the login_dict is not valid\n        \"\"\"\n        super().__init__(name, is_active)\n        mongodb_username = login_dict.mongodb_username\n        mongodb_password = login_dict.mongodb_password\n        mongodb_database_url = login_dict.mongodb_database_url\n\n        uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n        uri = uri + \"/?retryWrites=true&amp;w=majority\"\n        # Create a new client and connect to the server\n        self.client: MongoClient = MongoClient(uri)\n\n        # Send a ping to confirm a successful connection\n        self.client.admin.command(\"ping\")\n\n    @validate_active\n    def upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n\n        content_dict: the content that should be uploaded onto the mongodb base\n        storage_path: the access path towards the mongodb collection\n        job_id: the id of the file we are about to create\n        \"\"\"\n\n        _, collection = self._get_database_and_collection(storage_path)\n\n        content_dict[\"_id\"] = ObjectId(job_id)\n\n        try:\n            collection.insert_one(content_dict)\n        except DuplicateKeyError as err:\n            raise FileExistsError(\n                f\"The file with the id {job_id} already exists in the collection {storage_path}.\"\n            ) from err\n        # remove the id from the content dict for further use\n        content_dict.pop(\"_id\", None)\n\n    @validate_active\n    def get(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n\n        Args:\n            storage_path: the path towards the file, excluding the filename / id\n            job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the file\n        \"\"\"\n        try:\n            document_to_find = {\"_id\": ObjectId(job_id)}\n        except InvalidId as err:\n            raise FileNotFoundError(\n                f\"The job_id {job_id} is not valid. Please check the job_id.\"\n            ) from err\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n\n        _, collection = self._get_database_and_collection(storage_path)\n\n        result_found = collection.find_one(document_to_find)\n\n        if not result_found:\n            raise FileNotFoundError(\n                f\"Could not find a file under {storage_path} with the id {job_id}.\"\n            )\n\n        # remove the id from the result dict for further use\n        result_found.pop(\"_id\", None)\n        return result_found\n\n    @validate_active\n    def update(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content. It replaces the old content with the new content.\n\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n\n        Raises:\n            FileNotFoundError: If the file is not found\n        \"\"\"\n\n        _, collection = self._get_database_and_collection(storage_path)\n\n        filter_dict = {\"_id\": ObjectId(job_id)}\n        result = collection.replace_one(filter_dict, content_dict)\n\n        if result.matched_count == 0:\n            raise FileNotFoundError(f\"Could not update file under {storage_path}\")\n\n    @validate_active\n    def move(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n\n        # delete the old file\n        _, collection = self._get_database_and_collection(start_path)\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n        result_found = collection.find_one(document_to_find)\n\n        collection.delete_one(document_to_find)\n\n        # add the document to the new collection\n        _, collection = self._get_database_and_collection(final_path)\n\n        collection.insert_one(result_found)\n\n    @validate_active\n    def delete(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Remove the file from the mongodb database\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n            job_id: the name of the file\n\n        Returns:\n            None\n        \"\"\"\n        _, collection = self._get_database_and_collection(storage_path)\n\n        try:\n            document_to_find = {\"_id\": ObjectId(job_id)}\n        except InvalidId as err:\n            raise FileNotFoundError(\n                f\"The job_id {job_id} is not valid. Please check the job_id.\"\n            ) from err\n        result = collection.delete_one(document_to_find)\n        if result.deleted_count == 0:\n            raise FileNotFoundError(\n                f\"Could not find a file under {storage_path} with the id {job_id}.\"\n            )\n\n    def _get_database_and_collection(\n        self, storage_path: str\n    ) -&gt; tuple[Database, Collection]:\n        \"\"\"\n        Get the database and the collection on which we work.\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n\n        Returns:\n            The database and the collection on which we work\n        \"\"\"\n        # strip the path from leading and trailing slashes\n        storage_path = storage_path.strip(\"/\")\n\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n        return database, collection\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbCore.__init__","title":"<code>__init__(login_dict, name, is_active=True)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> <p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>MongodbLoginInformation</code> <p>The login dict that contains the neccessary         information to connect to the mongodb</p> required <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the login_dict is not valid</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def __init__(\n    self, login_dict: MongodbLoginInformation, name: str, is_active: bool = True\n) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n\n    Args:\n        login_dict: The login dict that contains the neccessary\n                    information to connect to the mongodb\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n\n\n    Raises:\n        ValidationError: If the login_dict is not valid\n    \"\"\"\n    super().__init__(name, is_active)\n    mongodb_username = login_dict.mongodb_username\n    mongodb_password = login_dict.mongodb_password\n    mongodb_database_url = login_dict.mongodb_database_url\n\n    uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n    uri = uri + \"/?retryWrites=true&amp;w=majority\"\n    # Create a new client and connect to the server\n    self.client: MongoClient = MongoClient(uri)\n\n    # Send a ping to confirm a successful connection\n    self.client.admin.command(\"ping\")\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbCore.delete","title":"<code>delete(storage_path, job_id)</code>","text":"<p>Remove the file from the mongodb database</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file is currently stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef delete(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Remove the file from the mongodb database\n\n    Args:\n        storage_path: the path where the file is currently stored, but excluding the file name\n        job_id: the name of the file\n\n    Returns:\n        None\n    \"\"\"\n    _, collection = self._get_database_and_collection(storage_path)\n\n    try:\n        document_to_find = {\"_id\": ObjectId(job_id)}\n    except InvalidId as err:\n        raise FileNotFoundError(\n            f\"The job_id {job_id} is not valid. Please check the job_id.\"\n        ) from err\n    result = collection.delete_one(document_to_find)\n    if result.deleted_count == 0:\n        raise FileNotFoundError(\n            f\"Could not find a file under {storage_path} with the id {job_id}.\"\n        )\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbCore.get","title":"<code>get(storage_path, job_id)</code>","text":"<p>Get the file content from the storage</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path towards the file, excluding the filename / id</p> required <code>job_id</code> <code>str</code> <p>the id of the file we are about to look up</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The content of the file</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef get(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n\n    Args:\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the file\n    \"\"\"\n    try:\n        document_to_find = {\"_id\": ObjectId(job_id)}\n    except InvalidId as err:\n        raise FileNotFoundError(\n            f\"The job_id {job_id} is not valid. Please check the job_id.\"\n        ) from err\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n\n    _, collection = self._get_database_and_collection(storage_path)\n\n    result_found = collection.find_one(document_to_find)\n\n    if not result_found:\n        raise FileNotFoundError(\n            f\"Could not find a file under {storage_path} with the id {job_id}.\"\n        )\n\n    # remove the id from the result dict for further use\n    result_found.pop(\"_id\", None)\n    return result_found\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbCore.move","title":"<code>move(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef move(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n\n    # delete the old file\n    _, collection = self._get_database_and_collection(start_path)\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n    result_found = collection.find_one(document_to_find)\n\n    collection.delete_one(document_to_find)\n\n    # add the document to the new collection\n    _, collection = self._get_database_and_collection(final_path)\n\n    collection.insert_one(result_found)\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbCore.update","title":"<code>update(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content. It replaces the old content with the new content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file is not found</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef update(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content. It replaces the old content with the new content.\n\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n\n    Raises:\n        FileNotFoundError: If the file is not found\n    \"\"\"\n\n    _, collection = self._get_database_and_collection(storage_path)\n\n    filter_dict = {\"_id\": ObjectId(job_id)}\n    result = collection.replace_one(filter_dict, content_dict)\n\n    if result.matched_count == 0:\n        raise FileNotFoundError(f\"Could not update file under {storage_path}\")\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbCore.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the file to the storage</p> <p>content_dict: the content that should be uploaded onto the mongodb base storage_path: the access path towards the mongodb collection job_id: the id of the file we are about to create</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n\n    content_dict: the content that should be uploaded onto the mongodb base\n    storage_path: the access path towards the mongodb collection\n    job_id: the id of the file we are about to create\n    \"\"\"\n\n    _, collection = self._get_database_and_collection(storage_path)\n\n    content_dict[\"_id\"] = ObjectId(job_id)\n\n    try:\n        collection.insert_one(content_dict)\n    except DuplicateKeyError as err:\n        raise FileExistsError(\n            f\"The file with the id {job_id} already exists in the collection {storage_path}.\"\n        ) from err\n    # remove the id from the content dict for further use\n    content_dict.pop(\"_id\", None)\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProvider","title":"<code>MongodbProvider</code>","text":"<p>               Bases: <code>MongodbProviderExtended</code></p> <p>The access to the mongodb. This is the simplified version for people that are running devices.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>class MongodbProvider(MongodbProviderExtended):\n    \"\"\"\n    The access to the mongodb. This is the simplified version for people that are running devices.\n    \"\"\"\n\n    def __init__(self, login_dict: MongodbLoginInformation) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n        \"\"\"\n        super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def __init__(self, login_dict: MongodbLoginInformation) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n    \"\"\"\n    super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended","title":"<code>MongodbProviderExtended</code>","text":"<p>               Bases: <code>StorageProvider</code>, <code>MongodbCore</code></p> <p>The access to the mongodb</p> <p>Attributes:</p> Name Type Description <code>configs_path</code> <code>PathStr</code> <p>The path to the folder where the configurations are stored</p> <code>queue_path</code> <code>PathStr</code> <p>The path to the folder where the jobs are stored</p> <code>running_path</code> <code>PathStr</code> <p>The path to the folder where the running jobs are stored</p> <code>finished_path</code> <code>PathStr</code> <p>The path to the folder where the finished jobs are stored</p> <code>deleted_path</code> <code>PathStr</code> <p>The path to the folder where the deleted jobs are stored</p> <code>status_path</code> <code>PathStr</code> <p>The path to the folder where the status is stored</p> <code>results_path</code> <code>PathStr</code> <p>The path to the folder where the results are stored</p> <code>pks_path</code> <code>PathStr</code> <p>The path to the folder where the public keys are stored</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>class MongodbProviderExtended(StorageProvider, MongodbCore):\n    \"\"\"\n    The access to the mongodb\n\n    Attributes:\n        configs_path: The path to the folder where the configurations are stored\n        queue_path: The path to the folder where the jobs are stored\n        running_path: The path to the folder where the running jobs are stored\n        finished_path: The path to the folder where the finished jobs are stored\n        deleted_path: The path to the folder where the deleted jobs are stored\n        status_path: The path to the folder where the status is stored\n        results_path: The path to the folder where the results are stored\n        pks_path: The path to the folder where the public keys are stored\n    \"\"\"\n\n    configs_path: PathStr = \"backends/configs\"\n    queue_path: PathStr = \"jobs/queued\"\n    running_path: PathStr = \"jobs/running\"\n    finished_path: PathStr = \"jobs/finished\"\n    deleted_path: PathStr = \"jobs/deleted\"\n    status_path: PathStr = \"status\"\n    results_path: PathStr = \"results\"\n    pks_path: PathStr = \"backends/public_keys\"\n\n    def get_configs_path(self, display_name: Optional[DisplayNameStr] = None) -&gt; str:\n        \"\"\"\n        Get the path to the configs.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The path to the configs.\n        \"\"\"\n        return self.configs_path\n\n    def get_attribute_path(\n        self,\n        attribute_name: str,\n        display_name: Optional[DisplayNameStr] = None,\n        job_id: Optional[str] = None,\n    ) -&gt; str:\n        \"\"\"\n        Get the path to the results of the device.\n\n        Args:\n            display_name: The name of the backend\n            attribute_name: The name of the attribute\n            job_id: The job_id of the job\n\n        Returns:\n            The path to the results of the device.\n        \"\"\"\n\n        match attribute_name:\n            case \"running\":\n                path = self.running_path\n            case \"queue\":\n                path = f\"{self.queue_path}/{display_name}\"\n            case _:\n                raise ValueError(f\"The attribute name {attribute_name} is not valid.\")\n        return path\n\n    def get_internal_job_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the internal job id from the job_id.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The internal job id\n        \"\"\"\n        return job_id\n\n    def get_config_id(self, display_name: DisplayNameStr) -&gt; str:\n        \"\"\"\n        Get the name of the config json file.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The name of the config json file.\n        \"\"\"\n        raise NotImplementedError(\"This function is not implemented.\")\n\n    @validate_active\n    def get_backends(self) -&gt; list[DisplayNameStr]:\n        \"\"\"\n        Get a list of all the backends that the provider offers.\n        \"\"\"\n\n        # get the collection on which we work\n        _, config_collection = self._get_database_and_collection(self.configs_path)\n\n        # get all the documents in the collection configs and save the disply_name in a list\n        backend_names: list[DisplayNameStr] = []\n        for config_dict in config_collection.find():\n            config_dict.pop(\"_id\")\n            expected_keys_for_jws = {\"header\", \"payload\", \"signature\"}\n            if set(config_dict.keys()) == expected_keys_for_jws:\n                backend_names.append(config_dict[\"payload\"][\"display_name\"])\n            else:\n                backend_names.append(config_dict[\"display_name\"])\n        return backend_names\n\n    def upload_config(\n        self,\n        config_dict: BackendConfigSchemaIn,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            display_name : The name of the backend\n            private_jwk: The private JWK to sign the configuration with\n\n        Returns:\n            None\n        \"\"\"\n        config_dict = self._verify_config(config_dict, display_name)\n\n        # first we have to check if the device already exists in the database\n\n        document_to_find = {\"display_name\": display_name}\n\n        # get the collection on which we work\n        _, collection = self._get_database_and_collection(self.configs_path)\n\n        document_to_find = {\"display_name\": display_name}\n        result_found = collection.find_one(document_to_find)\n        if result_found:\n            raise FileExistsError(\n                f\"The configuration for {display_name} already exists and should not be overwritten.\"\n            )\n\n        # now also look for signed configurations\n        signed_document_to_find = {\"payload.display_name\": display_name}\n        result_found = collection.find_one(signed_document_to_find)\n        if result_found:\n            raise FileExistsError(\n                f\"The configuration for {display_name} already exists and should not be overwritten.\"\n            )\n\n        upload_dict = self._format_config_dict(config_dict, private_jwk)\n        config_id = uuid.uuid4().hex[:24]\n        self.upload(upload_dict, self.configs_path, config_id)\n\n    def update_config(\n        self,\n        config_dict: BackendConfigSchemaIn,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        The function that updates the spooler configuration on the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            display_name : The name of the backend\n            private_jwk: The private key of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n        config_dict = self._verify_config(config_dict, display_name)\n\n        _, collection = self._get_database_and_collection(self.configs_path)\n\n        # now make sure that we add the timezone as we open the file\n        collection_with_tz = collection.with_options(\n            codec_options=CodecOptions(tz_aware=True, tzinfo=timezone.utc)\n        )\n        # first we have to check if the device already exists in the database\n        document_to_find = {\"display_name\": display_name}\n        result_found = collection_with_tz.find_one(document_to_find)\n\n        signed_document_to_find = {\"payload.display_name\": display_name}\n        signed_backend_config_dict = collection_with_tz.find_one(\n            signed_document_to_find\n        )\n\n        if result_found:\n            old_config_jws = result_found\n            job_id = result_found[\"_id\"]\n        elif signed_backend_config_dict:\n            old_config_jws = signed_backend_config_dict\n            job_id = signed_backend_config_dict[\"_id\"]\n            old_config_jws.pop(\"_id\")\n        else:\n            raise FileNotFoundError(\n                (\n                    f\"The config for {display_name} does not exist and should not be updated.\"\n                    \"Use the upload_config method instead.\"\n                )\n            )\n        upload_dict = self._format_update_config(\n            old_config_jws, config_dict, private_jwk\n        )\n\n        self.update(\n            content_dict=upload_dict,\n            storage_path=self.configs_path,\n            job_id=job_id,\n        )\n\n    @validate_active\n    def get_config(self, display_name: DisplayNameStr) -&gt; BackendConfigSchemaIn:\n        \"\"\"\n        The function that downloads the spooler configuration to the storage.\n\n        Args:\n            display_name : The name of the backend\n\n        Raises:\n            FileNotFoundError: If the backend does not exist\n\n        Returns:\n            The configuration of the backend in complete form.\n        \"\"\"\n        # get the collection on which we work\n        _, config_collection = self._get_database_and_collection(self.configs_path)\n\n        # create the filter for the document with display_name that is equal to display_name\n        document_to_find = {\"display_name\": display_name}\n        backend_config_dict = config_collection.find_one(document_to_find)\n\n        signed_document_to_find = {\"payload.display_name\": display_name}\n        signed_backend_config_dict = config_collection.find_one(signed_document_to_find)\n\n        # work with the unsigned backend\n        if backend_config_dict:\n            backend_config_dict.pop(\"_id\")\n            return BackendConfigSchemaIn(**backend_config_dict)\n\n        # work with the signed backend this is working normally due to the mongodb API, but to make\n        # mypy happy, we have to check if the signed_backend_config_dict is not None\n        elif signed_backend_config_dict:\n            payload = signed_backend_config_dict[\"payload\"]\n            return BackendConfigSchemaIn(**payload)\n\n        raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n    def _delete_config(self, display_name: DisplayNameStr) -&gt; bool:\n        \"\"\"\n        Delete a config from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n\n        Raises:\n            FileNotFoundError: If the config does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n\n        config_dict = self.get_config(display_name)\n        _, collection = self._get_database_and_collection(self.configs_path)\n\n        if not config_dict.sign:\n            document_to_find = {\"display_name\": display_name}\n        else:\n            document_to_find = {\"payload.display_name\": display_name}\n\n        result_found = collection.find_one(document_to_find)\n        if result_found is None:\n            raise FileNotFoundError(f\"the config for {display_name} does not exist.\")\n        self.delete(self.configs_path, str(result_found[\"_id\"]))\n\n        return True\n\n    def create_job_id(self, display_name: DisplayNameStr, username: str) -&gt; str:\n        \"\"\"\n        Create a job id for the job.\n\n        Returns:\n            The job id\n        \"\"\"\n        return (uuid.uuid4().hex)[:24]\n\n    def get_device_status_path(\n        self, display_name: DisplayNameStr, username: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"\n        Get the path to the status of the device.\n\n        Args:\n            display_name: The name of the backend\n            username: The username of the user\n\n        Returns:\n            The path to the status of the device.\n        \"\"\"\n        return f\"{self.status_path}/{display_name}\"\n\n    def get_status_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the name of the status json file.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The name of the status json file.\n        \"\"\"\n        return job_id\n\n    def get_device_results_path(self, display_name: DisplayNameStr, job_id: str) -&gt; str:\n        \"\"\"\n        Get the path to the results of the device.\n\n        Args:\n            display_name: The name of the backend\n            job_id: The job_id of the job\n\n        Returns:\n            The path to the results of the device.\n        \"\"\"\n        return f\"{self.results_path}/{display_name}\"\n\n    def get_result_id(self, job_id: str) -&gt; str:\n        \"\"\"\n        Get the name of the result json file.\n\n        Args:\n            job_id: The job_id of the job\n\n        Returns:\n            The name of the result json file.\n        \"\"\"\n        return job_id\n\n    def _delete_status(\n        self, display_name: DisplayNameStr, username: str, job_id: str\n    ) -&gt; bool:\n        \"\"\"\n        Delete a status from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Raises:\n            FileNotFoundError: If the status does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        status_json_dir = self.get_device_status_path(display_name)\n\n        self.delete(storage_path=status_json_dir, job_id=job_id)\n        return True\n\n    def _delete_result(self, display_name: DisplayNameStr, job_id: str) -&gt; bool:\n        \"\"\"\n        Delete a result from the storage. This is only intended for test purposes.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Raises:\n            FileNotFoundError: If the result does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        result_json_dir = self.get_device_results_path(display_name, job_id)\n\n        self.delete(storage_path=result_json_dir, job_id=job_id)\n        return True\n\n    def upload_public_key(self, public_jwk: JWK, display_name: DisplayNameStr) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler public JWK to the storage.\n\n        Args:\n            public_jwk: The JWK that contains the public key\n            display_name : The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # first make sure that the public key is intended for verification\n        if not public_jwk.key_ops == \"verify\":\n            raise ValueError(\"The key is not intended for verification\")\n\n        # make sure that the key does not contain a private key\n        if public_jwk.d is not None:\n            raise ValueError(\"The key contains a private key\")\n\n        # make sure that the key has the correct kid\n        config_dict = self.get_config(display_name)\n        if public_jwk.kid != config_dict.kid:\n            raise ValueError(\"The key does not have the correct kid.\")\n\n        _, collection = self._get_database_and_collection(self.pks_path)\n\n        # first we have to check if the device already exists in the database\n        document_to_find = {\"kid\": config_dict.kid}\n\n        result_found = collection.find_one(document_to_find)\n        if result_found:\n            # update the file\n            self.update(\n                content_dict=public_jwk.model_dump(),\n                storage_path=self.pks_path,\n                job_id=result_found[\"_id\"],\n            )\n            return\n\n        # if the device does not exist, we have to create it\n        config_id = uuid.uuid4().hex[:24]\n        self.upload(public_jwk.model_dump(), self.pks_path, config_id)\n\n    def get_public_key(self, display_name: DisplayNameStr) -&gt; JWK:\n        \"\"\"\n        The function that gets the spooler public JWK for the device.\n\n        Args:\n            display_name : The name of the backend\n\n        Returns:\n            JWk : The public JWK object\n        \"\"\"\n\n        # get the database on which we work\n        _, collection = self._get_database_and_collection(self.pks_path)\n\n        # now get the appropiate kid\n        config_dict = self.get_config(display_name)\n        if config_dict.kid is None:\n            raise ValueError(\"The kid is not set in the backend configuration.\")\n\n        # create the filter for the document with display_name that is equal to display_name\n        document_to_find = {\"kid\": config_dict.kid}\n        public_jwk_dict = collection.find_one(document_to_find)\n\n        if not public_jwk_dict:\n            raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n        public_jwk_dict.pop(\"_id\")\n        return JWK(**public_jwk_dict)\n\n    def _delete_public_key(self, kid: str) -&gt; bool:\n        \"\"\"\n        Delete a public key from the storage. This is only intended for test purposes.\n\n        Args:\n            kid: The key id of the public key\n\n        Raises:\n            FileNotFoundError: If the public key does not exist.\n\n        Returns:\n            Success if the file was deleted successfully\n        \"\"\"\n        document_to_find = {\"kid\": kid}\n        # get the database on which we work\n        _, collection = self._get_database_and_collection(self.pks_path)\n\n        result_found = collection.find_one(document_to_find)\n        if result_found is None:\n            raise FileNotFoundError(f\"The public key with kid {kid} does not exist\")\n        self.delete(self.pks_path, str(result_found[\"_id\"]))\n        return True\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict | None,\n        status_msg_dict: StatusMsgDict,\n        job_id: str,\n        display_name: DisplayNameStr,\n        private_jwk: Optional[JWK] = None,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        The function checks if the reported status of the job has changed to DONE. If so, it will create\n        a result json file and move the job json file to the finished folder. It will also update the\n        status json file.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            display_name: the name of the backend\n            private_jwk: the private JWK to sign the result with\n\n        Returns:\n            None\n\n        Raises:\n\n        \"\"\"\n\n        job_json_start_dir = self.running_path\n        # check if the job is done or had an error\n        if status_msg_dict.status == \"DONE\":\n            # test if the result dict is None\n            if result_dict is None:\n                raise ValueError(\n                    \"The 'result_dict' argument cannot be None if the job is done.\"\n                )\n            result_uploaded = self.upload_result(\n                result_dict, display_name, job_id, private_jwk\n            )\n            if not result_uploaded:\n                raise ValueError(\"The result was not uploaded successfully.\")\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = f\"{self.finished_path}/{display_name}\"\n            self.move(job_json_start_dir, job_finished_json_dir, job_id)\n\n        elif status_msg_dict.status == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = self.deleted_path\n            self.move(job_json_start_dir, deleted_json_dir, job_id)\n\n        # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n        # and create the status json file\n        status_json_dir = self.get_device_status_path(display_name)\n\n        try:\n            self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n        except FileNotFoundError:\n            logging.warning(\n                \"The status file was missing for %s with job_id %s was missing.\",\n                display_name,\n                job_id,\n            )\n            self.upload_status(display_name, \"\", job_id)\n            self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of documents in the collection of all the queued jobs.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n        _, collection = self._get_database_and_collection(storage_path)\n\n        # now get the id of all the documents in the collection\n        results = collection.find({}, {\"_id\": 1})\n        file_list = []\n        for result in results:\n            file_list.append(str(result[\"_id\"]))\n        return file_list\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.create_job_id","title":"<code>create_job_id(display_name, username)</code>","text":"<p>Create a job id for the job.</p> <p>Returns:</p> Type Description <code>str</code> <p>The job id</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def create_job_id(self, display_name: DisplayNameStr, username: str) -&gt; str:\n    \"\"\"\n    Create a job id for the job.\n\n    Returns:\n        The job id\n    \"\"\"\n    return (uuid.uuid4().hex)[:24]\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_attribute_path","title":"<code>get_attribute_path(attribute_name, display_name=None, job_id=None)</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <code>attribute_name</code> <code>str</code> <p>The name of the attribute</p> required <code>job_id</code> <code>Optional[str]</code> <p>The job_id of the job</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_attribute_path(\n    self,\n    attribute_name: str,\n    display_name: Optional[DisplayNameStr] = None,\n    job_id: Optional[str] = None,\n) -&gt; str:\n    \"\"\"\n    Get the path to the results of the device.\n\n    Args:\n        display_name: The name of the backend\n        attribute_name: The name of the attribute\n        job_id: The job_id of the job\n\n    Returns:\n        The path to the results of the device.\n    \"\"\"\n\n    match attribute_name:\n        case \"running\":\n            path = self.running_path\n        case \"queue\":\n            path = f\"{self.queue_path}/{display_name}\"\n        case _:\n            raise ValueError(f\"The attribute name {attribute_name} is not valid.\")\n    return path\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_backends","title":"<code>get_backends()</code>","text":"<p>Get a list of all the backends that the provider offers.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef get_backends(self) -&gt; list[DisplayNameStr]:\n    \"\"\"\n    Get a list of all the backends that the provider offers.\n    \"\"\"\n\n    # get the collection on which we work\n    _, config_collection = self._get_database_and_collection(self.configs_path)\n\n    # get all the documents in the collection configs and save the disply_name in a list\n    backend_names: list[DisplayNameStr] = []\n    for config_dict in config_collection.find():\n        config_dict.pop(\"_id\")\n        expected_keys_for_jws = {\"header\", \"payload\", \"signature\"}\n        if set(config_dict.keys()) == expected_keys_for_jws:\n            backend_names.append(config_dict[\"payload\"][\"display_name\"])\n        else:\n            backend_names.append(config_dict[\"display_name\"])\n    return backend_names\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_config","title":"<code>get_config(display_name)</code>","text":"<p>The function that downloads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p> <p>Returns:</p> Type Description <code>BackendConfigSchemaIn</code> <p>The configuration of the backend in complete form.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>@validate_active\ndef get_config(self, display_name: DisplayNameStr) -&gt; BackendConfigSchemaIn:\n    \"\"\"\n    The function that downloads the spooler configuration to the storage.\n\n    Args:\n        display_name : The name of the backend\n\n    Raises:\n        FileNotFoundError: If the backend does not exist\n\n    Returns:\n        The configuration of the backend in complete form.\n    \"\"\"\n    # get the collection on which we work\n    _, config_collection = self._get_database_and_collection(self.configs_path)\n\n    # create the filter for the document with display_name that is equal to display_name\n    document_to_find = {\"display_name\": display_name}\n    backend_config_dict = config_collection.find_one(document_to_find)\n\n    signed_document_to_find = {\"payload.display_name\": display_name}\n    signed_backend_config_dict = config_collection.find_one(signed_document_to_find)\n\n    # work with the unsigned backend\n    if backend_config_dict:\n        backend_config_dict.pop(\"_id\")\n        return BackendConfigSchemaIn(**backend_config_dict)\n\n    # work with the signed backend this is working normally due to the mongodb API, but to make\n    # mypy happy, we have to check if the signed_backend_config_dict is not None\n    elif signed_backend_config_dict:\n        payload = signed_backend_config_dict[\"payload\"]\n        return BackendConfigSchemaIn(**payload)\n\n    raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_config_id","title":"<code>get_config_id(display_name)</code>","text":"<p>Get the name of the config json file.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the config json file.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_config_id(self, display_name: DisplayNameStr) -&gt; str:\n    \"\"\"\n    Get the name of the config json file.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The name of the config json file.\n    \"\"\"\n    raise NotImplementedError(\"This function is not implemented.\")\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_configs_path","title":"<code>get_configs_path(display_name=None)</code>","text":"<p>Get the path to the configs.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>Optional[DisplayNameStr]</code> <p>The name of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the configs.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_configs_path(self, display_name: Optional[DisplayNameStr] = None) -&gt; str:\n    \"\"\"\n    Get the path to the configs.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The path to the configs.\n    \"\"\"\n    return self.configs_path\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_device_results_path","title":"<code>get_device_results_path(display_name, job_id)</code>","text":"<p>Get the path to the results of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the results of the device.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_device_results_path(self, display_name: DisplayNameStr, job_id: str) -&gt; str:\n    \"\"\"\n    Get the path to the results of the device.\n\n    Args:\n        display_name: The name of the backend\n        job_id: The job_id of the job\n\n    Returns:\n        The path to the results of the device.\n    \"\"\"\n    return f\"{self.results_path}/{display_name}\"\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_device_status_path","title":"<code>get_device_status_path(display_name, username=None)</code>","text":"<p>Get the path to the status of the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>DisplayNameStr</code> <p>The name of the backend</p> required <code>username</code> <code>Optional[str]</code> <p>The username of the user</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the status of the device.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_device_status_path(\n    self, display_name: DisplayNameStr, username: Optional[str] = None\n) -&gt; str:\n    \"\"\"\n    Get the path to the status of the device.\n\n    Args:\n        display_name: The name of the backend\n        username: The username of the user\n\n    Returns:\n        The path to the status of the device.\n    \"\"\"\n    return f\"{self.status_path}/{display_name}\"\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of documents in the collection of all the queued jobs.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of documents in the collection of all the queued jobs.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n\n    _, collection = self._get_database_and_collection(storage_path)\n\n    # now get the id of all the documents in the collection\n    results = collection.find({}, {\"_id\": 1})\n    file_list = []\n    for result in results:\n        file_list.append(str(result[\"_id\"]))\n    return file_list\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_internal_job_id","title":"<code>get_internal_job_id(job_id)</code>","text":"<p>Get the internal job id from the job_id.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The internal job id</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_internal_job_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the internal job id from the job_id.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The internal job id\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_public_key","title":"<code>get_public_key(display_name)</code>","text":"<p>The function that gets the spooler public JWK for the device.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Name Type Description <code>JWk</code> <code>JWK</code> <p>The public JWK object</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_public_key(self, display_name: DisplayNameStr) -&gt; JWK:\n    \"\"\"\n    The function that gets the spooler public JWK for the device.\n\n    Args:\n        display_name : The name of the backend\n\n    Returns:\n        JWk : The public JWK object\n    \"\"\"\n\n    # get the database on which we work\n    _, collection = self._get_database_and_collection(self.pks_path)\n\n    # now get the appropiate kid\n    config_dict = self.get_config(display_name)\n    if config_dict.kid is None:\n        raise ValueError(\"The kid is not set in the backend configuration.\")\n\n    # create the filter for the document with display_name that is equal to display_name\n    document_to_find = {\"kid\": config_dict.kid}\n    public_jwk_dict = collection.find_one(document_to_find)\n\n    if not public_jwk_dict:\n        raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n    public_jwk_dict.pop(\"_id\")\n    return JWK(**public_jwk_dict)\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_result_id","title":"<code>get_result_id(job_id)</code>","text":"<p>Get the name of the result json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the result json file.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_result_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the name of the result json file.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The name of the result json file.\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.get_status_id","title":"<code>get_status_id(job_id)</code>","text":"<p>Get the name of the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The job_id of the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the status json file.</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def get_status_id(self, job_id: str) -&gt; str:\n    \"\"\"\n    Get the name of the status json file.\n\n    Args:\n        job_id: The job_id of the job\n\n    Returns:\n        The name of the status json file.\n    \"\"\"\n    return job_id\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.update_config","title":"<code>update_config(config_dict, display_name, private_jwk=None)</code>","text":"<p>The function that updates the spooler configuration on the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private key of the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def update_config(\n    self,\n    config_dict: BackendConfigSchemaIn,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    The function that updates the spooler configuration on the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        display_name : The name of the backend\n        private_jwk: The private key of the backend\n\n    Returns:\n        None\n    \"\"\"\n\n    config_dict = self._verify_config(config_dict, display_name)\n\n    _, collection = self._get_database_and_collection(self.configs_path)\n\n    # now make sure that we add the timezone as we open the file\n    collection_with_tz = collection.with_options(\n        codec_options=CodecOptions(tz_aware=True, tzinfo=timezone.utc)\n    )\n    # first we have to check if the device already exists in the database\n    document_to_find = {\"display_name\": display_name}\n    result_found = collection_with_tz.find_one(document_to_find)\n\n    signed_document_to_find = {\"payload.display_name\": display_name}\n    signed_backend_config_dict = collection_with_tz.find_one(\n        signed_document_to_find\n    )\n\n    if result_found:\n        old_config_jws = result_found\n        job_id = result_found[\"_id\"]\n    elif signed_backend_config_dict:\n        old_config_jws = signed_backend_config_dict\n        job_id = signed_backend_config_dict[\"_id\"]\n        old_config_jws.pop(\"_id\")\n    else:\n        raise FileNotFoundError(\n            (\n                f\"The config for {display_name} does not exist and should not be updated.\"\n                \"Use the upload_config method instead.\"\n            )\n        )\n    upload_dict = self._format_update_config(\n        old_config_jws, config_dict, private_jwk\n    )\n\n    self.update(\n        content_dict=upload_dict,\n        storage_path=self.configs_path,\n        job_id=job_id,\n    )\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, display_name, private_jwk=None)</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>The function checks if the reported status of the job has changed to DONE. If so, it will create a result json file and move the job json file to the finished folder. It will also update the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict | None</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>display_name</code> <code>DisplayNameStr</code> <p>the name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>the private JWK to sign the result with</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict | None,\n    status_msg_dict: StatusMsgDict,\n    job_id: str,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    The function checks if the reported status of the job has changed to DONE. If so, it will create\n    a result json file and move the job json file to the finished folder. It will also update the\n    status json file.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        display_name: the name of the backend\n        private_jwk: the private JWK to sign the result with\n\n    Returns:\n        None\n\n    Raises:\n\n    \"\"\"\n\n    job_json_start_dir = self.running_path\n    # check if the job is done or had an error\n    if status_msg_dict.status == \"DONE\":\n        # test if the result dict is None\n        if result_dict is None:\n            raise ValueError(\n                \"The 'result_dict' argument cannot be None if the job is done.\"\n            )\n        result_uploaded = self.upload_result(\n            result_dict, display_name, job_id, private_jwk\n        )\n        if not result_uploaded:\n            raise ValueError(\"The result was not uploaded successfully.\")\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = f\"{self.finished_path}/{display_name}\"\n        self.move(job_json_start_dir, job_finished_json_dir, job_id)\n\n    elif status_msg_dict.status == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = self.deleted_path\n        self.move(job_json_start_dir, deleted_json_dir, job_id)\n\n    # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n    # and create the status json file\n    status_json_dir = self.get_device_status_path(display_name)\n\n    try:\n        self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n    except FileNotFoundError:\n        logging.warning(\n            \"The status file was missing for %s with job_id %s was missing.\",\n            display_name,\n            job_id,\n        )\n        self.upload_status(display_name, \"\", job_id)\n        self.update(status_msg_dict.model_dump(), status_json_dir, job_id)\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.upload_config","title":"<code>upload_config(config_dict, display_name, private_jwk=None)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>display_name</code> <p>The name of the backend</p> required <code>private_jwk</code> <code>Optional[JWK]</code> <p>The private JWK to sign the configuration with</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def upload_config(\n    self,\n    config_dict: BackendConfigSchemaIn,\n    display_name: DisplayNameStr,\n    private_jwk: Optional[JWK] = None,\n) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        display_name : The name of the backend\n        private_jwk: The private JWK to sign the configuration with\n\n    Returns:\n        None\n    \"\"\"\n    config_dict = self._verify_config(config_dict, display_name)\n\n    # first we have to check if the device already exists in the database\n\n    document_to_find = {\"display_name\": display_name}\n\n    # get the collection on which we work\n    _, collection = self._get_database_and_collection(self.configs_path)\n\n    document_to_find = {\"display_name\": display_name}\n    result_found = collection.find_one(document_to_find)\n    if result_found:\n        raise FileExistsError(\n            f\"The configuration for {display_name} already exists and should not be overwritten.\"\n        )\n\n    # now also look for signed configurations\n    signed_document_to_find = {\"payload.display_name\": display_name}\n    result_found = collection.find_one(signed_document_to_find)\n    if result_found:\n        raise FileExistsError(\n            f\"The configuration for {display_name} already exists and should not be overwritten.\"\n        )\n\n    upload_dict = self._format_config_dict(config_dict, private_jwk)\n    config_id = uuid.uuid4().hex[:24]\n    self.upload(upload_dict, self.configs_path, config_id)\n</code></pre>"},{"location":"storage_providers/storage_providers/#src.sqooler.storage_providers.mongodb.MongodbProviderExtended.upload_public_key","title":"<code>upload_public_key(public_jwk, display_name)</code>","text":"<p>The function that uploads the spooler public JWK to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>public_jwk</code> <code>JWK</code> <p>The JWK that contains the public key</p> required <code>display_name</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers/mongodb.py</code> <pre><code>def upload_public_key(self, public_jwk: JWK, display_name: DisplayNameStr) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler public JWK to the storage.\n\n    Args:\n        public_jwk: The JWK that contains the public key\n        display_name : The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # first make sure that the public key is intended for verification\n    if not public_jwk.key_ops == \"verify\":\n        raise ValueError(\"The key is not intended for verification\")\n\n    # make sure that the key does not contain a private key\n    if public_jwk.d is not None:\n        raise ValueError(\"The key contains a private key\")\n\n    # make sure that the key has the correct kid\n    config_dict = self.get_config(display_name)\n    if public_jwk.kid != config_dict.kid:\n        raise ValueError(\"The key does not have the correct kid.\")\n\n    _, collection = self._get_database_and_collection(self.pks_path)\n\n    # first we have to check if the device already exists in the database\n    document_to_find = {\"kid\": config_dict.kid}\n\n    result_found = collection.find_one(document_to_find)\n    if result_found:\n        # update the file\n        self.update(\n            content_dict=public_jwk.model_dump(),\n            storage_path=self.pks_path,\n            job_id=result_found[\"_id\"],\n        )\n        return\n\n    # if the device does not exist, we have to create it\n    config_id = uuid.uuid4().hex[:24]\n    self.upload(public_jwk.model_dump(), self.pks_path, config_id)\n</code></pre>"}]}