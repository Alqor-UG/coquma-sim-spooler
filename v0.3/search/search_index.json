{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Sqooler","text":"<p>Sqooler is a pydantic based SDK that allows you to receive jobs for quantum quantum hardware in a reliable fashion. It is therefore meant for the developer and quantum hardware owner who wants to provide a cloud access to their code in a secure fashion. A few important features:</p> <ul> <li>The PC never has to grant access privileges to any outside contributor.</li> <li>The remote jobs are heavily controlled through pydantic.</li> <li>Simple setup through templates.</li> </ul>"},{"location":"#our-related-projects","title":"Our related projects","text":"<ul> <li><code>sqooler</code> - SDK to provide cloud access to your hardware or simulator.</li> <li><code>labscript-qc-example</code> - Template to provide cloud access to your labscript code.</li> <li><code>sqooler-example</code> - Template to provide cloud access to your simulator.</li> <li><code>qlued</code> - Webkit for user management etc.</li> </ul>"},{"location":"#related-projects","title":"Related projects","text":"<ul> <li><code>labscript</code> - The labscript suite is a powerful and extensible framework for experiment composition, control, execution, and analysis.</li> <li><code>qiskit-cold-atom</code> - qiskit code to access cold atoms as an end user.</li> </ul>"},{"location":"contributing/","title":"Welcome to the sqooler contributing guide","text":"<p>Thank you for investing your time in potentially contributing to our project! Any contribution you make will be reflected on the repository of the open source project sqooler .</p> <p>You can contribute to the sqooler  content and site in several ways, which we will present you below. </p>"},{"location":"contributing/#discussions","title":"Discussions","text":"<p>Discussions are where we have conversations.</p> <p>If you'd like help troubleshooting a sqooler PR you're working on, have a great new idea, or want to share something amazing you've learned about quantum hardware access, join us in discussions.</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Issues are used to track tasks that contributors can help with. </p> <p>If you've found something in the content or the code that should be updated, search open issues to see if someone else has reported the same thing. If it's something new, open an issue here. We'll use the issue to have a conversation about the problem you want to fix.</p>"},{"location":"contributing/#create-a-new-issue","title":"Create a new issue","text":"<p>If you spot a problem with the docs, search if an issue already exists. If a related issue doesn't exist, you can open a new issue.</p>"},{"location":"contributing/#solve-an-issue","title":"Solve an issue","text":"<p>Scan through our existing issues to find one that interests you. You can narrow down the search using labels as filters. See Labels for more information. As a general rule, we don\u2019t assign issues to anyone. If you find an issue to work on, you are welcome to open a PR with a fix.</p>"},{"location":"contributing/#make-changes-in-the-github-ui","title":"Make Changes in the github UI","text":"<p>Click Make a contribution at the top of any page to make small changes such as a typo, sentence fix, or a broken link. This takes you to the .md file where you can make your changes and create a pull request for a review.</p>"},{"location":"contributing/#commit-your-update","title":"Commit your update","text":"<p>Commit the changes once you are happy with them. Don't forget to self-review to speed up the review process .</p>"},{"location":"contributing/#pull-requests","title":"Pull requests","text":"<p>A pull request is a way to suggest changes in our repository. When we merge those changes, they should be deployed to the live site almost immediately. </p> <p>So when you're finished with the changes, create a pull request, also known as a PR.</p> <ul> <li>Fill the description so that we can review your PR. This template helps reviewers understand your changes as well as the purpose of your pull request. </li> <li>Don't forget to link PR to issue if you are solving one.</li> <li>Enable the checkbox to allow maintainer edits so the branch can be updated for a merge. Once you submit your PR, a sqooler team member will review your proposal. We may ask questions or request additional information.</li> <li>We may ask for changes to be made before a PR can be merged, either using suggested changes or pull request comments. You can apply suggested changes directly through the UI. You can make any other changes in your fork, then commit them to your branch.</li> <li>As you update your PR and apply changes, mark each conversation as resolved.</li> <li>If you run into any merge issues, checkout this git tutorial to help you resolve merge conflicts and other issues.</li> </ul>"},{"location":"contributing/#your-pr-is-merged","title":"Your PR is merged!","text":"<p>Congratulations  The sqooler team thanks you . </p> <p>Once your PR is merged, your contributions will be publicly visible on the sqooler repo. </p> <p>Now you are part of the sqooler community. Thank you for your contributions! We look forward to working with you to make our project even better.</p>"},{"location":"contributing/#attribution","title":"Attribution","text":"<p>These contribution guidelines are adapted from the contribution guidelines for Github docs, available online on the github.</p>"},{"location":"schemes/","title":"API documentation of schemes","text":"<p>The module that contains common logic for schemes, validation etc. There is no obvious need, why this code should be touch in a new back-end.</p>"},{"location":"schemes/#src.sqooler.schemes.BackendConfigSchemaIn","title":"<code>BackendConfigSchemaIn</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The schema send in to detail the configuration of the backend. This is uploaded to the storage provider.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class BackendConfigSchemaIn(BaseModel):\n    \"\"\"\n    The schema send in to detail the configuration of the backend.\n    This is uploaded to the storage provider.\n    \"\"\"\n\n    description: str = Field(description=\"A description for the backend\")\n    version: str = Field(description=\"The backend version in the form X.Y.Z\")\n    display_name: Optional[str] = Field(\n        description=\" Alternate name field for the backend\"\n    )\n    cold_atom_type: str = Field(\n        description=\"The type of cold atom system that is simulated. Non standard qiskit field.\"\n    )\n    gates: list = Field(\n        description=\"The list of GateConfig objects for the basis gates of the backend\"\n    )\n    max_experiments: int = Field(\n        description=\"The maximum number of experiments per job\"\n    )\n    max_shots: int = Field(\n        description=\"The maximum number of shots allowed on the backend\"\n    )\n    simulator: bool = Field(description=\"True if the backend is a simulator\")\n    supported_instructions: list[str] = Field(\n        description=\"Instructions supported by the backend.\"\n    )\n    num_wires: int = Field(description=\"The number of qubits / wires for the backend\")\n    wire_order: str = Field(\n        description=\"The wire order of the backend. Either linear or interleaved.\"\n    )\n    num_species: int = Field(description=\"The number of species in the system.\")\n    operational: bool = Field(description=\"True if the backend is operational\")\n    pending_jobs: Optional[int] = Field(\n        default=None, description=\"The number of pending jobs on the backend\"\n    )\n    status_msg: Optional[str] = Field(\n        default=None, description=\"The status message for the backend\"\n    )\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.BackendConfigSchemaOut","title":"<code>BackendConfigSchemaOut</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The schema send out to detail the configuration of the backend. We follow the conventions of the qiskit configuration dictionary here.</p> <p>Will becomes compatible with qiskit.providers.models.BackendConfiguration</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class BackendConfigSchemaOut(BaseModel):\n    \"\"\"\n    The schema send out to detail the configuration of the backend. We follow the\n    conventions of the qiskit configuration dictionary here.\n\n    Will becomes compatible with qiskit.providers.models.BackendConfiguration\n    \"\"\"\n\n    description: str = Field(description=\"A description for the backend\")\n    display_name: str = Field(description=\" Alternate name field for the backend\")\n    conditional: bool = Field(\n        default=False, description=\"True if the backend supports conditional operations\"\n    )\n    coupling_map: str = Field(\n        default=\"linear\", description=\"The coupling map for the device\"\n    )\n    dynamic_reprate_enabled: bool = Field(\n        default=False,\n        description=\"whether delay between programs can be set dynamically \",\n    )\n    local: bool = Field(\n        default=False, description=\"True if the backend is local or False if remote\"\n    )\n    memory: bool = Field(default=False, description=\"True if backend supports memory\")\n    open_pulse: bool = Field(default=False, description=\"True if backend is OpenPulse\")\n    backend_version: str = Field(description=\"The backend version in the form X.Y.Z\")\n    n_qubits: int = Field(description=\"The number of qubits / wires for the backend\")\n    backend_name: str = Field(description=\"The backend name\")\n    basis_gates: list[str] = Field(\n        description=\"The list of strings for the basis gates of the backends\"\n    )\n    max_experiments: int = Field(\n        description=\"The maximum number of experiments per job\"\n    )\n    max_shots: int = Field(\n        description=\"The maximum number of shots allowed on the backend\"\n    )\n    simulator: bool = Field(description=\"True if the backend is a simulator\")\n    gates: list = Field(\n        description=\"The list of GateConfig objects for the basis gates of the backend\"\n    )\n    supported_instructions: list[str] = Field(\n        description=\"Instructions supported by the backend.\"\n    )\n    cold_atom_type: str = Field(\n        description=\"The type of cold atom system that is simulated. Non standard qiskit field.\"\n    )\n    wire_order: str = Field(\n        description=(\n            \"The wire order of the backend. Either linear or interleaved.\"\n            \" Non standard qiskit field.\"\n        )\n    )\n    num_species: int = Field(\n        description=\"The number of species in the system. Non standard qiskit field.\"\n    )\n    url: Optional[str] = Field(default=None, description=\"The url of the backend\")\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.BackendStatusSchemaOut","title":"<code>BackendStatusSchemaOut</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The schema for the status of a backend. Follows the conventions of the <code>qiskit.providers.models.BackendStatus</code>.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class BackendStatusSchemaOut(BaseModel):\n    \"\"\"\n    The schema for the status of a backend. Follows the conventions of the\n    `qiskit.providers.models.BackendStatus`.\n    \"\"\"\n\n    backend_name: str = Field(description=\"The name of the backend\")\n    backend_version: str = Field(\n        description=\"The version of the backend. Of the form X.Y.Z\"\n    )\n    operational: bool = Field(description=\"True if the backend is operational\")\n    pending_jobs: int = Field(description=\"The number of pending jobs on the backend\")\n    status_msg: str = Field(description=\"The status message for the backend\")\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.DropboxLoginInformation","title":"<code>DropboxLoginInformation</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The login information for the dropbox</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class DropboxLoginInformation(BaseModel):\n    \"\"\"\n    The login information for the dropbox\n    \"\"\"\n\n    app_key: str\n    app_secret: str\n    refresh_token: str\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.ExperimentDict","title":"<code>ExperimentDict</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>A class that defines the structure of the experiments.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class ExperimentDict(BaseModel):\n    \"\"\"\n    A class that defines the structure of the experiments.\n    \"\"\"\n\n    header: dict = Field(description=\"Contains centralized information about the job.\")\n    shots: int = Field(description=\"number of shots in the experiment.\")\n    success: bool = Field(description=\"True if experiment ran successfully.\")\n    data: dict = Field(description=\"dictionary of results for the experiment.\")\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.GateDict","title":"<code>GateDict</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The most basic class for a gate as it is communicated in the json API.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class GateDict(BaseModel):\n    \"\"\"\n    The most basic class for a gate as it is communicated in\n    the json API.\n    \"\"\"\n\n    name: str = Field(description=\"The name of the gate\")\n    wires: list[int] = Field(description=\"The wires on which the gate acts\")\n    params: list[float] = Field(description=\"The parameters of the gate\")\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.GateInstruction","title":"<code>GateInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The basic class for all the gate intructions of a backend. Any gate has to have the following attributes.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class GateInstruction(BaseModel):\n    \"\"\"\n    The basic class for all the gate intructions of a backend.\n    Any gate has to have the following attributes.\n    \"\"\"\n\n    name: str\n    parameters: str\n    description: str\n    coupling_map: list\n    qasm_def: str = \"{}\"\n    is_gate: bool = True\n\n    @classmethod\n    def config_dict(cls) -&gt; dict:\n        \"\"\"\n        Give back the properties of the instruction such as needed for the server.\n        \"\"\"\n        return {\n            \"coupling_map\": cls.model_fields[\"coupling_map\"].default,\n            \"description\": cls.model_fields[\"description\"].default,\n            \"name\": cls.model_fields[\"name\"].default,\n            \"parameters\": [cls.model_fields[\"parameters\"].default],\n            \"qasm_def\": cls.model_fields[\"qasm_def\"].default,\n        }\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.GateInstruction.config_dict","title":"<code>config_dict()</code>  <code>classmethod</code>","text":"<p>Give back the properties of the instruction such as needed for the server.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>@classmethod\ndef config_dict(cls) -&gt; dict:\n    \"\"\"\n    Give back the properties of the instruction such as needed for the server.\n    \"\"\"\n    return {\n        \"coupling_map\": cls.model_fields[\"coupling_map\"].default,\n        \"description\": cls.model_fields[\"description\"].default,\n        \"name\": cls.model_fields[\"name\"].default,\n        \"parameters\": [cls.model_fields[\"parameters\"].default],\n        \"qasm_def\": cls.model_fields[\"qasm_def\"].default,\n    }\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.LabscriptSpooler","title":"<code>LabscriptSpooler</code>","text":"<p>             Bases: <code>Spooler</code></p> <p>A specialized spooler class that allows us to execute jobs in labscript directly. The main changes are that we need to add the job in a different way and connect it to a  <code>runmanager.remoeClient</code></p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class LabscriptSpooler(Spooler):\n    \"\"\"\n    A specialized spooler class that allows us to execute jobs in labscript directly.\n    The main changes are that we need to add the job in a different way and connect it to a\n     `runmanager.remoeClient`\n    \"\"\"\n\n    def __init__(\n        self,\n        ins_schema_dict: dict,\n        device_config: Type[BaseModel],\n        n_wires: int,\n        remote_client: Any,  # it would be really nice to fix this type\n        description: str = \"\",\n        n_max_shots: int = 1000,\n        version: str = \"0.0.1\",\n        cold_atom_type: str = \"spin\",\n        n_max_experiments: int = 15,\n        wire_order: str = \"interleaved\",\n        num_species: int = 1,\n        operational: bool = True,\n    ):\n        \"\"\"\n        The constructor of the class.\n        \"\"\"\n        super().__init__(\n            ins_schema_dict,\n            device_config,\n            n_wires,\n            description,\n            n_max_shots,\n            version,\n            cold_atom_type,\n            n_max_experiments,\n            wire_order,\n            num_species,\n            operational,\n        )\n        self.remote_client = remote_client\n\n    def add_job(\n        self, json_dict: dict, status_msg_dict: StatusMsgDict\n    ) -&gt; tuple[ResultDict, StatusMsgDict]:\n        \"\"\"\n        The function that translates the json with the instructions into some circuit\n        and executes it. It performs several checks for the job to see if it is properly\n        working. If things are fine the job gets added the list of things that should be\n        executed.\n\n        Args:\n            json_dict: The job dictonary of all the instructions.\n            status_msg_dict: the status dictionary of the job we are treating.\n        \"\"\"\n        job_id = status_msg_dict.job_id\n\n        result_draft: dict = {\n            \"display_name\": self.display_name,\n            \"backend_version\": self.version,\n            \"job_id\": job_id,\n            \"qobj_id\": None,\n            \"success\": True,\n            \"status\": \"finished\",\n            \"header\": {},\n            \"results\": [],\n        }\n        err_msg, json_is_fine = self.check_json_dict(json_dict)\n        if json_is_fine:\n            # check_hilbert_space_dimension\n            dim_err_msg, dim_ok = self.check_dimension(json_dict)\n            if dim_ok:\n                for exp in json_dict:\n                    exp_dict = {exp: json_dict[exp]}\n                    # prepare the shots folder\n                    self.remote_client.reset_shot_output_folder()\n                    self._modify_shot_output_folder(job_id + \"/\" + str(exp))\n\n                    # Here we generate the ciruit\n                    result_draft[\"results\"].append(self.gen_circuit(exp_dict, job_id))\n\n                status_msg_dict.detail += \"; Passed json sanity check; Compilation done. \\\n                    Shots sent to solver.\"\n                status_msg_dict.status = \"DONE\"\n                result_dict = ResultDict(**result_draft)\n                return result_dict, status_msg_dict\n\n            status_msg_dict.detail += (\n                \";Failed dimensionality test. Too many atoms. File will be deleted. Error message: \"\n                + dim_err_msg\n            )\n            status_msg_dict.error_message += (\n                \";Failed dimensionality test. Too many atoms. File will be deleted. Error message: \"\n                + dim_err_msg\n            )\n            status_msg_dict.status = \"ERROR\"\n\n            result_dict = ResultDict(**result_draft)\n            return result_dict, status_msg_dict\n\n        status_msg_dict.detail += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict.error_message += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict.status = \"ERROR\"\n\n        result_dict = ResultDict(**result_draft)\n        return result_dict, status_msg_dict\n\n    def _modify_shot_output_folder(self, new_dir: str) -&gt; None:\n        \"\"\"\n        I am not sure what this function does.\n\n        Args:\n            new_dir: The new directory under which we save the shots.\n        \"\"\"\n        defaut_shot_folder = str(self.remote_client.get_shot_output_folder())\n        print(f\"Default shot folder: {defaut_shot_folder}\")\n        modified_shot_folder = (defaut_shot_folder.rsplit(\"\\\\\", 1)[0]) + \"/\" + new_dir\n        print(f\"Modified shot folder: {modified_shot_folder}\")\n        self.remote_client.set_shot_output_folder(modified_shot_folder)\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.LabscriptSpooler.__init__","title":"<code>__init__(ins_schema_dict, device_config, n_wires, remote_client, description='', n_max_shots=1000, version='0.0.1', cold_atom_type='spin', n_max_experiments=15, wire_order='interleaved', num_species=1, operational=True)</code>","text":"<p>The constructor of the class.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def __init__(\n    self,\n    ins_schema_dict: dict,\n    device_config: Type[BaseModel],\n    n_wires: int,\n    remote_client: Any,  # it would be really nice to fix this type\n    description: str = \"\",\n    n_max_shots: int = 1000,\n    version: str = \"0.0.1\",\n    cold_atom_type: str = \"spin\",\n    n_max_experiments: int = 15,\n    wire_order: str = \"interleaved\",\n    num_species: int = 1,\n    operational: bool = True,\n):\n    \"\"\"\n    The constructor of the class.\n    \"\"\"\n    super().__init__(\n        ins_schema_dict,\n        device_config,\n        n_wires,\n        description,\n        n_max_shots,\n        version,\n        cold_atom_type,\n        n_max_experiments,\n        wire_order,\n        num_species,\n        operational,\n    )\n    self.remote_client = remote_client\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.LabscriptSpooler.add_job","title":"<code>add_job(json_dict, status_msg_dict)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>The job dictonary of all the instructions.</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the status dictionary of the job we are treating.</p> required Source code in <code>src/sqooler/schemes.py</code> <pre><code>def add_job(\n    self, json_dict: dict, status_msg_dict: StatusMsgDict\n) -&gt; tuple[ResultDict, StatusMsgDict]:\n    \"\"\"\n    The function that translates the json with the instructions into some circuit\n    and executes it. It performs several checks for the job to see if it is properly\n    working. If things are fine the job gets added the list of things that should be\n    executed.\n\n    Args:\n        json_dict: The job dictonary of all the instructions.\n        status_msg_dict: the status dictionary of the job we are treating.\n    \"\"\"\n    job_id = status_msg_dict.job_id\n\n    result_draft: dict = {\n        \"display_name\": self.display_name,\n        \"backend_version\": self.version,\n        \"job_id\": job_id,\n        \"qobj_id\": None,\n        \"success\": True,\n        \"status\": \"finished\",\n        \"header\": {},\n        \"results\": [],\n    }\n    err_msg, json_is_fine = self.check_json_dict(json_dict)\n    if json_is_fine:\n        # check_hilbert_space_dimension\n        dim_err_msg, dim_ok = self.check_dimension(json_dict)\n        if dim_ok:\n            for exp in json_dict:\n                exp_dict = {exp: json_dict[exp]}\n                # prepare the shots folder\n                self.remote_client.reset_shot_output_folder()\n                self._modify_shot_output_folder(job_id + \"/\" + str(exp))\n\n                # Here we generate the ciruit\n                result_draft[\"results\"].append(self.gen_circuit(exp_dict, job_id))\n\n            status_msg_dict.detail += \"; Passed json sanity check; Compilation done. \\\n                Shots sent to solver.\"\n            status_msg_dict.status = \"DONE\"\n            result_dict = ResultDict(**result_draft)\n            return result_dict, status_msg_dict\n\n        status_msg_dict.detail += (\n            \";Failed dimensionality test. Too many atoms. File will be deleted. Error message: \"\n            + dim_err_msg\n        )\n        status_msg_dict.error_message += (\n            \";Failed dimensionality test. Too many atoms. File will be deleted. Error message: \"\n            + dim_err_msg\n        )\n        status_msg_dict.status = \"ERROR\"\n\n        result_dict = ResultDict(**result_draft)\n        return result_dict, status_msg_dict\n\n    status_msg_dict.detail += (\n        \"; Failed json sanity check. File will be deleted. Error message : \"\n        + err_msg\n    )\n    status_msg_dict.error_message += (\n        \"; Failed json sanity check. File will be deleted. Error message : \"\n        + err_msg\n    )\n    status_msg_dict.status = \"ERROR\"\n\n    result_dict = ResultDict(**result_draft)\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.LocalLoginInformation","title":"<code>LocalLoginInformation</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The login information for a local storage provider.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class LocalLoginInformation(BaseModel):\n    \"\"\"\n    The login information for a local storage provider.\n    \"\"\"\n\n    base_path: str = Field(\n        description=\"The base path of the storage provider on your local file system.\"\n    )\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.MongodbLoginInformation","title":"<code>MongodbLoginInformation</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The login information for MongoDB</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class MongodbLoginInformation(BaseModel):\n    \"\"\"\n    The login information for MongoDB\n    \"\"\"\n\n    mongodb_username: str\n    mongodb_password: str\n    mongodb_database_url: str\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.ResultDict","title":"<code>ResultDict</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>A class that defines the structure of results. It is closely related to the qiskit class qiskit.result.Result.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class ResultDict(BaseModel):\n    \"\"\"\n    A class that defines the structure of results. It is closely related to the\n    qiskit class qiskit.result.Result.\n    \"\"\"\n\n    backend_name: Optional[str] = Field(\n        default=None, description=\"The name of the backend\"\n    )\n    display_name: str = Field(description=\"alternate name field for the backend\")\n    backend_version: str = Field(description=\"backend version, in the form X.Y.Z.\")\n    job_id: str = Field(description=\"unique execution id from the backend.\")\n    qobj_id: Optional[str] = Field(default=None, description=\"user-generated Qobj id.\")\n    success: bool = Field(description=\"True if complete input qobj executed correctly.\")\n    status: str = Field(description=\"status of job execution.\")\n    header: dict = Field(description=\"Contains centralized information about the job.\")\n    results: list[ExperimentDict] = Field(\n        description=\"corresponding results for array of experiments of the input qobj\"\n    )\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.Spooler","title":"<code>Spooler</code>","text":"<p>The class for the spooler. So it is not just a scheme, but it also contains some common logic. So it should most likely live in another file at some point.</p> <p>Attributes:</p> Name Type Description <code>ins_schema_dict</code> <p>A dictionary the contains all the allowed instructions for this spooler.</p> <code>device_config</code> <p>A dictionary that some main config params for the experiment.</p> <code>n_wires</code> <p>maximum number of wires for the spooler</p> <code>n_max_shots</code> <p>the maximum number of shots for the spooler</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class Spooler:\n    \"\"\"\n    The class for the spooler. So it is not just a scheme, but it also contains some common logic.\n    So it should most likely live in another file at some point.\n\n    Attributes:\n        ins_schema_dict : A dictionary the contains all the allowed instructions for this spooler.\n        device_config: A dictionary that some main config params for the experiment.\n        n_wires: maximum number of wires for the spooler\n        n_max_shots: the maximum number of shots for the spooler\n\n    \"\"\"\n\n    def __init__(\n        self,\n        ins_schema_dict: dict,\n        device_config: Type[BaseModel],\n        n_wires: int,\n        description: str = \"\",\n        n_max_shots: int = 1000,\n        version: str = \"0.0.1\",\n        cold_atom_type: str = \"spin\",\n        n_max_experiments: int = 15,\n        wire_order: str = \"interleaved\",\n        num_species: int = 1,\n        operational: bool = True,\n    ):\n        \"\"\"\n        The constructor of the class.\n        \"\"\"\n        self.ins_schema_dict = ins_schema_dict\n        self.device_config = device_config\n        self.n_max_shots = n_max_shots\n        self.n_wires = n_wires\n        self.description = description\n        self.version = version\n        self.cold_atom_type = cold_atom_type\n        self.n_max_experiments = n_max_experiments\n        self.wire_order = wire_order\n        self.num_species = num_species\n        self._display_name: str = \"\"\n        self.operational = operational\n\n    def check_experiment(self, exper_dict: dict) -&gt; tuple[str, bool]:\n        \"\"\"\n        Check the validity of the experiment.\n        This has to be implement in each subclass extra.\n\n        Args:\n            exper_dict: The dictionary that contains the logic and should\n                be verified.\n\n        Returns:\n            str: The error message\n            bool: Is the experiment ok ?\n        \"\"\"\n        try:\n            self.device_config(**exper_dict)\n            return \"\", True\n        except ValidationError as err:\n            return str(err), False\n\n    def get_configuration(self) -&gt; BackendConfigSchemaIn:\n        \"\"\"\n        Sends back the configuration dictionary of the spooler.\n        \"\"\"\n        gate_list = []\n        for _, ins_obj in self.ins_schema_dict.items():\n            if \"is_gate\" in ins_obj.model_fields:\n                gate_list.append(ins_obj.config_dict())\n        backend_config_dict = {\n            \"description\": self.description,\n            \"version\": self.version,\n            \"cold_atom_type\": self.cold_atom_type,\n            \"gates\": gate_list,\n            \"max_experiments\": self.n_max_experiments,\n            \"max_shots\": self.n_max_shots,\n            \"simulator\": True,\n            \"supported_instructions\": list(self.ins_schema_dict.keys()),\n            \"num_wires\": self.n_wires,\n            \"wire_order\": self.wire_order,\n            \"num_species\": self.num_species,\n            \"operational\": self.operational,\n            \"display_name\": self.display_name,\n        }\n        return BackendConfigSchemaIn(**backend_config_dict)\n\n    def check_instructions(self, ins_list: list) -&gt; tuple[str, bool]:\n        \"\"\"\n        Check all the instruction to make sure that they are valid and part\n        of the allowed instructions.\n        \"\"\"\n        err_code = \"\"\n        exp_ok = False\n        # first check that we actually have any instructions safed in the ins_schema_dict\n        if len(self.ins_schema_dict) == 0:\n            err_code = \"No instructions allowed. Add instructions to the spooler.\"\n            exp_ok = False\n            return err_code, exp_ok\n\n        for ins in ins_list:\n            try:\n                gate_instr = gate_dict_from_list(ins)\n                # see if the instruction is part of the allowed instructions\n                if gate_instr.name not in self.ins_schema_dict.keys():\n                    err_code = \"Instruction not allowed.\"\n                    exp_ok = False\n                    return err_code, exp_ok\n\n                # now verify that the parameters are ok\n                gate_dict = gate_instr.model_dump()\n                self.ins_schema_dict[gate_instr.name](**gate_dict)\n                exp_ok = True\n            except ValidationError as err:\n                err_code = \"Error in instruction \" + str(err)\n                exp_ok = False\n            if not exp_ok:\n                break\n        return err_code, exp_ok\n\n    def check_dimension(self, json_dict: dict) -&gt; tuple[str, bool]:\n        \"\"\"\n        Make sure that the Hilbert space dimension is not too large.\n\n        It can be implemented in the class that inherits, but it is not necessary.\n        So this is only a placeholder.\n\n        Args:\n            json_dict: the dictonary with the instructions\n\n        Returns:\n            str: the error message\n            bool: is the dimension ok ?\n        \"\"\"\n        # pylint: disable=W0613\n        return \"\", True\n\n    def check_json_dict(self, json_dict: dict) -&gt; tuple[str, bool]:\n        \"\"\"\n        Check if the json file has the appropiate syntax.\n\n        Args:\n            json_dict (dict): the dictonary that we will test.\n\n        Returns:\n            bool: is the expression having the appropiate syntax ?\n        \"\"\"\n        err_code = \"No instructions received.\"\n        exp_ok = False\n        for expr in json_dict:\n            err_code = \"Wrong experiment name or too many experiments\"\n            # Fix this pylint issue whenever you have time, but be careful !\n            # pylint: disable=W0702\n            try:\n                exp_ok = (\n                    expr.startswith(\"experiment_\")\n                    and expr[11:].isdigit()\n                    and (int(expr[11:]) &lt;= self.n_max_experiments)\n                )\n            except:\n                exp_ok = False\n                break\n            if not exp_ok:\n                break\n            # test the structure of the experiment\n            err_code, exp_ok = self.check_experiment(json_dict[expr])\n            if not exp_ok:\n                break\n            # time to check the structure of the instructions\n            ins_list = json_dict[expr][\"instructions\"]\n            err_code, exp_ok = self.check_instructions(ins_list)\n            if not exp_ok:\n                break\n        return err_code.replace(\"\\n\", \"..\"), exp_ok\n\n    @property\n    def display_name(self) -&gt; str:\n        \"\"\"\n        The name of the spooler.\n        \"\"\"\n        return self._display_name\n\n    @display_name.setter\n    def display_name(self, value: str) -&gt; None:\n        if isinstance(value, str):  # Check if the provided value is a string\n            self._display_name = value\n        else:\n            raise ValueError(\"display_name must be a string\")\n\n    @property\n    def gen_circuit(self) -&gt; Callable[[dict, Optional[str]], ExperimentDict]:\n        \"\"\"\n        The function that generates the circuit.\n        It can be basically anything that allows the execution of the circuit.\n\n        Returns:\n            Callable[[dict, str | None], ExperimentDict]: The function that generates the circuit.\n\n        Raises:\n            ValueError: if the gen_circuit is not a callable function\n        \"\"\"\n        if not hasattr(self, \"_gen_circuit\"):\n            raise ValueError(\"gen_circuit must be set\")\n        return self._gen_circuit\n\n    @gen_circuit.setter\n    def gen_circuit(\n        self, value: Callable[[dict, Optional[str]], ExperimentDict]\n    ) -&gt; None:\n        \"\"\"\n        The setter for the gen_circuit function.\n\n        Args:\n            value: The function that generates the circuit.\n        \"\"\"\n        if callable(value):  # Check if the provided value is a callable (function)\n            self._gen_circuit = value\n        else:\n            raise ValueError(\"gen_circuit must be a callable function\")\n\n    def add_job(\n        self, json_dict: dict, status_msg_dict: StatusMsgDict\n    ) -&gt; tuple[ResultDict, StatusMsgDict]:\n        \"\"\"\n        The function that translates the json with the instructions into some circuit and executes it.\n        It performs several checks for the job to see if it is properly working.\n        If things are fine the job gets added the list of things that should be executed.\n\n        Args:\n            json_dict: The job dictonary of all the instructions.\n            status_msg_dict: the status dictionary of the job we are treating.\n\n        Returns:\n            result_dict: The dictionary with the results of the job.\n            status_msg_dict: The status dictionary of the job.\n        \"\"\"\n        job_id = status_msg_dict.job_id\n\n        result_draft: dict = {\n            \"display_name\": self.display_name,\n            \"backend_version\": self.version,\n            \"job_id\": job_id,\n            \"qobj_id\": None,\n            \"success\": True,\n            \"status\": \"finished\",\n            \"header\": {},\n            \"results\": [],\n        }\n        err_msg, json_is_fine = self.check_json_dict(json_dict)\n        if json_is_fine:\n            # check_hilbert_space_dimension\n            dim_err_msg, dim_ok = self.check_dimension(json_dict)\n            if dim_ok:\n                for exp in json_dict:\n                    exp_dict = {exp: json_dict[exp]}\n                    # Here we\n                    try:\n                        # this assumes that we never have more than one argument here.\n                        result_draft[\"results\"].append(self.gen_circuit(exp_dict))  # type: ignore\n                    except ValueError as err:\n                        status_msg_dict.detail += \"; \" + str(err)\n                        status_msg_dict.error_message += \"; \" + str(err)\n                        status_msg_dict.status = \"ERROR\"\n                        result_dict = ResultDict(**result_draft)\n                        return result_dict, status_msg_dict\n                status_msg_dict.detail += \"; Passed json sanity check; Compilation done. \\\n                    Shots sent to solver.\"\n                status_msg_dict.status = \"DONE\"\n                result_dict = ResultDict(**result_draft)\n                return result_dict, status_msg_dict\n\n            status_msg_dict.detail += (\n                \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message : \"\n                + dim_err_msg\n            )\n            status_msg_dict.error_message += (\n                \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message :  \"\n                + dim_err_msg\n            )\n            status_msg_dict.status = \"ERROR\"\n            result_dict = ResultDict(**result_draft)\n            return result_dict, status_msg_dict\n        else:\n            status_msg_dict.detail += (\n                \"; Failed json sanity check. File will be deleted. Error message : \"\n                + err_msg\n            )\n            status_msg_dict.error_message += (\n                \"; Failed json sanity check. File will be deleted. Error message : \"\n                + err_msg\n            )\n            status_msg_dict.status = \"ERROR\"\n\n        result_dict = ResultDict(**result_draft)\n        return result_dict, status_msg_dict\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.Spooler.display_name","title":"<code>display_name: str</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the spooler.</p>"},{"location":"schemes/#src.sqooler.schemes.Spooler.gen_circuit","title":"<code>gen_circuit: Callable[[dict, Optional[str]], ExperimentDict]</code>  <code>property</code> <code>writable</code>","text":"<p>The function that generates the circuit. It can be basically anything that allows the execution of the circuit.</p> <p>Returns:</p> Type Description <code>Callable[[dict, Optional[str]], ExperimentDict]</code> <p>Callable[[dict, str | None], ExperimentDict]: The function that generates the circuit.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the gen_circuit is not a callable function</p>"},{"location":"schemes/#src.sqooler.schemes.Spooler.__init__","title":"<code>__init__(ins_schema_dict, device_config, n_wires, description='', n_max_shots=1000, version='0.0.1', cold_atom_type='spin', n_max_experiments=15, wire_order='interleaved', num_species=1, operational=True)</code>","text":"<p>The constructor of the class.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def __init__(\n    self,\n    ins_schema_dict: dict,\n    device_config: Type[BaseModel],\n    n_wires: int,\n    description: str = \"\",\n    n_max_shots: int = 1000,\n    version: str = \"0.0.1\",\n    cold_atom_type: str = \"spin\",\n    n_max_experiments: int = 15,\n    wire_order: str = \"interleaved\",\n    num_species: int = 1,\n    operational: bool = True,\n):\n    \"\"\"\n    The constructor of the class.\n    \"\"\"\n    self.ins_schema_dict = ins_schema_dict\n    self.device_config = device_config\n    self.n_max_shots = n_max_shots\n    self.n_wires = n_wires\n    self.description = description\n    self.version = version\n    self.cold_atom_type = cold_atom_type\n    self.n_max_experiments = n_max_experiments\n    self.wire_order = wire_order\n    self.num_species = num_species\n    self._display_name: str = \"\"\n    self.operational = operational\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.Spooler.add_job","title":"<code>add_job(json_dict, status_msg_dict)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>The job dictonary of all the instructions.</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the status dictionary of the job we are treating.</p> required <p>Returns:</p> Name Type Description <code>result_dict</code> <code>ResultDict</code> <p>The dictionary with the results of the job.</p> <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>The status dictionary of the job.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def add_job(\n    self, json_dict: dict, status_msg_dict: StatusMsgDict\n) -&gt; tuple[ResultDict, StatusMsgDict]:\n    \"\"\"\n    The function that translates the json with the instructions into some circuit and executes it.\n    It performs several checks for the job to see if it is properly working.\n    If things are fine the job gets added the list of things that should be executed.\n\n    Args:\n        json_dict: The job dictonary of all the instructions.\n        status_msg_dict: the status dictionary of the job we are treating.\n\n    Returns:\n        result_dict: The dictionary with the results of the job.\n        status_msg_dict: The status dictionary of the job.\n    \"\"\"\n    job_id = status_msg_dict.job_id\n\n    result_draft: dict = {\n        \"display_name\": self.display_name,\n        \"backend_version\": self.version,\n        \"job_id\": job_id,\n        \"qobj_id\": None,\n        \"success\": True,\n        \"status\": \"finished\",\n        \"header\": {},\n        \"results\": [],\n    }\n    err_msg, json_is_fine = self.check_json_dict(json_dict)\n    if json_is_fine:\n        # check_hilbert_space_dimension\n        dim_err_msg, dim_ok = self.check_dimension(json_dict)\n        if dim_ok:\n            for exp in json_dict:\n                exp_dict = {exp: json_dict[exp]}\n                # Here we\n                try:\n                    # this assumes that we never have more than one argument here.\n                    result_draft[\"results\"].append(self.gen_circuit(exp_dict))  # type: ignore\n                except ValueError as err:\n                    status_msg_dict.detail += \"; \" + str(err)\n                    status_msg_dict.error_message += \"; \" + str(err)\n                    status_msg_dict.status = \"ERROR\"\n                    result_dict = ResultDict(**result_draft)\n                    return result_dict, status_msg_dict\n            status_msg_dict.detail += \"; Passed json sanity check; Compilation done. \\\n                Shots sent to solver.\"\n            status_msg_dict.status = \"DONE\"\n            result_dict = ResultDict(**result_draft)\n            return result_dict, status_msg_dict\n\n        status_msg_dict.detail += (\n            \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message : \"\n            + dim_err_msg\n        )\n        status_msg_dict.error_message += (\n            \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message :  \"\n            + dim_err_msg\n        )\n        status_msg_dict.status = \"ERROR\"\n        result_dict = ResultDict(**result_draft)\n        return result_dict, status_msg_dict\n    else:\n        status_msg_dict.detail += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict.error_message += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict.status = \"ERROR\"\n\n    result_dict = ResultDict(**result_draft)\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.Spooler.check_dimension","title":"<code>check_dimension(json_dict)</code>","text":"<p>Make sure that the Hilbert space dimension is not too large.</p> <p>It can be implemented in the class that inherits, but it is not necessary. So this is only a placeholder.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the dictonary with the instructions</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the error message</p> <code>bool</code> <code>bool</code> <p>is the dimension ok ?</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def check_dimension(self, json_dict: dict) -&gt; tuple[str, bool]:\n    \"\"\"\n    Make sure that the Hilbert space dimension is not too large.\n\n    It can be implemented in the class that inherits, but it is not necessary.\n    So this is only a placeholder.\n\n    Args:\n        json_dict: the dictonary with the instructions\n\n    Returns:\n        str: the error message\n        bool: is the dimension ok ?\n    \"\"\"\n    # pylint: disable=W0613\n    return \"\", True\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.Spooler.check_experiment","title":"<code>check_experiment(exper_dict)</code>","text":"<p>Check the validity of the experiment. This has to be implement in each subclass extra.</p> <p>Parameters:</p> Name Type Description Default <code>exper_dict</code> <code>dict</code> <p>The dictionary that contains the logic and should be verified.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The error message</p> <code>bool</code> <code>bool</code> <p>Is the experiment ok ?</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def check_experiment(self, exper_dict: dict) -&gt; tuple[str, bool]:\n    \"\"\"\n    Check the validity of the experiment.\n    This has to be implement in each subclass extra.\n\n    Args:\n        exper_dict: The dictionary that contains the logic and should\n            be verified.\n\n    Returns:\n        str: The error message\n        bool: Is the experiment ok ?\n    \"\"\"\n    try:\n        self.device_config(**exper_dict)\n        return \"\", True\n    except ValidationError as err:\n        return str(err), False\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.Spooler.check_instructions","title":"<code>check_instructions(ins_list)</code>","text":"<p>Check all the instruction to make sure that they are valid and part of the allowed instructions.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def check_instructions(self, ins_list: list) -&gt; tuple[str, bool]:\n    \"\"\"\n    Check all the instruction to make sure that they are valid and part\n    of the allowed instructions.\n    \"\"\"\n    err_code = \"\"\n    exp_ok = False\n    # first check that we actually have any instructions safed in the ins_schema_dict\n    if len(self.ins_schema_dict) == 0:\n        err_code = \"No instructions allowed. Add instructions to the spooler.\"\n        exp_ok = False\n        return err_code, exp_ok\n\n    for ins in ins_list:\n        try:\n            gate_instr = gate_dict_from_list(ins)\n            # see if the instruction is part of the allowed instructions\n            if gate_instr.name not in self.ins_schema_dict.keys():\n                err_code = \"Instruction not allowed.\"\n                exp_ok = False\n                return err_code, exp_ok\n\n            # now verify that the parameters are ok\n            gate_dict = gate_instr.model_dump()\n            self.ins_schema_dict[gate_instr.name](**gate_dict)\n            exp_ok = True\n        except ValidationError as err:\n            err_code = \"Error in instruction \" + str(err)\n            exp_ok = False\n        if not exp_ok:\n            break\n    return err_code, exp_ok\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.Spooler.check_json_dict","title":"<code>check_json_dict(json_dict)</code>","text":"<p>Check if the json file has the appropiate syntax.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the dictonary that we will test.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>tuple[str, bool]</code> <p>is the expression having the appropiate syntax ?</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def check_json_dict(self, json_dict: dict) -&gt; tuple[str, bool]:\n    \"\"\"\n    Check if the json file has the appropiate syntax.\n\n    Args:\n        json_dict (dict): the dictonary that we will test.\n\n    Returns:\n        bool: is the expression having the appropiate syntax ?\n    \"\"\"\n    err_code = \"No instructions received.\"\n    exp_ok = False\n    for expr in json_dict:\n        err_code = \"Wrong experiment name or too many experiments\"\n        # Fix this pylint issue whenever you have time, but be careful !\n        # pylint: disable=W0702\n        try:\n            exp_ok = (\n                expr.startswith(\"experiment_\")\n                and expr[11:].isdigit()\n                and (int(expr[11:]) &lt;= self.n_max_experiments)\n            )\n        except:\n            exp_ok = False\n            break\n        if not exp_ok:\n            break\n        # test the structure of the experiment\n        err_code, exp_ok = self.check_experiment(json_dict[expr])\n        if not exp_ok:\n            break\n        # time to check the structure of the instructions\n        ins_list = json_dict[expr][\"instructions\"]\n        err_code, exp_ok = self.check_instructions(ins_list)\n        if not exp_ok:\n            break\n    return err_code.replace(\"\\n\", \"..\"), exp_ok\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.Spooler.get_configuration","title":"<code>get_configuration()</code>","text":"<p>Sends back the configuration dictionary of the spooler.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def get_configuration(self) -&gt; BackendConfigSchemaIn:\n    \"\"\"\n    Sends back the configuration dictionary of the spooler.\n    \"\"\"\n    gate_list = []\n    for _, ins_obj in self.ins_schema_dict.items():\n        if \"is_gate\" in ins_obj.model_fields:\n            gate_list.append(ins_obj.config_dict())\n    backend_config_dict = {\n        \"description\": self.description,\n        \"version\": self.version,\n        \"cold_atom_type\": self.cold_atom_type,\n        \"gates\": gate_list,\n        \"max_experiments\": self.n_max_experiments,\n        \"max_shots\": self.n_max_shots,\n        \"simulator\": True,\n        \"supported_instructions\": list(self.ins_schema_dict.keys()),\n        \"num_wires\": self.n_wires,\n        \"wire_order\": self.wire_order,\n        \"num_species\": self.num_species,\n        \"operational\": self.operational,\n        \"display_name\": self.display_name,\n    }\n    return BackendConfigSchemaIn(**backend_config_dict)\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.StatusMsgDict","title":"<code>StatusMsgDict</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>A class that defines the structure of the status messages.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class StatusMsgDict(BaseModel):\n    \"\"\"\n    A class that defines the structure of the status messages.\n    \"\"\"\n\n    job_id: str = Field(description=\"unique execution id from the backend.\")\n    status: str = Field(description=\"status of job execution.\")\n    detail: str = Field(description=\"detailed status of job execution.\")\n    error_message: str = Field(description=\"error message of job execution.\")\n</code></pre>"},{"location":"schemes/#src.sqooler.schemes.gate_dict_from_list","title":"<code>gate_dict_from_list(inst_list)</code>","text":"<p>Transforms a list into an appropiate dictionnary for instructions. The list is assumed to be in the format [name, wires, params].</p> <p>Parameters:</p> Name Type Description Default <code>inst_list</code> <code>list</code> <p>The list that should be transformed.</p> required <p>Returns:</p> Type Description <code>GateDict</code> <p>A GateDict object.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def gate_dict_from_list(inst_list: list) -&gt; GateDict:\n    \"\"\"\n    Transforms a list into an appropiate dictionnary for instructions. The list\n    is assumed to be in the format [name, wires, params].\n\n    Args:\n        inst_list: The list that should be transformed.\n\n    Returns:\n        A GateDict object.\n    \"\"\"\n    gate_draft = {\"name\": inst_list[0], \"wires\": inst_list[1], \"params\": inst_list[2]}\n    return GateDict(**gate_draft)\n</code></pre>"},{"location":"storage_providers/","title":"API documentation of storage providers","text":"<p>The module that contains all the necessary logic for communication with the external storage for the jobs. It creates an abstract API layer for the storage providers.</p>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProvider","title":"<code>DropboxProvider</code>","text":"<p>             Bases: <code>DropboxProviderExtended</code></p> <p>The class that implements the dropbox storage provider.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class DropboxProvider(DropboxProviderExtended):\n    \"\"\"\n    The class that implements the dropbox storage provider.\n    \"\"\"\n\n    def __init__(self, login_dict: DropboxLoginInformation) -&gt; None:\n        \"\"\"\n        Args:\n            login_dict: The dictionary that contains the login information\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n        \"\"\"\n\n        super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>DropboxLoginInformation</code> <p>The dictionary that contains the login information</p> required <code>name</code> <p>The name of the storage provider</p> required <code>is_active</code> <p>Is the storage provider active.</p> required Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(self, login_dict: DropboxLoginInformation) -&gt; None:\n    \"\"\"\n    Args:\n        login_dict: The dictionary that contains the login information\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n    \"\"\"\n\n    super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended","title":"<code>DropboxProviderExtended</code>","text":"<p>             Bases: <code>StorageProvider</code></p> <p>The class that implements the dropbox storage provider.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class DropboxProviderExtended(StorageProvider):\n    \"\"\"\n    The class that implements the dropbox storage provider.\n    \"\"\"\n\n    def __init__(\n        self, login_dict: DropboxLoginInformation, name: str, is_active: bool = True\n    ) -&gt; None:\n        \"\"\"\n        Args:\n            login_dict: The dictionary that contains the login information\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n        \"\"\"\n\n        super().__init__(name, is_active)\n        self.app_key = login_dict.app_key\n        self.app_secret = login_dict.app_secret\n        self.refresh_token = login_dict.refresh_token\n\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the content_dict as a json file to the dropbox\n\n        Args:\n            content_dict: the content of the file that should be uploaded\n            storage_path: the path where the file should be stored, but excluding the file name\n            job_id: the name of the file without the .json extension\n        \"\"\"\n\n        # create the appropriate string for the dropbox API\n        dump_str = json.dumps(content_dict)\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            dbx.users_get_current_account()\n            dbx.files_upload(\n                dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n            )\n\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the dropbox\n\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n            full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n            _, res = dbx.files_download(path=full_path)\n            data = res.content\n        return json.loads(data.decode(\"utf-8\"))\n\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the job\n        \"\"\"\n        return self.get_file_content(storage_path=storage_path, job_id=f\"job-{job_id}\")\n\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # create the appropriate string for the dropbox API\n        dump_str = json.dumps(content_dict)\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            dbx.users_get_current_account()\n            dbx.files_upload(\n                dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n            )\n\n    @validate_active\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n        # strip trailing and leading slashes from the paths\n        start_path = start_path.strip(\"/\")\n        final_path = final_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            dbx.users_get_current_account()\n\n            full_start_path = \"/\" + start_path + \"/\" + job_id + \".json\"\n            full_final_path = \"/\" + final_path + \"/\" + job_id + \".json\"\n            dbx.files_move_v2(full_start_path, full_final_path)\n\n    @validate_active\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Remove the file from the dropbox\n\n        Args:\n            storage_path: the path where the file should be stored, but excluding the file name\n            job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n\n            full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n            _ = dbx.files_delete(path=full_path)\n\n    def upload_config(\n        self, config_dict: BackendConfigSchemaIn, backend_name: str\n    ) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        All the configurations are stored in the Backend_files/Config folder.\n        For each backend there is a separate folder in which the configuration is stored as a json file.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n        config_path = \"Backend_files/Config/\" + backend_name\n        self.upload(config_dict.model_dump(), config_path, \"config\")\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict,\n        status_msg_dict: StatusMsgDict,\n        job_id: str,\n        backend_name: str,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the dropbox.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # this should become part of the json file instead of its name in the future\n        extracted_username = job_id.split(\"-\")[2]\n\n        status_json_dir = (\n            \"/Backend_files/Status/\" + backend_name + \"/\" + extracted_username + \"/\"\n        )\n        status_json_name = \"status-\" + job_id\n\n        job_json_name = \"job-\" + job_id\n        job_json_start_dir = \"Backend_files/Running_Jobs\"\n\n        if status_msg_dict.status == \"DONE\":\n            # let us create the result json file\n            result_json_dir = (\n                \"/Backend_files/Result/\" + backend_name + \"/\" + extracted_username + \"/\"\n            )\n            result_json_name = \"result-\" + job_id\n            self.upload(result_dict.model_dump(), result_json_dir, result_json_name)\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = (\n                \"/Backend_files/Finished_Jobs/\"\n                + backend_name\n                + \"/\"\n                + extracted_username\n                + \"/\"\n            )\n            self.move_file(job_json_start_dir, job_finished_json_dir, job_json_name)\n\n        elif status_msg_dict.status == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = \"Backend_files/Deleted_Jobs\"\n            self.move_file(job_json_start_dir, deleted_json_dir, job_json_name)\n\n        # and create the status json file\n        self.upload(status_msg_dict.model_dump(), status_json_dir, status_json_name)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of files. Typically we are looking for the queued jobs of a backend here.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n        # strip trailing and leading slashes from the paths\n        storage_path = storage_path.strip(\"/\")\n\n        storage_path = \"/\" + storage_path.strip(\"/\") + \"/\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        file_list = []\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n            # We should really handle these exceptions cleaner, but this seems a bit\n            # complicated right now\n            # pylint: disable=W0703\n            try:\n                response = dbx.files_list_folder(path=storage_path)\n                file_list = response.entries\n                file_list = [item.name for item in file_list]\n            except ApiError:\n                print(f\"Could not obtain job queue for {storage_path}\")\n            except Exception as err:\n                print(err)\n        return file_list\n\n    @validate_active\n    def get_backends(self) -&gt; list[str]:\n        \"\"\"\n        Get a list of all the backends that the provider offers.\n        \"\"\"\n        backend_config_path = \"/Backend_files/Config/\"\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n\n            folders_results = dbx.files_list_folder(path=backend_config_path)\n            entries = folders_results.entries\n            backend_names = []\n            for entry in entries:\n                backend_names.append(entry.name)\n        return backend_names\n\n    def get_backend_dict(self, display_name: str) -&gt; BackendConfigSchemaOut:\n        \"\"\"\n        The configuration of the backend.\n\n        Args:\n            display_name: The identifier of the backend\n\n        Returns:\n            The full schema of the backend.\n        \"\"\"\n        backend_json_path = f\"Backend_files/Config/{display_name}\"\n        backend_config_dict = self.get_file_content(\n            storage_path=backend_json_path, job_id=\"config\"\n        )\n        backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n        qiskit_backend_dict = self.backend_dict_to_qiskit(backend_config_info)\n        return qiskit_backend_dict\n\n    def get_backend_status(self, display_name: str) -&gt; BackendStatusSchemaOut:\n        \"\"\"\n        Get the status of the backend. This follows the qiskit logic.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The status dict of the backend\n        \"\"\"\n        backend_json_path = f\"Backend_files/Config/{display_name}\"\n        backend_config_dict = self.get_file_content(\n            storage_path=backend_json_path, job_id=\"config\"\n        )\n        backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n        qiskit_backend_dict = self.backend_dict_to_qiskit_status(backend_config_info)\n        return qiskit_backend_dict\n\n    def upload_job(self, job_dict: dict, display_name: str, username: str) -&gt; str:\n        \"\"\"\n        This function uploads a job to the backend and creates the job_id.\n\n        Args:\n            job_dict: The job dictionary that should be uploaded\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n\n        Returns:\n            The job_id of the uploaded job\n        \"\"\"\n        job_id = (\n            (datetime.datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\"))\n            + \"-\"\n            + display_name\n            + \"-\"\n            + username\n            + \"-\"\n            + (uuid.uuid4().hex)[:5]\n        )\n        # now we upload the job to the backend\n        # this is currently very much backend specific\n        job_json_dir = \"/Backend_files/Queued_Jobs/\" + display_name + \"/\"\n        job_json_name = \"job-\" + job_id\n\n        self.upload(\n            content_dict=job_dict, storage_path=job_json_dir, job_id=job_json_name\n        )\n        return job_id\n\n    def upload_status(\n        self, display_name: str, username: str, job_id: str\n    ) -&gt; StatusMsgDict:\n        \"\"\"\n        This function uploads a status file to the backend and creates the status dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The status dict of the job\n        \"\"\"\n        status_json_dir = \"Backend_files/Status/\" + display_name + \"/\" + username\n        status_json_name = \"status-\" + job_id\n        status_draft = {\n            \"job_id\": job_id,\n            \"status\": \"INITIALIZING\",\n            \"detail\": \"Got your json.\",\n            \"error_message\": \"None\",\n        }\n        status_dict = StatusMsgDict(**status_draft)\n        self.upload(\n            content_dict=status_dict.model_dump(),\n            storage_path=status_json_dir,\n            job_id=status_json_name,\n        )\n        return status_dict\n\n    def get_status(\n        self, display_name: str, username: str, job_id: str\n    ) -&gt; StatusMsgDict:\n        \"\"\"\n        This function gets the status file from the backend and returns the status dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The status dict of the job\n        \"\"\"\n        status_json_dir = \"Backend_files/Status/\" + display_name + \"/\" + username\n        status_json_name = \"status-\" + job_id\n\n        status_dict = self.get_file_content(\n            storage_path=status_json_dir, job_id=status_json_name\n        )\n        return StatusMsgDict(**status_dict)\n\n    def get_result(self, display_name: str, username: str, job_id: str) -&gt; ResultDict:\n        \"\"\"\n        This function gets the result file from the backend and returns the result dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The result dict of the job\n        \"\"\"\n        result_json_dir = \"Backend_files/Result/\" + display_name + \"/\" + username\n        result_json_name = \"result-\" + job_id\n        result_dict = self.get_file_content(\n            storage_path=result_json_dir, job_id=result_json_name\n        )\n        backend_config_info = self.get_backend_dict(display_name)\n        result_dict[\"backend_name\"] = backend_config_info.backend_name\n\n        typed_result = ResultDict(**result_dict)\n        return typed_result\n\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n        \"\"\"\n        A function that obtains the next job in the queue.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n        job_json_dir = \"/Backend_files/Queued_Jobs/\" + backend_name + \"/\"\n        job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n        job_list = self.get_file_queue(job_json_dir)\n        # if there is a job, we should move it\n        if job_list:\n            job_json_name = job_list[0]\n            job_dict[\"job_id\"] = job_json_name[4:-5]\n\n            # split the .json from the job_json_name\n            job_json_name = job_json_name.split(\".\")[0]\n            # and move the file into the right directory\n            self.move_file(job_json_dir, \"Backend_files/Running_Jobs\", job_json_name)\n            job_dict[\"job_json_path\"] = \"Backend_files/Running_Jobs\"\n        return job_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.__init__","title":"<code>__init__(login_dict, name, is_active=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>DropboxLoginInformation</code> <p>The dictionary that contains the login information</p> required <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(\n    self, login_dict: DropboxLoginInformation, name: str, is_active: bool = True\n) -&gt; None:\n    \"\"\"\n    Args:\n        login_dict: The dictionary that contains the login information\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n    \"\"\"\n\n    super().__init__(name, is_active)\n    self.app_key = login_dict.app_key\n    self.app_secret = login_dict.app_secret\n    self.refresh_token = login_dict.refresh_token\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Remove the file from the dropbox</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file. Is a json file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef delete_file(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Remove the file from the dropbox\n\n    Args:\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n        _ = dbx.files_delete(path=full_path)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_backend_dict","title":"<code>get_backend_dict(display_name)</code>","text":"<p>The configuration of the backend.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The identifier of the backend</p> required <p>Returns:</p> Type Description <code>BackendConfigSchemaOut</code> <p>The full schema of the backend.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_backend_dict(self, display_name: str) -&gt; BackendConfigSchemaOut:\n    \"\"\"\n    The configuration of the backend.\n\n    Args:\n        display_name: The identifier of the backend\n\n    Returns:\n        The full schema of the backend.\n    \"\"\"\n    backend_json_path = f\"Backend_files/Config/{display_name}\"\n    backend_config_dict = self.get_file_content(\n        storage_path=backend_json_path, job_id=\"config\"\n    )\n    backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n    qiskit_backend_dict = self.backend_dict_to_qiskit(backend_config_info)\n    return qiskit_backend_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_backend_status","title":"<code>get_backend_status(display_name)</code>","text":"<p>Get the status of the backend. This follows the qiskit logic.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>BackendStatusSchemaOut</code> <p>The status dict of the backend</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_backend_status(self, display_name: str) -&gt; BackendStatusSchemaOut:\n    \"\"\"\n    Get the status of the backend. This follows the qiskit logic.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The status dict of the backend\n    \"\"\"\n    backend_json_path = f\"Backend_files/Config/{display_name}\"\n    backend_config_dict = self.get_file_content(\n        storage_path=backend_json_path, job_id=\"config\"\n    )\n    backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n    qiskit_backend_dict = self.backend_dict_to_qiskit_status(backend_config_info)\n    return qiskit_backend_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_backends","title":"<code>get_backends()</code>","text":"<p>Get a list of all the backends that the provider offers.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef get_backends(self) -&gt; list[str]:\n    \"\"\"\n    Get a list of all the backends that the provider offers.\n    \"\"\"\n    backend_config_path = \"/Backend_files/Config/\"\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n\n        folders_results = dbx.files_list_folder(path=backend_config_path)\n        entries = folders_results.entries\n        backend_names = []\n        for entry in entries:\n            backend_names.append(entry.name)\n    return backend_names\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Get the file content from the dropbox</p> <p>storage_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the dropbox\n\n    storage_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n        _, res = dbx.files_download(path=full_path)\n        data = res.content\n    return json.loads(data.decode(\"utf-8\"))\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of files. Typically we are looking for the queued jobs of a backend here.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of files. Typically we are looking for the queued jobs of a backend here.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n\n    # strip trailing and leading slashes from the paths\n    storage_path = storage_path.strip(\"/\")\n\n    storage_path = \"/\" + storage_path.strip(\"/\") + \"/\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    file_list = []\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n        # We should really handle these exceptions cleaner, but this seems a bit\n        # complicated right now\n        # pylint: disable=W0703\n        try:\n            response = dbx.files_list_folder(path=storage_path)\n            file_list = response.entries\n            file_list = [item.name for item in file_list]\n        except ApiError:\n            print(f\"Could not obtain job queue for {storage_path}\")\n        except Exception as err:\n            print(err)\n    return file_list\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the job\n    \"\"\"\n    return self.get_file_content(storage_path=storage_path, job_id=f\"job-{job_id}\")\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n    \"\"\"\n    A function that obtains the next job in the queue.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n    job_json_dir = \"/Backend_files/Queued_Jobs/\" + backend_name + \"/\"\n    job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n    job_list = self.get_file_queue(job_json_dir)\n    # if there is a job, we should move it\n    if job_list:\n        job_json_name = job_list[0]\n        job_dict[\"job_id\"] = job_json_name[4:-5]\n\n        # split the .json from the job_json_name\n        job_json_name = job_json_name.split(\".\")[0]\n        # and move the file into the right directory\n        self.move_file(job_json_dir, \"Backend_files/Running_Jobs\", job_json_name)\n        job_dict[\"job_json_path\"] = \"Backend_files/Running_Jobs\"\n    return job_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_result","title":"<code>get_result(display_name, username, job_id)</code>","text":"<p>This function gets the result file from the backend and returns the result dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>ResultDict</code> <p>The result dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_result(self, display_name: str, username: str, job_id: str) -&gt; ResultDict:\n    \"\"\"\n    This function gets the result file from the backend and returns the result dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The result dict of the job\n    \"\"\"\n    result_json_dir = \"Backend_files/Result/\" + display_name + \"/\" + username\n    result_json_name = \"result-\" + job_id\n    result_dict = self.get_file_content(\n        storage_path=result_json_dir, job_id=result_json_name\n    )\n    backend_config_info = self.get_backend_dict(display_name)\n    result_dict[\"backend_name\"] = backend_config_info.backend_name\n\n    typed_result = ResultDict(**result_dict)\n    return typed_result\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.get_status","title":"<code>get_status(display_name, username, job_id)</code>","text":"<p>This function gets the status file from the backend and returns the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_status(\n    self, display_name: str, username: str, job_id: str\n) -&gt; StatusMsgDict:\n    \"\"\"\n    This function gets the status file from the backend and returns the status dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The status dict of the job\n    \"\"\"\n    status_json_dir = \"Backend_files/Status/\" + display_name + \"/\" + username\n    status_json_name = \"status-\" + job_id\n\n    status_dict = self.get_file_content(\n        storage_path=status_json_dir, job_id=status_json_name\n    )\n    return StatusMsgDict(**status_dict)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n    # strip trailing and leading slashes from the paths\n    start_path = start_path.strip(\"/\")\n    final_path = final_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        dbx.users_get_current_account()\n\n        full_start_path = \"/\" + start_path + \"/\" + job_id + \".json\"\n        full_final_path = \"/\" + final_path + \"/\" + job_id + \".json\"\n        dbx.files_move_v2(full_start_path, full_final_path)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # create the appropriate string for the dropbox API\n    dump_str = json.dumps(content_dict)\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        dbx.users_get_current_account()\n        dbx.files_upload(\n            dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n        )\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>","text":"<p>Upload the status and result to the dropbox.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict,\n    status_msg_dict: StatusMsgDict,\n    job_id: str,\n    backend_name: str,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the dropbox.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # this should become part of the json file instead of its name in the future\n    extracted_username = job_id.split(\"-\")[2]\n\n    status_json_dir = (\n        \"/Backend_files/Status/\" + backend_name + \"/\" + extracted_username + \"/\"\n    )\n    status_json_name = \"status-\" + job_id\n\n    job_json_name = \"job-\" + job_id\n    job_json_start_dir = \"Backend_files/Running_Jobs\"\n\n    if status_msg_dict.status == \"DONE\":\n        # let us create the result json file\n        result_json_dir = (\n            \"/Backend_files/Result/\" + backend_name + \"/\" + extracted_username + \"/\"\n        )\n        result_json_name = \"result-\" + job_id\n        self.upload(result_dict.model_dump(), result_json_dir, result_json_name)\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = (\n            \"/Backend_files/Finished_Jobs/\"\n            + backend_name\n            + \"/\"\n            + extracted_username\n            + \"/\"\n        )\n        self.move_file(job_json_start_dir, job_finished_json_dir, job_json_name)\n\n    elif status_msg_dict.status == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = \"Backend_files/Deleted_Jobs\"\n        self.move_file(job_json_start_dir, deleted_json_dir, job_json_name)\n\n    # and create the status json file\n    self.upload(status_msg_dict.model_dump(), status_json_dir, status_json_name)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the content_dict as a json file to the dropbox</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>Mapping</code> <p>the content of the file that should be uploaded</p> required <code>storage_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file without the .json extension</p> required Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the content_dict as a json file to the dropbox\n\n    Args:\n        content_dict: the content of the file that should be uploaded\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file without the .json extension\n    \"\"\"\n\n    # create the appropriate string for the dropbox API\n    dump_str = json.dumps(content_dict)\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        dbx.users_get_current_account()\n        dbx.files_upload(\n            dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n        )\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>All the configurations are stored in the Backend_files/Config folder. For each backend there is a separate folder in which the configuration is stored as a json file.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_config(\n    self, config_dict: BackendConfigSchemaIn, backend_name: str\n) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    All the configurations are stored in the Backend_files/Config folder.\n    For each backend there is a separate folder in which the configuration is stored as a json file.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n\n    config_path = \"Backend_files/Config/\" + backend_name\n    self.upload(config_dict.model_dump(), config_path, \"config\")\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.upload_job","title":"<code>upload_job(job_dict, display_name, username)</code>","text":"<p>This function uploads a job to the backend and creates the job_id.</p> <p>Parameters:</p> Name Type Description Default <code>job_dict</code> <code>dict</code> <p>The job dictionary that should be uploaded</p> required <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job_id of the uploaded job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_job(self, job_dict: dict, display_name: str, username: str) -&gt; str:\n    \"\"\"\n    This function uploads a job to the backend and creates the job_id.\n\n    Args:\n        job_dict: The job dictionary that should be uploaded\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n\n    Returns:\n        The job_id of the uploaded job\n    \"\"\"\n    job_id = (\n        (datetime.datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\"))\n        + \"-\"\n        + display_name\n        + \"-\"\n        + username\n        + \"-\"\n        + (uuid.uuid4().hex)[:5]\n    )\n    # now we upload the job to the backend\n    # this is currently very much backend specific\n    job_json_dir = \"/Backend_files/Queued_Jobs/\" + display_name + \"/\"\n    job_json_name = \"job-\" + job_id\n\n    self.upload(\n        content_dict=job_dict, storage_path=job_json_dir, job_id=job_json_name\n    )\n    return job_id\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.DropboxProviderExtended.upload_status","title":"<code>upload_status(display_name, username, job_id)</code>","text":"<p>This function uploads a status file to the backend and creates the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_status(\n    self, display_name: str, username: str, job_id: str\n) -&gt; StatusMsgDict:\n    \"\"\"\n    This function uploads a status file to the backend and creates the status dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The status dict of the job\n    \"\"\"\n    status_json_dir = \"Backend_files/Status/\" + display_name + \"/\" + username\n    status_json_name = \"status-\" + job_id\n    status_draft = {\n        \"job_id\": job_id,\n        \"status\": \"INITIALIZING\",\n        \"detail\": \"Got your json.\",\n        \"error_message\": \"None\",\n    }\n    status_dict = StatusMsgDict(**status_draft)\n    self.upload(\n        content_dict=status_dict.model_dump(),\n        storage_path=status_json_dir,\n        job_id=status_json_name,\n    )\n    return status_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProvider","title":"<code>LocalProvider</code>","text":"<p>             Bases: <code>LocalProviderExtended</code></p> <p>Create a file storage that works on the local machine.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class LocalProvider(LocalProviderExtended):\n    \"\"\"\n    Create a file storage that works on the local machine.\n    \"\"\"\n\n    def __init__(self, login_dict: LocalLoginInformation) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n        \"\"\"\n        super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(self, login_dict: LocalLoginInformation) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n    \"\"\"\n    super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended","title":"<code>LocalProviderExtended</code>","text":"<p>             Bases: <code>StorageProvider</code></p> <p>Create a file storage that works on the local machine.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class LocalProviderExtended(StorageProvider):\n    \"\"\"\n    Create a file storage that works on the local machine.\n    \"\"\"\n\n    def __init__(\n        self, login_dict: LocalLoginInformation, name: str, is_active: bool = True\n    ) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n\n        Args:\n            login_dict: The login dict that contains the neccessary\n                        information to connect to the local storage\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n\n        Raises:\n            ValidationError: If the login_dict is not valid\n        \"\"\"\n        super().__init__(name, is_active)\n        self.base_path = login_dict.base_path\n\n    @validate_active\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # json folder\n        folder_path = self.base_path + \"/\" + storage_path\n        if not os.path.exists(folder_path):\n            os.makedirs(folder_path)\n\n        # create the full path\n        file_name = job_id + \".json\"\n        full_json_path = os.path.join(folder_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n\n        with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n            json.dump(content_dict, json_file)\n\n    @validate_active\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        file_name = job_id + \".json\"\n        full_json_path = os.path.join(self.base_path, storage_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n\n        with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n            loaded_data_dict = json.load(json_file)\n        return loaded_data_dict\n\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the job\n        \"\"\"\n        job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n        return job_dict\n\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # json folder\n        file_name = job_id + \".json\"\n        full_json_path = os.path.join(self.base_path, storage_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n\n        # does the file already exist ?\n        if not os.path.exists(secure_path):\n            raise FileNotFoundError(\n                f\"The file {secure_path} does not exist and cannot be updated.\"\n            )\n        with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n            json.dump(content_dict, json_file)\n\n    @validate_active\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from `start_path` to `final_path`\n        \"\"\"\n        start_path = start_path.strip(\"/\")\n\n        source_file = self.base_path + \"/\" + start_path + \"/\" + job_id + \".json\"\n\n        final_path = self.base_path + \"/\" + final_path + \"/\"\n        if not os.path.exists(final_path):\n            os.makedirs(final_path)\n\n        # Move the file\n        shutil.move(source_file, final_path)\n\n    @validate_active\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Delete the file from the storage\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n            job_id: the name of the file\n\n        Returns:\n            None\n        \"\"\"\n        storage_path = storage_path.strip(\"/\")\n        source_file = self.base_path + \"/\" + storage_path + \"/\" + job_id + \".json\"\n        os.remove(source_file)\n\n    @validate_active\n    def get_backends(self) -&gt; list[str]:\n        \"\"\"\n        Get a list of all the backends that the provider offers.\n        \"\"\"\n        # path of the configs\n        config_path = self.base_path + \"/backends/configs\"\n        backend_names: list[str] = []\n\n        # If the folder does not exist, return an empty list\n        if not os.path.exists(config_path):\n            return backend_names\n\n        # Get a list of all items in the folder\n        all_items = os.listdir(config_path)\n        # Filter out only the JSON files\n        json_files = [item for item in all_items if item.endswith(\".json\")]\n\n        for file_name in json_files:\n            full_json_path = os.path.join(config_path, file_name)\n            secure_path = os.path.normpath(full_json_path)\n\n            with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n                config_dict = json.load(json_file)\n                backend_names.append(config_dict[\"display_name\"])\n        return backend_names\n\n    @validate_active\n    def get_backend_dict(self, display_name: str) -&gt; BackendConfigSchemaOut:\n        \"\"\"\n        The configuration dictionary of the backend such that it can be sent out to the API to\n        the common user. We make sure that it is compatible with QISKIT within this function.\n\n        Args:\n            display_name: The identifier of the backend\n\n        Returns:\n            The full schema of the backend.\n\n        Raises:\n            FileNotFoundError: If the backend does not exist\n        \"\"\"\n        # path of the configs\n        config_path = self.base_path + \"/backends/configs\"\n        file_name = display_name + \".json\"\n        full_json_path = os.path.join(config_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n        with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n            backend_config_dict = json.load(json_file)\n\n        if not backend_config_dict:\n            raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n        backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n        qiskit_backend_dict = self.backend_dict_to_qiskit(backend_config_info)\n        return qiskit_backend_dict\n\n    def get_backend_status(self, display_name: str) -&gt; BackendStatusSchemaOut:\n        \"\"\"\n        Get the status of the backend. This follows the qiskit logic.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The status dict of the backend\n\n        Raises:\n            FileNotFoundError: If the backend does not exist\n        \"\"\"\n        # path of the configs\n        file_name = display_name + \".json\"\n        config_path = self.base_path + \"/backends/configs\"\n        full_json_path = os.path.join(config_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n        with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n            backend_config_dict = json.load(json_file)\n\n        if not backend_config_dict:\n            raise FileNotFoundError(\n                f\"The backend {display_name} does not exist for the given storageprovider.\"\n            )\n\n        backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n        qiskit_backend_dict = self.backend_dict_to_qiskit_status(backend_config_info)\n        return qiskit_backend_dict\n\n    def upload_job(self, job_dict: dict, display_name: str, username: str) -&gt; str:\n        \"\"\"\n        Upload the job to the storage provider.\n\n        Args:\n            job_dict: the full job dict\n            display_name: the name of the backend\n            username: the name of the user that submitted the job\n\n        Returns:\n            The job id of the uploaded job.\n        \"\"\"\n\n        storage_path = \"jobs/queued/\" + display_name\n        job_id = (uuid.uuid4().hex)[:24]\n\n        self.upload(content_dict=job_dict, storage_path=storage_path, job_id=job_id)\n        return job_id\n\n    def upload_status(\n        self, display_name: str, username: str, job_id: str\n    ) -&gt; StatusMsgDict:\n        \"\"\"\n        This function uploads a status file to the backend and creates the status dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The status dict of the job\n        \"\"\"\n        storage_path = \"status/\" + display_name\n        status_draft = {\n            \"job_id\": job_id,\n            \"status\": \"INITIALIZING\",\n            \"detail\": \"Got your json.\",\n            \"error_message\": \"None\",\n        }\n\n        # should we also upload the username into the dict ?\n        status_dict = StatusMsgDict(**status_draft)\n        # now upload the status dict\n        self.upload(\n            content_dict=status_dict.model_dump(),\n            storage_path=storage_path,\n            job_id=job_id,\n        )\n        return status_dict\n\n    def get_status(\n        self, display_name: str, username: str, job_id: str\n    ) -&gt; StatusMsgDict:\n        \"\"\"\n        This function gets the status file from the backend and returns the status dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The status dict of the job\n        \"\"\"\n        status_json_dir = \"status/\" + display_name\n\n        status_dict = self.get_file_content(storage_path=status_json_dir, job_id=job_id)\n        return StatusMsgDict(**status_dict)\n\n    def get_result(self, display_name: str, username: str, job_id: str) -&gt; ResultDict:\n        \"\"\"\n        This function gets the result file from the backend and returns the result dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The result dict of the job\n        \"\"\"\n        result_json_dir = \"results/\" + display_name\n        result_dict = self.get_file_content(storage_path=result_json_dir, job_id=job_id)\n\n        backend_config_info = self.get_backend_dict(display_name)\n        result_dict[\"backend_name\"] = backend_config_info.backend_name\n        typed_result = ResultDict(**result_dict)\n        return typed_result\n\n    def upload_config(\n        self, config_dict: BackendConfigSchemaIn, backend_name: str\n    ) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # path of the configs\n        config_path = os.path.join(self.base_path, \"backends/configs\")\n        config_path = os.path.normpath(os.path.join(self.base_path, \"backends/configs\"))\n        # test if the config path already exists. If it does not, create it\n        if not os.path.exists(config_path):\n            os.makedirs(config_path)\n\n        file_name = backend_name + \".json\"\n        full_json_path = os.path.join(config_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n        with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n            json.dump(config_dict.model_dump(), json_file)\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict,\n        status_msg_dict: StatusMsgDict,\n        job_id: str,\n        backend_name: str,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        job_json_start_dir = \"jobs/running\"\n        # check if the job is done or had an error\n        if status_msg_dict.status == \"DONE\":\n            # test if the result dict is None\n            if result_dict is None:\n                raise ValueError(\n                    \"The 'result_dict' argument cannot be None if the job is done.\"\n                )\n            # let us create the result json file\n            result_json_dir = \"results/\" + backend_name\n            self.upload(result_dict.model_dump(), result_json_dir, job_id)\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = \"jobs/finished/\" + backend_name\n            self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n        elif status_msg_dict.status == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = \"jobs/deleted\"\n            self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n        # and create the status json file\n        status_json_dir = \"status/\" + backend_name\n        self.update_file(status_msg_dict.model_dump(), status_json_dir, job_id)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of files\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n        # get a list of files in the folder\n        full_path = self.base_path + \"/\" + storage_path\n        # test if the path exists. Otherwise simply return an empty list\n        if not os.path.exists(full_path):\n            return []\n        return os.listdir(full_path)\n\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n        \"\"\"\n        A function that obtains the next job in the queue.\n\n        Args:\n            backend_name: The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n        queue_dir = \"jobs/queued/\" + backend_name\n        job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n        job_list = self.get_file_queue(queue_dir)\n        # if there is a job, we should move it\n        if job_list:\n            job_json_name = job_list[0]\n            job_id = job_json_name[:-5]\n            job_dict[\"job_id\"] = job_id\n\n            # and move the file into the right directory\n            self.move_file(queue_dir, \"jobs/running\", job_id)\n            job_dict[\"job_json_path\"] = \"jobs/running\"\n        return job_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.__init__","title":"<code>__init__(login_dict, name, is_active=True)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> <p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>LocalLoginInformation</code> <p>The login dict that contains the neccessary         information to connect to the local storage</p> required <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the login_dict is not valid</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(\n    self, login_dict: LocalLoginInformation, name: str, is_active: bool = True\n) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n\n    Args:\n        login_dict: The login dict that contains the neccessary\n                    information to connect to the local storage\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n\n    Raises:\n        ValidationError: If the login_dict is not valid\n    \"\"\"\n    super().__init__(name, is_active)\n    self.base_path = login_dict.base_path\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Delete the file from the storage</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file is currently stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef delete_file(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Delete the file from the storage\n\n    Args:\n        storage_path: the path where the file is currently stored, but excluding the file name\n        job_id: the name of the file\n\n    Returns:\n        None\n    \"\"\"\n    storage_path = storage_path.strip(\"/\")\n    source_file = self.base_path + \"/\" + storage_path + \"/\" + job_id + \".json\"\n    os.remove(source_file)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_backend_dict","title":"<code>get_backend_dict(display_name)</code>","text":"<p>The configuration dictionary of the backend such that it can be sent out to the API to the common user. We make sure that it is compatible with QISKIT within this function.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The identifier of the backend</p> required <p>Returns:</p> Type Description <code>BackendConfigSchemaOut</code> <p>The full schema of the backend.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef get_backend_dict(self, display_name: str) -&gt; BackendConfigSchemaOut:\n    \"\"\"\n    The configuration dictionary of the backend such that it can be sent out to the API to\n    the common user. We make sure that it is compatible with QISKIT within this function.\n\n    Args:\n        display_name: The identifier of the backend\n\n    Returns:\n        The full schema of the backend.\n\n    Raises:\n        FileNotFoundError: If the backend does not exist\n    \"\"\"\n    # path of the configs\n    config_path = self.base_path + \"/backends/configs\"\n    file_name = display_name + \".json\"\n    full_json_path = os.path.join(config_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n    with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n        backend_config_dict = json.load(json_file)\n\n    if not backend_config_dict:\n        raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n    backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n    qiskit_backend_dict = self.backend_dict_to_qiskit(backend_config_info)\n    return qiskit_backend_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_backend_status","title":"<code>get_backend_status(display_name)</code>","text":"<p>Get the status of the backend. This follows the qiskit logic.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>BackendStatusSchemaOut</code> <p>The status dict of the backend</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_backend_status(self, display_name: str) -&gt; BackendStatusSchemaOut:\n    \"\"\"\n    Get the status of the backend. This follows the qiskit logic.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The status dict of the backend\n\n    Raises:\n        FileNotFoundError: If the backend does not exist\n    \"\"\"\n    # path of the configs\n    file_name = display_name + \".json\"\n    config_path = self.base_path + \"/backends/configs\"\n    full_json_path = os.path.join(config_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n    with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n        backend_config_dict = json.load(json_file)\n\n    if not backend_config_dict:\n        raise FileNotFoundError(\n            f\"The backend {display_name} does not exist for the given storageprovider.\"\n        )\n\n    backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n    qiskit_backend_dict = self.backend_dict_to_qiskit_status(backend_config_info)\n    return qiskit_backend_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_backends","title":"<code>get_backends()</code>","text":"<p>Get a list of all the backends that the provider offers.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef get_backends(self) -&gt; list[str]:\n    \"\"\"\n    Get a list of all the backends that the provider offers.\n    \"\"\"\n    # path of the configs\n    config_path = self.base_path + \"/backends/configs\"\n    backend_names: list[str] = []\n\n    # If the folder does not exist, return an empty list\n    if not os.path.exists(config_path):\n        return backend_names\n\n    # Get a list of all items in the folder\n    all_items = os.listdir(config_path)\n    # Filter out only the JSON files\n    json_files = [item for item in all_items if item.endswith(\".json\")]\n\n    for file_name in json_files:\n        full_json_path = os.path.join(config_path, file_name)\n        secure_path = os.path.normpath(full_json_path)\n\n        with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n            config_dict = json.load(json_file)\n            backend_names.append(config_dict[\"display_name\"])\n    return backend_names\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Get the file content from the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    file_name = job_id + \".json\"\n    full_json_path = os.path.join(self.base_path, storage_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n\n    with open(secure_path, \"r\", encoding=\"utf-8\") as json_file:\n        loaded_data_dict = json.load(json_file)\n    return loaded_data_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of files</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of files\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n    # get a list of files in the folder\n    full_path = self.base_path + \"/\" + storage_path\n    # test if the path exists. Otherwise simply return an empty list\n    if not os.path.exists(full_path):\n        return []\n    return os.listdir(full_path)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the job\n    \"\"\"\n    job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n    return job_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n    \"\"\"\n    A function that obtains the next job in the queue.\n\n    Args:\n        backend_name: The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n    queue_dir = \"jobs/queued/\" + backend_name\n    job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n    job_list = self.get_file_queue(queue_dir)\n    # if there is a job, we should move it\n    if job_list:\n        job_json_name = job_list[0]\n        job_id = job_json_name[:-5]\n        job_dict[\"job_id\"] = job_id\n\n        # and move the file into the right directory\n        self.move_file(queue_dir, \"jobs/running\", job_id)\n        job_dict[\"job_json_path\"] = \"jobs/running\"\n    return job_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_result","title":"<code>get_result(display_name, username, job_id)</code>","text":"<p>This function gets the result file from the backend and returns the result dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>ResultDict</code> <p>The result dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_result(self, display_name: str, username: str, job_id: str) -&gt; ResultDict:\n    \"\"\"\n    This function gets the result file from the backend and returns the result dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The result dict of the job\n    \"\"\"\n    result_json_dir = \"results/\" + display_name\n    result_dict = self.get_file_content(storage_path=result_json_dir, job_id=job_id)\n\n    backend_config_info = self.get_backend_dict(display_name)\n    result_dict[\"backend_name\"] = backend_config_info.backend_name\n    typed_result = ResultDict(**result_dict)\n    return typed_result\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.get_status","title":"<code>get_status(display_name, username, job_id)</code>","text":"<p>This function gets the status file from the backend and returns the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_status(\n    self, display_name: str, username: str, job_id: str\n) -&gt; StatusMsgDict:\n    \"\"\"\n    This function gets the status file from the backend and returns the status dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The status dict of the job\n    \"\"\"\n    status_json_dir = \"status/\" + display_name\n\n    status_dict = self.get_file_content(storage_path=status_json_dir, job_id=job_id)\n    return StatusMsgDict(**status_dict)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Move the file from <code>start_path</code> to <code>final_path</code></p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from `start_path` to `final_path`\n    \"\"\"\n    start_path = start_path.strip(\"/\")\n\n    source_file = self.base_path + \"/\" + start_path + \"/\" + job_id + \".json\"\n\n    final_path = self.base_path + \"/\" + final_path + \"/\"\n    if not os.path.exists(final_path):\n        os.makedirs(final_path)\n\n    # Move the file\n    shutil.move(source_file, final_path)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # json folder\n    file_name = job_id + \".json\"\n    full_json_path = os.path.join(self.base_path, storage_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n\n    # does the file already exist ?\n    if not os.path.exists(secure_path):\n        raise FileNotFoundError(\n            f\"The file {secure_path} does not exist and cannot be updated.\"\n        )\n    with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n        json.dump(content_dict, json_file)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict,\n    status_msg_dict: StatusMsgDict,\n    job_id: str,\n    backend_name: str,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    job_json_start_dir = \"jobs/running\"\n    # check if the job is done or had an error\n    if status_msg_dict.status == \"DONE\":\n        # test if the result dict is None\n        if result_dict is None:\n            raise ValueError(\n                \"The 'result_dict' argument cannot be None if the job is done.\"\n            )\n        # let us create the result json file\n        result_json_dir = \"results/\" + backend_name\n        self.upload(result_dict.model_dump(), result_json_dir, job_id)\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = \"jobs/finished/\" + backend_name\n        self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n    elif status_msg_dict.status == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = \"jobs/deleted\"\n        self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n    # and create the status json file\n    status_json_dir = \"status/\" + backend_name\n    self.update_file(status_msg_dict.model_dump(), status_json_dir, job_id)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the file to the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # json folder\n    folder_path = self.base_path + \"/\" + storage_path\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n\n    # create the full path\n    file_name = job_id + \".json\"\n    full_json_path = os.path.join(folder_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n\n    with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n        json.dump(content_dict, json_file)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_config(\n    self, config_dict: BackendConfigSchemaIn, backend_name: str\n) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # path of the configs\n    config_path = os.path.join(self.base_path, \"backends/configs\")\n    config_path = os.path.normpath(os.path.join(self.base_path, \"backends/configs\"))\n    # test if the config path already exists. If it does not, create it\n    if not os.path.exists(config_path):\n        os.makedirs(config_path)\n\n    file_name = backend_name + \".json\"\n    full_json_path = os.path.join(config_path, file_name)\n    secure_path = os.path.normpath(full_json_path)\n    with open(secure_path, \"w\", encoding=\"utf-8\") as json_file:\n        json.dump(config_dict.model_dump(), json_file)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.upload_job","title":"<code>upload_job(job_dict, display_name, username)</code>","text":"<p>Upload the job to the storage provider.</p> <p>Parameters:</p> Name Type Description Default <code>job_dict</code> <code>dict</code> <p>the full job dict</p> required <code>display_name</code> <code>str</code> <p>the name of the backend</p> required <code>username</code> <code>str</code> <p>the name of the user that submitted the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job id of the uploaded job.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_job(self, job_dict: dict, display_name: str, username: str) -&gt; str:\n    \"\"\"\n    Upload the job to the storage provider.\n\n    Args:\n        job_dict: the full job dict\n        display_name: the name of the backend\n        username: the name of the user that submitted the job\n\n    Returns:\n        The job id of the uploaded job.\n    \"\"\"\n\n    storage_path = \"jobs/queued/\" + display_name\n    job_id = (uuid.uuid4().hex)[:24]\n\n    self.upload(content_dict=job_dict, storage_path=storage_path, job_id=job_id)\n    return job_id\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.LocalProviderExtended.upload_status","title":"<code>upload_status(display_name, username, job_id)</code>","text":"<p>This function uploads a status file to the backend and creates the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_status(\n    self, display_name: str, username: str, job_id: str\n) -&gt; StatusMsgDict:\n    \"\"\"\n    This function uploads a status file to the backend and creates the status dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The status dict of the job\n    \"\"\"\n    storage_path = \"status/\" + display_name\n    status_draft = {\n        \"job_id\": job_id,\n        \"status\": \"INITIALIZING\",\n        \"detail\": \"Got your json.\",\n        \"error_message\": \"None\",\n    }\n\n    # should we also upload the username into the dict ?\n    status_dict = StatusMsgDict(**status_draft)\n    # now upload the status dict\n    self.upload(\n        content_dict=status_dict.model_dump(),\n        storage_path=storage_path,\n        job_id=job_id,\n    )\n    return status_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProvider","title":"<code>MongodbProvider</code>","text":"<p>             Bases: <code>MongodbProviderExtended</code></p> <p>The access to the mongodb. This is the simplified version for people that are running devices.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class MongodbProvider(MongodbProviderExtended):\n    \"\"\"\n    The access to the mongodb. This is the simplified version for people that are running devices.\n    \"\"\"\n\n    def __init__(self, login_dict: MongodbLoginInformation) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n        \"\"\"\n        super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(self, login_dict: MongodbLoginInformation) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n    \"\"\"\n    super().__init__(login_dict, name=\"default\", is_active=True)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended","title":"<code>MongodbProviderExtended</code>","text":"<p>             Bases: <code>StorageProvider</code></p> <p>The access to the mongodb</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class MongodbProviderExtended(StorageProvider):\n    \"\"\"\n    The access to the mongodb\n    \"\"\"\n\n    def __init__(\n        self, login_dict: MongodbLoginInformation, name: str, is_active: bool = True\n    ) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n\n        Args:\n            login_dict: The login dict that contains the neccessary\n                        information to connect to the mongodb\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n\n\n        Raises:\n            ValidationError: If the login_dict is not valid\n        \"\"\"\n        super().__init__(name, is_active)\n        mongodb_username = login_dict.mongodb_username\n        mongodb_password = login_dict.mongodb_password\n        mongodb_database_url = login_dict.mongodb_database_url\n\n        uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n        uri = uri + \"/?retryWrites=true&amp;w=majority\"\n        # Create a new client and connect to the server\n        self.client: MongoClient = MongoClient(uri)\n\n        # Send a ping to confirm a successful connection\n        self.client.admin.command(\"ping\")\n\n    @validate_active\n    def upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n\n        content_dict: the content that should be uploaded onto the mongodb base\n        storage_path: the access path towards the mongodb collection\n        job_id: the id of the file we are about to create\n        \"\"\"\n        storage_splitted = storage_path.split(\"/\")\n\n        # get the database on which we work\n        database = self.client[storage_splitted[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_splitted[1:])\n        collection = database[collection_name]\n\n        content_dict[\"_id\"] = ObjectId(job_id)\n        collection.insert_one(content_dict)\n\n        # remove the id from the content dict for further use\n        content_dict.pop(\"_id\", None)\n\n    @validate_active\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n        \"\"\"\n        document_to_find = {\"_id\": ObjectId(job_id)}\n\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        result_found = collection.find_one(document_to_find)\n\n        if not result_found:\n            return {}\n\n        # remove the id from the result dict for further use\n        result_found.pop(\"_id\", None)\n        return result_found\n\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n\n        \"\"\"\n        job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n        job_dict.pop(\"_id\", None)\n        return job_dict\n\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        filter_dict = {\"_id\": ObjectId(job_id)}\n\n        newvalues = {\"$set\": content_dict}\n        collection.update_one(filter_dict, newvalues)\n\n    @validate_active\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[start_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(start_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n        result_found = collection.find_one(document_to_find)\n\n        # delete the old file\n        collection.delete_one(document_to_find)\n\n        # add the document to the new collection\n        database = self.client[final_path.split(\"/\")[0]]\n        collection_name = \".\".join(final_path.split(\"/\")[1:])\n        collection = database[collection_name]\n        collection.insert_one(result_found)\n\n    @validate_active\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Remove the file from the mongodb database\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n            job_id: the name of the file\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n        collection.delete_one(document_to_find)\n\n    @validate_active\n    def get_backends(self) -&gt; list[str]:\n        \"\"\"\n        Get a list of all the backends that the provider offers.\n        \"\"\"\n\n        # get the database on which we work\n        database = self.client[\"backends\"]\n        config_collection = database[\"configs\"]\n        # get all the documents in the collection configs and save the disply_name in a list\n        backend_names: list[str] = []\n        for config_dict in config_collection.find():\n            backend_names.append(config_dict[\"display_name\"])\n        return backend_names\n\n    @validate_active\n    def get_backend_dict(self, display_name: str) -&gt; BackendConfigSchemaOut:\n        \"\"\"\n        The configuration dictionary of the backend such that it can be sent out to the API to\n        the common user. We make sure that it is compatible with QISKIT within this function.\n\n        Args:\n            display_name: The identifier of the backend\n\n        Returns:\n            The full schema of the backend.\n        \"\"\"\n        # get the database on which we work\n        database = self.client[\"backends\"]\n        config_collection = database[\"configs\"]\n\n        # create the filter for the document with display_name that is equal to display_name\n        document_to_find = {\"display_name\": display_name}\n        backend_config_dict = config_collection.find_one(document_to_find)\n\n        if not backend_config_dict:\n            raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n        backend_config_dict.pop(\"_id\")\n        backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n        qiskit_backend_dict = self.backend_dict_to_qiskit(backend_config_info)\n        return qiskit_backend_dict\n\n    def get_backend_status(self, display_name: str) -&gt; BackendStatusSchemaOut:\n        \"\"\"\n        Get the status of the backend. This follows the qiskit logic.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The status dict of the backend\n\n        Raises:\n            FileNotFoundError: If the backend does not exist\n        \"\"\"\n        # get the database on which we work\n        database = self.client[\"backends\"]\n        config_collection = database[\"configs\"]\n\n        # create the filter for the document with display_name that is equal to display_name\n        document_to_find = {\"display_name\": display_name}\n        backend_config_dict = config_collection.find_one(document_to_find)\n\n        if not backend_config_dict:\n            raise FileNotFoundError(\n                f\"The backend {display_name} does not exist for the given storageprovider.\"\n            )\n\n        backend_config_dict.pop(\"_id\")\n        backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n        qiskit_backend_dict = self.backend_dict_to_qiskit_status(backend_config_info)\n        return qiskit_backend_dict\n\n    def upload_config(\n        self, config_dict: BackendConfigSchemaIn, backend_name: str\n    ) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        config_path = \"backends/configs\"\n\n        # first we have to check if the device already exists in the database\n\n        document_to_find = {\"display_name\": backend_name}\n\n        # get the database on which we work\n        database = self.client[\"backends\"]\n\n        # get the collection on which we work\n        collection = database[\"configs\"]\n\n        result_found = collection.find_one(document_to_find)\n        config_dict.display_name = backend_name\n        if result_found:\n            # update the file\n            self.update_file(\n                content_dict=config_dict.model_dump(),\n                storage_path=config_path,\n                job_id=result_found[\"_id\"],\n            )\n            return\n\n        # if the device does not exist, we have to create it\n\n        config_id = uuid.uuid4().hex[:24]\n        self.upload(config_dict.model_dump(), config_path, config_id)\n\n    def upload_job(self, job_dict: dict, display_name: str, username: str) -&gt; str:\n        \"\"\"\n        Upload the job to the storage provider.\n\n        Args:\n            job_dict: the full job dict\n            display_name: the name of the backend\n            username: the name of the user that submitted the job\n\n        Returns:\n            The job id of the uploaded job.\n        \"\"\"\n\n        storage_path = \"jobs/queued/\" + display_name\n        job_id = (uuid.uuid4().hex)[:24]\n\n        self.upload(content_dict=job_dict, storage_path=storage_path, job_id=job_id)\n        return job_id\n\n    def upload_status(\n        self, display_name: str, username: str, job_id: str\n    ) -&gt; StatusMsgDict:\n        \"\"\"\n        This function uploads a status file to the backend and creates the status dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The status dict of the job\n        \"\"\"\n        storage_path = \"status/\" + display_name\n        status_draft = {\n            \"job_id\": job_id,\n            \"status\": \"INITIALIZING\",\n            \"detail\": \"Got your json.\",\n            \"error_message\": \"None\",\n        }\n\n        # should we also upload the username into the dict ?\n        status_dict = StatusMsgDict(**status_draft)\n        # now upload the status dict\n        self.upload(\n            content_dict=status_dict.model_dump(),\n            storage_path=storage_path,\n            job_id=job_id,\n        )\n        return status_dict\n\n    def get_status(\n        self, display_name: str, username: str, job_id: str\n    ) -&gt; StatusMsgDict:\n        \"\"\"\n        This function gets the status file from the backend and returns the status dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The status dict of the job\n        \"\"\"\n        status_json_dir = \"status/\" + display_name\n\n        status_dict = self.get_file_content(storage_path=status_json_dir, job_id=job_id)\n        return StatusMsgDict(**status_dict)\n\n    def get_result(self, display_name: str, username: str, job_id: str) -&gt; ResultDict:\n        \"\"\"\n        This function gets the result file from the backend and returns the result dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The result dict of the job\n        \"\"\"\n        result_json_dir = \"results/\" + display_name\n        result_dict = self.get_file_content(storage_path=result_json_dir, job_id=job_id)\n        backend_config_info = self.get_backend_dict(display_name)\n        result_dict[\"backend_name\"] = backend_config_info.backend_name\n\n        typed_result = ResultDict(**result_dict)\n        return typed_result\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict | None,\n        status_msg_dict: StatusMsgDict,\n        job_id: str,\n        backend_name: str,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        The function checks if the reported status of the job has changed to DONE. If so, it will create\n        a result json file and move the job json file to the finished folder. It will also update the\n        status json file.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n\n        Raises:\n\n        \"\"\"\n\n        job_json_start_dir = \"jobs/running\"\n        # check if the job is done or had an error\n        if status_msg_dict.status == \"DONE\":\n            # test if the result dict is None\n            if result_dict is None:\n                raise ValueError(\n                    \"The 'result_dict' argument cannot be None if the job is done.\"\n                )\n            # let us create the result json file\n            result_json_dir = \"results/\" + backend_name\n            self.upload(result_dict.model_dump(), result_json_dir, job_id)\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = \"jobs/finished/\" + backend_name\n            self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n        elif status_msg_dict.status == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = \"jobs/deleted\"\n            self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n        # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n        # and create the status json file\n        status_json_dir = \"status/\" + backend_name\n        self.update_file(status_msg_dict.model_dump(), status_json_dir, job_id)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of documents in the collection of all the queued jobs.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n        # strip trailing and leading slashes from the paths\n        storage_path = storage_path.strip(\"/\")\n\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        # now get the id of all the documents in the collection\n        results = collection.find({}, {\"_id\": 1})\n        file_list = []\n        for result in results:\n            file_list.append(str(result[\"_id\"]))\n        return file_list\n\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n        \"\"\"\n        A function that obtains the next job in the queue. It looks in the queued folder and moves the\n        first job to the running folder.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n\n        queue_dir = \"jobs/queued/\" + backend_name\n        job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n        job_list = self.get_file_queue(queue_dir)\n        # if there is a job, we should move it\n        if job_list:\n            job_id = job_list[0]\n            job_dict[\"job_id\"] = job_id\n\n            # and move the file into the right directory\n            self.move_file(queue_dir, \"jobs/running\", job_id)\n            job_dict[\"job_json_path\"] = \"jobs/running\"\n        return job_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.__init__","title":"<code>__init__(login_dict, name, is_active=True)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> <p>Parameters:</p> Name Type Description Default <code>login_dict</code> <code>MongodbLoginInformation</code> <p>The login dict that contains the neccessary         information to connect to the mongodb</p> required <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the login_dict is not valid</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(\n    self, login_dict: MongodbLoginInformation, name: str, is_active: bool = True\n) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n\n    Args:\n        login_dict: The login dict that contains the neccessary\n                    information to connect to the mongodb\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n\n\n    Raises:\n        ValidationError: If the login_dict is not valid\n    \"\"\"\n    super().__init__(name, is_active)\n    mongodb_username = login_dict.mongodb_username\n    mongodb_password = login_dict.mongodb_password\n    mongodb_database_url = login_dict.mongodb_database_url\n\n    uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n    uri = uri + \"/?retryWrites=true&amp;w=majority\"\n    # Create a new client and connect to the server\n    self.client: MongoClient = MongoClient(uri)\n\n    # Send a ping to confirm a successful connection\n    self.client.admin.command(\"ping\")\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Remove the file from the mongodb database</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file is currently stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef delete_file(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Remove the file from the mongodb database\n\n    Args:\n        storage_path: the path where the file is currently stored, but excluding the file name\n        job_id: the name of the file\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n    collection.delete_one(document_to_find)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_backend_dict","title":"<code>get_backend_dict(display_name)</code>","text":"<p>The configuration dictionary of the backend such that it can be sent out to the API to the common user. We make sure that it is compatible with QISKIT within this function.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The identifier of the backend</p> required <p>Returns:</p> Type Description <code>BackendConfigSchemaOut</code> <p>The full schema of the backend.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef get_backend_dict(self, display_name: str) -&gt; BackendConfigSchemaOut:\n    \"\"\"\n    The configuration dictionary of the backend such that it can be sent out to the API to\n    the common user. We make sure that it is compatible with QISKIT within this function.\n\n    Args:\n        display_name: The identifier of the backend\n\n    Returns:\n        The full schema of the backend.\n    \"\"\"\n    # get the database on which we work\n    database = self.client[\"backends\"]\n    config_collection = database[\"configs\"]\n\n    # create the filter for the document with display_name that is equal to display_name\n    document_to_find = {\"display_name\": display_name}\n    backend_config_dict = config_collection.find_one(document_to_find)\n\n    if not backend_config_dict:\n        raise FileNotFoundError(\"The backend does not exist for the given storage.\")\n\n    backend_config_dict.pop(\"_id\")\n    backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n    qiskit_backend_dict = self.backend_dict_to_qiskit(backend_config_info)\n    return qiskit_backend_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_backend_status","title":"<code>get_backend_status(display_name)</code>","text":"<p>Get the status of the backend. This follows the qiskit logic.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>BackendStatusSchemaOut</code> <p>The status dict of the backend</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the backend does not exist</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_backend_status(self, display_name: str) -&gt; BackendStatusSchemaOut:\n    \"\"\"\n    Get the status of the backend. This follows the qiskit logic.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The status dict of the backend\n\n    Raises:\n        FileNotFoundError: If the backend does not exist\n    \"\"\"\n    # get the database on which we work\n    database = self.client[\"backends\"]\n    config_collection = database[\"configs\"]\n\n    # create the filter for the document with display_name that is equal to display_name\n    document_to_find = {\"display_name\": display_name}\n    backend_config_dict = config_collection.find_one(document_to_find)\n\n    if not backend_config_dict:\n        raise FileNotFoundError(\n            f\"The backend {display_name} does not exist for the given storageprovider.\"\n        )\n\n    backend_config_dict.pop(\"_id\")\n    backend_config_info = BackendConfigSchemaIn(**backend_config_dict)\n    qiskit_backend_dict = self.backend_dict_to_qiskit_status(backend_config_info)\n    return qiskit_backend_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_backends","title":"<code>get_backends()</code>","text":"<p>Get a list of all the backends that the provider offers.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef get_backends(self) -&gt; list[str]:\n    \"\"\"\n    Get a list of all the backends that the provider offers.\n    \"\"\"\n\n    # get the database on which we work\n    database = self.client[\"backends\"]\n    config_collection = database[\"configs\"]\n    # get all the documents in the collection configs and save the disply_name in a list\n    backend_names: list[str] = []\n    for config_dict in config_collection.find():\n        backend_names.append(config_dict[\"display_name\"])\n    return backend_names\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Get the file content from the storage</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n    \"\"\"\n    document_to_find = {\"_id\": ObjectId(job_id)}\n\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    result_found = collection.find_one(document_to_find)\n\n    if not result_found:\n        return {}\n\n    # remove the id from the result dict for further use\n    result_found.pop(\"_id\", None)\n    return result_found\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of documents in the collection of all the queued jobs.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of documents in the collection of all the queued jobs.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n    # strip trailing and leading slashes from the paths\n    storage_path = storage_path.strip(\"/\")\n\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    # now get the id of all the documents in the collection\n    results = collection.find({}, {\"_id\": 1})\n    file_list = []\n    for result in results:\n        file_list.append(str(result[\"_id\"]))\n    return file_list\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n\n    \"\"\"\n    job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n    job_dict.pop(\"_id\", None)\n    return job_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>","text":"<p>A function that obtains the next job in the queue. It looks in the queued folder and moves the first job to the running folder.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n    \"\"\"\n    A function that obtains the next job in the queue. It looks in the queued folder and moves the\n    first job to the running folder.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n\n    queue_dir = \"jobs/queued/\" + backend_name\n    job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n    job_list = self.get_file_queue(queue_dir)\n    # if there is a job, we should move it\n    if job_list:\n        job_id = job_list[0]\n        job_dict[\"job_id\"] = job_id\n\n        # and move the file into the right directory\n        self.move_file(queue_dir, \"jobs/running\", job_id)\n        job_dict[\"job_json_path\"] = \"jobs/running\"\n    return job_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_result","title":"<code>get_result(display_name, username, job_id)</code>","text":"<p>This function gets the result file from the backend and returns the result dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>ResultDict</code> <p>The result dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_result(self, display_name: str, username: str, job_id: str) -&gt; ResultDict:\n    \"\"\"\n    This function gets the result file from the backend and returns the result dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The result dict of the job\n    \"\"\"\n    result_json_dir = \"results/\" + display_name\n    result_dict = self.get_file_content(storage_path=result_json_dir, job_id=job_id)\n    backend_config_info = self.get_backend_dict(display_name)\n    result_dict[\"backend_name\"] = backend_config_info.backend_name\n\n    typed_result = ResultDict(**result_dict)\n    return typed_result\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.get_status","title":"<code>get_status(display_name, username, job_id)</code>","text":"<p>This function gets the status file from the backend and returns the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_status(\n    self, display_name: str, username: str, job_id: str\n) -&gt; StatusMsgDict:\n    \"\"\"\n    This function gets the status file from the backend and returns the status dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The status dict of the job\n    \"\"\"\n    status_json_dir = \"status/\" + display_name\n\n    status_dict = self.get_file_content(storage_path=status_json_dir, job_id=job_id)\n    return StatusMsgDict(**status_dict)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[start_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(start_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n    result_found = collection.find_one(document_to_find)\n\n    # delete the old file\n    collection.delete_one(document_to_find)\n\n    # add the document to the new collection\n    database = self.client[final_path.split(\"/\")[0]]\n    collection_name = \".\".join(final_path.split(\"/\")[1:])\n    collection = database[collection_name]\n    collection.insert_one(result_found)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    filter_dict = {\"_id\": ObjectId(job_id)}\n\n    newvalues = {\"$set\": content_dict}\n    collection.update_one(filter_dict, newvalues)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>The function checks if the reported status of the job has changed to DONE. If so, it will create a result json file and move the job json file to the finished folder. It will also update the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict | None</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict | None,\n    status_msg_dict: StatusMsgDict,\n    job_id: str,\n    backend_name: str,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    The function checks if the reported status of the job has changed to DONE. If so, it will create\n    a result json file and move the job json file to the finished folder. It will also update the\n    status json file.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n\n    Raises:\n\n    \"\"\"\n\n    job_json_start_dir = \"jobs/running\"\n    # check if the job is done or had an error\n    if status_msg_dict.status == \"DONE\":\n        # test if the result dict is None\n        if result_dict is None:\n            raise ValueError(\n                \"The 'result_dict' argument cannot be None if the job is done.\"\n            )\n        # let us create the result json file\n        result_json_dir = \"results/\" + backend_name\n        self.upload(result_dict.model_dump(), result_json_dir, job_id)\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = \"jobs/finished/\" + backend_name\n        self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n    elif status_msg_dict.status == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = \"jobs/deleted\"\n        self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n    # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n    # and create the status json file\n    status_json_dir = \"status/\" + backend_name\n    self.update_file(status_msg_dict.model_dump(), status_json_dir, job_id)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the file to the storage</p> <p>content_dict: the content that should be uploaded onto the mongodb base storage_path: the access path towards the mongodb collection job_id: the id of the file we are about to create</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@validate_active\ndef upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n\n    content_dict: the content that should be uploaded onto the mongodb base\n    storage_path: the access path towards the mongodb collection\n    job_id: the id of the file we are about to create\n    \"\"\"\n    storage_splitted = storage_path.split(\"/\")\n\n    # get the database on which we work\n    database = self.client[storage_splitted[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_splitted[1:])\n    collection = database[collection_name]\n\n    content_dict[\"_id\"] = ObjectId(job_id)\n    collection.insert_one(content_dict)\n\n    # remove the id from the content dict for further use\n    content_dict.pop(\"_id\", None)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_config(\n    self, config_dict: BackendConfigSchemaIn, backend_name: str\n) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    config_path = \"backends/configs\"\n\n    # first we have to check if the device already exists in the database\n\n    document_to_find = {\"display_name\": backend_name}\n\n    # get the database on which we work\n    database = self.client[\"backends\"]\n\n    # get the collection on which we work\n    collection = database[\"configs\"]\n\n    result_found = collection.find_one(document_to_find)\n    config_dict.display_name = backend_name\n    if result_found:\n        # update the file\n        self.update_file(\n            content_dict=config_dict.model_dump(),\n            storage_path=config_path,\n            job_id=result_found[\"_id\"],\n        )\n        return\n\n    # if the device does not exist, we have to create it\n\n    config_id = uuid.uuid4().hex[:24]\n    self.upload(config_dict.model_dump(), config_path, config_id)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.upload_job","title":"<code>upload_job(job_dict, display_name, username)</code>","text":"<p>Upload the job to the storage provider.</p> <p>Parameters:</p> Name Type Description Default <code>job_dict</code> <code>dict</code> <p>the full job dict</p> required <code>display_name</code> <code>str</code> <p>the name of the backend</p> required <code>username</code> <code>str</code> <p>the name of the user that submitted the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job id of the uploaded job.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_job(self, job_dict: dict, display_name: str, username: str) -&gt; str:\n    \"\"\"\n    Upload the job to the storage provider.\n\n    Args:\n        job_dict: the full job dict\n        display_name: the name of the backend\n        username: the name of the user that submitted the job\n\n    Returns:\n        The job id of the uploaded job.\n    \"\"\"\n\n    storage_path = \"jobs/queued/\" + display_name\n    job_id = (uuid.uuid4().hex)[:24]\n\n    self.upload(content_dict=job_dict, storage_path=storage_path, job_id=job_id)\n    return job_id\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.MongodbProviderExtended.upload_status","title":"<code>upload_status(display_name, username, job_id)</code>","text":"<p>This function uploads a status file to the backend and creates the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_status(\n    self, display_name: str, username: str, job_id: str\n) -&gt; StatusMsgDict:\n    \"\"\"\n    This function uploads a status file to the backend and creates the status dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The status dict of the job\n    \"\"\"\n    storage_path = \"status/\" + display_name\n    status_draft = {\n        \"job_id\": job_id,\n        \"status\": \"INITIALIZING\",\n        \"detail\": \"Got your json.\",\n        \"error_message\": \"None\",\n    }\n\n    # should we also upload the username into the dict ?\n    status_dict = StatusMsgDict(**status_draft)\n    # now upload the status dict\n    self.upload(\n        content_dict=status_dict.model_dump(),\n        storage_path=storage_path,\n        job_id=job_id,\n    )\n    return status_dict\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider","title":"<code>StorageProvider</code>","text":"<p>             Bases: <code>ABC</code></p> <p>The template for accessing any storage providers like dropbox, mongodb, amazon S3 etc.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class StorageProvider(ABC):\n    \"\"\"\n    The template for accessing any storage providers like dropbox, mongodb, amazon S3 etc.\n    \"\"\"\n\n    def __init__(self, name: str, is_active: bool = True) -&gt; None:\n        \"\"\"\n        Any storage provide must have a name that is not empty.\n\n        Args:\n            name: The name of the storage provider\n            is_active: Is the storage provider active.\n        \"\"\"\n        if not name:\n            raise ValueError(\"The name of the storage provider cannot be empty.\")\n        self.name = name\n        self.is_active = is_active\n\n    @abstractmethod\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n        \"\"\"\n\n    @abstractmethod\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n        \"\"\"\n\n    @abstractmethod\n    def get_backends(self) -&gt; list[str]:\n        \"\"\"\n        Get a list of all the backends that the provider offers.\n        \"\"\"\n\n    @abstractmethod\n    def get_backend_dict(self, display_name: str) -&gt; BackendConfigSchemaOut:\n        \"\"\"\n        The configuration of the backend.\n\n        Args:\n            display_name: The identifier of the backend\n\n        Returns:\n            The full schema of the backend.\n        \"\"\"\n\n    @abstractmethod\n    def get_backend_status(self, display_name: str) -&gt; BackendStatusSchemaOut:\n        \"\"\"\n        Get the status of the backend. This follows the qiskit logic.\n\n        Args:\n            display_name: The name of the backend\n\n        Returns:\n            The status dict of the backend\n        \"\"\"\n\n    @abstractmethod\n    def upload_job(self, job_dict: dict, display_name: str, username: str) -&gt; str:\n        \"\"\"\n        Upload the job to the storage provider.\n\n        Args:\n            job_dict: the full job dict\n            display_name: the name of the backend\n            username: the name of the user that submitted the job\n\n        Returns:\n            The job id of the uploaded job.\n        \"\"\"\n\n    @abstractmethod\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the job\n        \"\"\"\n\n    @abstractmethod\n    def upload_status(\n        self, display_name: str, username: str, job_id: str\n    ) -&gt; StatusMsgDict:\n        \"\"\"\n        This function uploads a status file to the backend and creates the status dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The status dict of the job\n        \"\"\"\n\n    @abstractmethod\n    def get_status(\n        self, display_name: str, username: str, job_id: str\n    ) -&gt; StatusMsgDict:\n        \"\"\"\n        This function gets the status file from the backend and returns the status dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The status dict of the job\n        \"\"\"\n\n    @abstractmethod\n    def get_result(self, display_name: str, username: str, job_id: str) -&gt; ResultDict:\n        \"\"\"\n        This function gets the result file from the backend and returns the result dict.\n\n        Args:\n            display_name: The name of the backend to which we want to upload the job\n            username: The username of the user that is uploading the job\n            job_id: The job_id of the job that we want to upload the status for\n\n        Returns:\n            The result dict of the job\n        \"\"\"\n\n    @abstractmethod\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from `start_path` to `final_path`\n        \"\"\"\n\n    @abstractmethod\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Delete the file from the storage\n        \"\"\"\n\n    @abstractmethod\n    def upload_config(\n        self, config_dict: BackendConfigSchemaIn, backend_name: str\n    ) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The model containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def update_in_database(\n        self,\n        result_dict: ResultDict,\n        status_msg_dict: StatusMsgDict,\n        job_id: str,\n        backend_name: str,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of files\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n    @abstractmethod\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n        \"\"\"\n        A function that obtains the next job in the queue.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n\n    def backend_dict_to_qiskit(\n        self, backend_config_info: BackendConfigSchemaIn\n    ) -&gt; BackendConfigSchemaOut:\n        \"\"\"\n        This function transforms the dictionary that is safed in the storage provider\n        into a qiskit backend dictionnary.\n\n        Args:\n            backend_config_info: The dictionary that contains the configuration of the backend\n\n        Returns:\n            The qiskit backend dictionary\n        \"\"\"\n        backend_config_dict = backend_config_info.model_dump()\n        display_name = backend_config_dict[\"display_name\"]\n        # for comaptibility with qiskit\n        backend_config_dict[\"basis_gates\"] = []\n        for gate in backend_config_dict[\"gates\"]:\n            backend_config_dict[\"basis_gates\"].append(gate[\"name\"])\n\n        # if the name is already in the dict, we should set the backend_name to the name\n        # otherwise we calculate it.\n        if backend_config_dict[\"simulator\"]:\n            backend_name = f\"{self.name}_{display_name}_simulator\"\n        else:\n            backend_name = f\"{self.name}_{display_name}_hardware\"\n\n        backend_config_dict[\"backend_name\"] = backend_name\n        backend_config_dict[\"n_qubits\"] = backend_config_dict[\"num_wires\"]\n        backend_config_dict[\"backend_version\"] = backend_config_dict[\"version\"]\n\n        backend_config_dict[\"conditional\"] = False\n        backend_config_dict[\"local\"] = False\n        backend_config_dict[\"open_pulse\"] = False\n        backend_config_dict[\"memory\"] = True\n        backend_config_dict[\"coupling_map\"] = \"linear\"\n        return BackendConfigSchemaOut(**backend_config_dict)\n\n    def backend_dict_to_qiskit_status(\n        self, backend_dict: BackendConfigSchemaIn\n    ) -&gt; BackendStatusSchemaOut:\n        \"\"\"\n        This function transforms the dictionary that is safed in the storage provider\n        into a qiskit backend status dictionnary.\n\n        Args:\n            backend_dict: The dictionary that contains the configuration of the backend\n\n        Returns:\n            The qiskit backend dictionary\n        \"\"\"\n        backend_status_dict = {\n            \"backend_name\": \"\",\n            \"backend_version\": \"\",\n            \"operational\": True,\n            \"pending_jobs\": 0,\n            \"status_msg\": \"\",\n        }\n\n        display_name = backend_dict.display_name\n\n        # if the name is already in the dict, we should set the backend_name to the name\n        # otherwise we calculate it.\n        if backend_dict.simulator:\n            backend_name = f\"{self.name}_{display_name}_simulator\"\n        else:\n            backend_name = f\"{self.name}_{display_name}_hardware\"\n\n        backend_status_dict[\"backend_name\"] = backend_name\n        backend_status_dict[\"backend_version\"] = backend_dict.version\n\n        # now I also need to obtain the operational status from the backend.\n        backend_status_dict[\"operational\"] = backend_dict.operational\n\n        # would be nice to attempt to get the pending jobs too, if possible easily.\n        if backend_dict.pending_jobs:\n            backend_status_dict[\"pending_jobs\"] = backend_dict.pending_jobs\n        else:\n            backend_status_dict[\"pending_jobs\"] = 0\n\n        # and also handle the status message which is currently optional BackendConfigSchemaIn\n        if backend_dict.status_msg:\n            backend_status_dict[\"status_msg\"] = backend_dict.status_msg\n        else:\n            backend_status_dict[\"status_msg\"] = \"\"\n        return BackendStatusSchemaOut(**backend_status_dict)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.__init__","title":"<code>__init__(name, is_active=True)</code>","text":"<p>Any storage provide must have a name that is not empty.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the storage provider</p> required <code>is_active</code> <code>bool</code> <p>Is the storage provider active.</p> <code>True</code> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(self, name: str, is_active: bool = True) -&gt; None:\n    \"\"\"\n    Any storage provide must have a name that is not empty.\n\n    Args:\n        name: The name of the storage provider\n        is_active: Is the storage provider active.\n    \"\"\"\n    if not name:\n        raise ValueError(\"The name of the storage provider cannot be empty.\")\n    self.name = name\n    self.is_active = is_active\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.backend_dict_to_qiskit","title":"<code>backend_dict_to_qiskit(backend_config_info)</code>","text":"<p>This function transforms the dictionary that is safed in the storage provider into a qiskit backend dictionnary.</p> <p>Parameters:</p> Name Type Description Default <code>backend_config_info</code> <code>BackendConfigSchemaIn</code> <p>The dictionary that contains the configuration of the backend</p> required <p>Returns:</p> Type Description <code>BackendConfigSchemaOut</code> <p>The qiskit backend dictionary</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def backend_dict_to_qiskit(\n    self, backend_config_info: BackendConfigSchemaIn\n) -&gt; BackendConfigSchemaOut:\n    \"\"\"\n    This function transforms the dictionary that is safed in the storage provider\n    into a qiskit backend dictionnary.\n\n    Args:\n        backend_config_info: The dictionary that contains the configuration of the backend\n\n    Returns:\n        The qiskit backend dictionary\n    \"\"\"\n    backend_config_dict = backend_config_info.model_dump()\n    display_name = backend_config_dict[\"display_name\"]\n    # for comaptibility with qiskit\n    backend_config_dict[\"basis_gates\"] = []\n    for gate in backend_config_dict[\"gates\"]:\n        backend_config_dict[\"basis_gates\"].append(gate[\"name\"])\n\n    # if the name is already in the dict, we should set the backend_name to the name\n    # otherwise we calculate it.\n    if backend_config_dict[\"simulator\"]:\n        backend_name = f\"{self.name}_{display_name}_simulator\"\n    else:\n        backend_name = f\"{self.name}_{display_name}_hardware\"\n\n    backend_config_dict[\"backend_name\"] = backend_name\n    backend_config_dict[\"n_qubits\"] = backend_config_dict[\"num_wires\"]\n    backend_config_dict[\"backend_version\"] = backend_config_dict[\"version\"]\n\n    backend_config_dict[\"conditional\"] = False\n    backend_config_dict[\"local\"] = False\n    backend_config_dict[\"open_pulse\"] = False\n    backend_config_dict[\"memory\"] = True\n    backend_config_dict[\"coupling_map\"] = \"linear\"\n    return BackendConfigSchemaOut(**backend_config_dict)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.backend_dict_to_qiskit_status","title":"<code>backend_dict_to_qiskit_status(backend_dict)</code>","text":"<p>This function transforms the dictionary that is safed in the storage provider into a qiskit backend status dictionnary.</p> <p>Parameters:</p> Name Type Description Default <code>backend_dict</code> <code>BackendConfigSchemaIn</code> <p>The dictionary that contains the configuration of the backend</p> required <p>Returns:</p> Type Description <code>BackendStatusSchemaOut</code> <p>The qiskit backend dictionary</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def backend_dict_to_qiskit_status(\n    self, backend_dict: BackendConfigSchemaIn\n) -&gt; BackendStatusSchemaOut:\n    \"\"\"\n    This function transforms the dictionary that is safed in the storage provider\n    into a qiskit backend status dictionnary.\n\n    Args:\n        backend_dict: The dictionary that contains the configuration of the backend\n\n    Returns:\n        The qiskit backend dictionary\n    \"\"\"\n    backend_status_dict = {\n        \"backend_name\": \"\",\n        \"backend_version\": \"\",\n        \"operational\": True,\n        \"pending_jobs\": 0,\n        \"status_msg\": \"\",\n    }\n\n    display_name = backend_dict.display_name\n\n    # if the name is already in the dict, we should set the backend_name to the name\n    # otherwise we calculate it.\n    if backend_dict.simulator:\n        backend_name = f\"{self.name}_{display_name}_simulator\"\n    else:\n        backend_name = f\"{self.name}_{display_name}_hardware\"\n\n    backend_status_dict[\"backend_name\"] = backend_name\n    backend_status_dict[\"backend_version\"] = backend_dict.version\n\n    # now I also need to obtain the operational status from the backend.\n    backend_status_dict[\"operational\"] = backend_dict.operational\n\n    # would be nice to attempt to get the pending jobs too, if possible easily.\n    if backend_dict.pending_jobs:\n        backend_status_dict[\"pending_jobs\"] = backend_dict.pending_jobs\n    else:\n        backend_status_dict[\"pending_jobs\"] = 0\n\n    # and also handle the status message which is currently optional BackendConfigSchemaIn\n    if backend_dict.status_msg:\n        backend_status_dict[\"status_msg\"] = backend_dict.status_msg\n    else:\n        backend_status_dict[\"status_msg\"] = \"\"\n    return BackendStatusSchemaOut(**backend_status_dict)\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.delete_file","title":"<code>delete_file(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Delete the file from the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef delete_file(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Delete the file from the storage\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_backend_dict","title":"<code>get_backend_dict(display_name)</code>  <code>abstractmethod</code>","text":"<p>The configuration of the backend.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The identifier of the backend</p> required <p>Returns:</p> Type Description <code>BackendConfigSchemaOut</code> <p>The full schema of the backend.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_backend_dict(self, display_name: str) -&gt; BackendConfigSchemaOut:\n    \"\"\"\n    The configuration of the backend.\n\n    Args:\n        display_name: The identifier of the backend\n\n    Returns:\n        The full schema of the backend.\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_backend_status","title":"<code>get_backend_status(display_name)</code>  <code>abstractmethod</code>","text":"<p>Get the status of the backend. This follows the qiskit logic.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>BackendStatusSchemaOut</code> <p>The status dict of the backend</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_backend_status(self, display_name: str) -&gt; BackendStatusSchemaOut:\n    \"\"\"\n    Get the status of the backend. This follows the qiskit logic.\n\n    Args:\n        display_name: The name of the backend\n\n    Returns:\n        The status dict of the backend\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_backends","title":"<code>get_backends()</code>  <code>abstractmethod</code>","text":"<p>Get a list of all the backends that the provider offers.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_backends(self) -&gt; list[str]:\n    \"\"\"\n    Get a list of all the backends that the provider offers.\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the file content from the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>  <code>abstractmethod</code>","text":"<p>Get a list of files</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of files\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the job\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>  <code>abstractmethod</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n    \"\"\"\n    A function that obtains the next job in the queue.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_result","title":"<code>get_result(display_name, username, job_id)</code>  <code>abstractmethod</code>","text":"<p>This function gets the result file from the backend and returns the result dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>ResultDict</code> <p>The result dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_result(self, display_name: str, username: str, job_id: str) -&gt; ResultDict:\n    \"\"\"\n    This function gets the result file from the backend and returns the result dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The result dict of the job\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.get_status","title":"<code>get_status(display_name, username, job_id)</code>  <code>abstractmethod</code>","text":"<p>This function gets the status file from the backend and returns the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_status(\n    self, display_name: str, username: str, job_id: str\n) -&gt; StatusMsgDict:\n    \"\"\"\n    This function gets the status file from the backend and returns the status dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The status dict of the job\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Move the file from <code>start_path</code> to <code>final_path</code></p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from `start_path` to `final_path`\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>  <code>abstractmethod</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>StatusMsgDict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef update_in_database(\n    self,\n    result_dict: ResultDict,\n    status_msg_dict: StatusMsgDict,\n    job_id: str,\n    backend_name: str,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Upload the file to the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>  <code>abstractmethod</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>BackendConfigSchemaIn</code> <p>The model containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef upload_config(\n    self, config_dict: BackendConfigSchemaIn, backend_name: str\n) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The model containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.upload_job","title":"<code>upload_job(job_dict, display_name, username)</code>  <code>abstractmethod</code>","text":"<p>Upload the job to the storage provider.</p> <p>Parameters:</p> Name Type Description Default <code>job_dict</code> <code>dict</code> <p>the full job dict</p> required <code>display_name</code> <code>str</code> <p>the name of the backend</p> required <code>username</code> <code>str</code> <p>the name of the user that submitted the job</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job id of the uploaded job.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef upload_job(self, job_dict: dict, display_name: str, username: str) -&gt; str:\n    \"\"\"\n    Upload the job to the storage provider.\n\n    Args:\n        job_dict: the full job dict\n        display_name: the name of the backend\n        username: the name of the user that submitted the job\n\n    Returns:\n        The job id of the uploaded job.\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.StorageProvider.upload_status","title":"<code>upload_status(display_name, username, job_id)</code>  <code>abstractmethod</code>","text":"<p>This function uploads a status file to the backend and creates the status dict.</p> <p>Parameters:</p> Name Type Description Default <code>display_name</code> <code>str</code> <p>The name of the backend to which we want to upload the job</p> required <code>username</code> <code>str</code> <p>The username of the user that is uploading the job</p> required <code>job_id</code> <code>str</code> <p>The job_id of the job that we want to upload the status for</p> required <p>Returns:</p> Type Description <code>StatusMsgDict</code> <p>The status dict of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef upload_status(\n    self, display_name: str, username: str, job_id: str\n) -&gt; StatusMsgDict:\n    \"\"\"\n    This function uploads a status file to the backend and creates the status dict.\n\n    Args:\n        display_name: The name of the backend to which we want to upload the job\n        username: The username of the user that is uploading the job\n        job_id: The job_id of the job that we want to upload the status for\n\n    Returns:\n        The status dict of the job\n    \"\"\"\n</code></pre>"},{"location":"storage_providers/#src.sqooler.storage_providers.validate_active","title":"<code>validate_active(func)</code>","text":"<p>Decorator to check if the storage provider is active.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def validate_active(func: Callable) -&gt; Callable:\n    \"\"\"\n    Decorator to check if the storage provider is active.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapper(self: Any, *args: Any, **kwargs: Any) -&gt; Callable:\n        \"\"\"\n        Wrapper around the function that checks if the storage provider is active.\"\"\"\n        if not self.is_active:\n            raise ValueError(\"The storage provider is not active.\")\n        return func(self, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"utils/","title":"API documentation of utils","text":"<p>This module contains some functions that are especially helpful for deployment of the  sqooler package.</p>"},{"location":"utils/#src.sqooler.utils.create_memory_data","title":"<code>create_memory_data(shots_array, exp_name, n_shots)</code>","text":"<p>The function to create memory key in results dictionary with proprer formatting.</p> Source code in <code>src/sqooler/utils.py</code> <pre><code>def create_memory_data(\n    shots_array: list, exp_name: str, n_shots: int\n) -&gt; ExperimentDict:\n    \"\"\"\n    The function to create memory key in results dictionary\n    with proprer formatting.\n    \"\"\"\n    exp_sub_dict: dict = {\n        \"header\": {\"name\": \"experiment_0\", \"extra metadata\": \"text\"},\n        \"shots\": 3,\n        \"success\": True,\n        \"data\": {\"memory\": None},\n    }\n\n    exp_sub_dict[\"header\"][\"name\"] = exp_name\n    exp_sub_dict[\"shots\"] = n_shots\n    memory_list = [\n        str(shot).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n        for shot in shots_array\n    ]\n    exp_sub_dict[\"data\"][\"memory\"] = memory_list\n    return ExperimentDict(**exp_sub_dict)\n</code></pre>"},{"location":"utils/#src.sqooler.utils.gate_dict_from_list","title":"<code>gate_dict_from_list(inst_list)</code>","text":"<p>Transforms a list into an appropiate dictionnary for instructions. The list is assumed to be in the format [name, wires, params].</p> <p>Parameters:</p> Name Type Description Default <code>inst_list</code> <code>list</code> <p>The list that should be transformed.</p> required <p>Returns:</p> Type Description <code>GateDict</code> <p>A GateDict object.</p> Source code in <code>src/sqooler/utils.py</code> <pre><code>def gate_dict_from_list(inst_list: list) -&gt; GateDict:\n    \"\"\"\n    Transforms a list into an appropiate dictionnary for instructions. The list\n    is assumed to be in the format [name, wires, params].\n\n    Args:\n        inst_list: The list that should be transformed.\n\n    Returns:\n        A GateDict object.\n    \"\"\"\n    gate_draft = {\"name\": inst_list[0], \"wires\": inst_list[1], \"params\": inst_list[2]}\n    return GateDict(**gate_draft)\n</code></pre>"},{"location":"utils/#src.sqooler.utils.main","title":"<code>main(storage_provider, backends, num_iter=0)</code>","text":"<p>Function for processing jobs continuously.</p> <p>Parameters:</p> Name Type Description Default <code>storage_provider</code> <code>StorageProvider</code> <p>The storage provider that should be used.</p> required <code>backends</code> <code>dict[str, Spooler]</code> <p>A dictionary of all the backends that should be updated.</p> required <code>num_iter</code> <code>int</code> <p>The number of iterations that should be done. If 0, then the loop will run forever.</p> <code>0</code> Source code in <code>src/sqooler/utils.py</code> <pre><code>def main(\n    storage_provider: StorageProvider,\n    backends: dict[str, Spooler],\n    num_iter: int = 0,\n) -&gt; None:\n    \"\"\"\n    Function for processing jobs continuously.\n\n    Args:\n        storage_provider: The storage provider that should be used.\n        backends: A dictionary of all the backends that should be updated.\n        num_iter: The number of iterations that should be done. If 0, then the loop\n            will run forever.\n    \"\"\"\n    backends_list = list(backends.keys())\n\n    # set the appropiate display names for all the back-ends\n    for requested_backend, spooler in backends.items():\n        # the content\n        spooler.display_name = requested_backend\n\n    counter = 0\n    # loop which is looking for the jobs\n    while num_iter == 0 or counter &lt; num_iter:\n        time.sleep(0.2)\n\n        # the following a fancy for loop of going through all the back-ends in the list\n        requested_backend = backends_list[0]\n        backends_list.append(backends_list.pop(0))\n        # let us first see if jobs are waiting\n        job_dict = storage_provider.get_next_job_in_queue(requested_backend)\n        if job_dict[\"job_json_path\"] == \"None\":\n            continue\n        job_json_dict = storage_provider.get_job_content(\n            storage_path=job_dict[\"job_json_path\"], job_id=job_dict[\"job_id\"]\n        )\n\n        result_draft: dict = {\n            \"display_name\": \"\",\n            \"backend_version\": \"\",\n            \"job_id\": \"\",\n            \"qobj_id\": None,\n            \"success\": True,\n            \"status\": \"finished\",\n            \"header\": {},\n            \"results\": [],\n        }\n\n        result_dict = ResultDict(**result_draft)\n        status_msg_draft = {\n            \"job_id\": job_dict[\"job_id\"],\n            \"status\": \"None\",\n            \"detail\": \"None\",\n            \"error_message\": \"None\",\n        }\n        status_msg_dict = StatusMsgDict(**status_msg_draft)\n        # Fix this pylint issue whenever you have time, but be careful !\n        # pylint: disable=W0703\n        try:\n            result_dict, status_msg_dict = backends[requested_backend].add_job(\n                job_json_dict, status_msg_dict\n            )\n\n        except Exception:\n            # Remove sensitive info like filepaths\n            tb_list = traceback.format_exc().splitlines()\n            for i, dummy in enumerate(tb_list):\n                tb_list[i] = re.sub(\n                    r'File \".*[\\\\/]([^\\\\/]+.py)\"', r'File \"\\1\"', tb_list[i]\n                )  # Regex for repalcing absolute filepath with only filename.\n                # Basically search for slashes and replace with the first group or\n                # bracketed expression which is obviously the filename.\n            slimmed_tb = \" \".join(tb_list)\n            # Update status dict\n            status_msg_dict.status = \"ERROR\"\n            status_msg_dict.detail += \"; \" + slimmed_tb\n            status_msg_dict.error_message += \"; \" + slimmed_tb\n\n        storage_provider.update_in_database(\n            result_dict, status_msg_dict, job_dict[\"job_id\"], requested_backend\n        )\n\n        counter += 1\n</code></pre>"},{"location":"utils/#src.sqooler.utils.run_json_circuit","title":"<code>run_json_circuit(json_dict, job_id, spooler)</code>","text":"<p>A support function that executes the job. Should be only used for testing.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the job dict that will be treated</p> required <code>job_id</code> <code>str</code> <p>the number of the job</p> required <code>spooler</code> <code>Spooler</code> <p>the spooler that will be used</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the results dict</p> Source code in <code>src/sqooler/utils.py</code> <pre><code>def run_json_circuit(json_dict: dict, job_id: str, spooler: Spooler) -&gt; dict:\n    \"\"\"\n    A support function that executes the job. Should be only used for testing.\n\n    Args:\n        json_dict: the job dict that will be treated\n        job_id: the number of the job\n        spooler: the spooler that will be used\n\n    Returns:\n        the results dict\n    \"\"\"\n    status_msg_draft = {\n        \"job_id\": job_id,\n        \"status\": \"None\",\n        \"detail\": \"None\",\n        \"error_message\": \"None\",\n    }\n    status_msg_dict = StatusMsgDict(**status_msg_draft)\n\n    result_dict, status_msg_dict = spooler.add_job(json_dict, status_msg_dict)\n    assert status_msg_dict.status == \"DONE\", \"Job failed\"\n    return result_dict.model_dump()\n</code></pre>"},{"location":"utils/#src.sqooler.utils.update_backends","title":"<code>update_backends(storage_provider, backends)</code>","text":"<p>Update the backends on the storage.</p> <p>Parameters:</p> Name Type Description Default <code>storage_provider</code> <code>StorageProvider</code> <p>The storage provider that should be used.</p> required <code>backends</code> <code>dict[str, Spooler]</code> <p>A dictionary of all the backends that should be updated.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/utils.py</code> <pre><code>def update_backends(\n    storage_provider: StorageProvider, backends: dict[str, Spooler]\n) -&gt; None:\n    \"\"\"\n    Update the backends on the storage.\n\n    Args:\n        storage_provider: The storage provider that should be used.\n        backends: A dictionary of all the backends that should be updated.\n\n    Returns:\n        None\n    \"\"\"\n    for requested_backend, spooler in backends.items():\n        # the content\n        backend_config_dict = spooler.get_configuration()\n        # set the display name\n        backend_config_dict.display_name = requested_backend\n\n        # upload the content through the storage provider\n        storage_provider.upload_config(backend_config_dict, requested_backend)\n</code></pre>"}]}