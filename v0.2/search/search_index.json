{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Sqooler","text":"<p>This is a collection of cold atom simulators that you can access through the <code>qiskit-cold-atom</code> and the <code>qlued</code> interface:</p> <ul> <li><code>qiskit-cold-atom</code> allows the enduser to write the circuit definitions on its laptop and send them to the server in form of a nice json file.</li> <li><code>qlued</code> handles the user management and stores the received json file in an appropiate queue.</li> <li><code>sqooler</code> acts as the backend that performs the calculations from the queue and sends back the result into the storage.</li> </ul> <p>To enable this work-flow, the simulator has to follow a few rules on how to parse the json files etc. This is what we have started to standardize and simplify as much as possible. In the following we documented each module its purpose and look forward to your contributions.</p>"},{"location":"#getting-started-on-heroku","title":"Getting started on heroku","text":"<p>The simplest way to use the package is to deploy it to <code>heroku</code>. This directly starts the <code>maintainer.py</code> in a loop, because it is defined like that in the <code>Procfile</code>.  However, you will also need to have the following credentials of the Dropbox:</p> <ul> <li><code>APP_KEY</code>, <code>APP_SECRET</code> and <code>REFRESH_TOKEN</code>. Please head over to the documentation of <code>qlued</code> to see how they might be set up.</li> <li>They should be all defined <code>Settings</code> &gt; <code>Config Vars</code>. </li> <li>Now your system  should automatically look for jobs that are under <code>Backend_files/Queued_Jobs</code>, process them and safe the result under <code>Backend_files/Finished_Jobs</code>.</li> </ul>"},{"location":"#getting-started-locally","title":"Getting started locally","text":"<p>Note</p> <p>This part of the documentiation needs a lot of love. Feel free to help us making it more understandable.</p> <p>If you would like to write some new simulator, extend it etc, you will need to deploy the code locally. Then you will need to:</p> <ul> <li>clone or fork the repo.</li> <li>pip install the <code>requirements.txt</code>.</li> <li>define <code>APP_KEY</code>, <code>APP_SECRET</code> and <code>REFRESH_TOKEN</code> in the <code>.env</code> file that is you should create in the root directory.</li> </ul>"},{"location":"#first-steps","title":"First steps","text":"<p>The whole system is set up on <code>python</code>. First, create a local environment. You can then install the requirements via <code>pip install -r requirements-dev.txt</code>.</p> <p>Second, we need to enable the storage of the settings, which we manage with python-decouple. To do so, create a <code>.env</code> file in the root directory.  <pre><code>project\n\u2502   README.md\n\u2502   maintainer.py\n|   .env\n|   ...    \n\u2502\n\u2514\u2500\u2500\u2500.github\n\u2502   \u2502   ...\n|\n\u2514\u2500\u2500\u2500utils\n\u2502   \u2502   ...\n|\n\u2502   ...\n</code></pre></p> <p>An example content of this file would be:</p> <pre><code># setting for MongoDB\nMONGODB_USERNAME = &lt;YOUR-USERNAME&gt;\nMONGODB_PASSWORD = &lt;YOUR-PASSWORD&gt;\nMONGODB_DATABASE_URL = &lt;YOUR-URL&gt;\n\n# settings for the Dropbox, if you use it as a storage\nAPP_KEY=&lt;YOUR-APP-KEY&gt;\nAPP_SECRET=&lt;YOUR-APP-SECRED&gt;\nREFRESH_TOKEN=&lt;YOUR-REFRESH-TOKEN&gt;\n</code></pre> <p>Then, to configure the storage make sure which one you use as we provide different options. For example, if you use the MongoDB storage you have to set the <code>MONGODB_USERNAME</code>, <code>MONGODB_PASSWORD</code> and <code>MONGODB_DATABASE_URL</code>.</p> <p>If you use the Dropbox storage, add the <code>APP_KEY</code>, <code>APP_SECRET</code> and <code>REFRESH_TOKEN</code> to the <code>.env</code> file.</p> <p>To run the system you should run the <code>maintainer</code> with <code>python maintainer.py</code>.</p> <p>Note</p> <p>This step also uploads the configuration of the backends onto the storage. So it is crucial for any kind of tests that involve <code>qlued</code>.</p> <p>You can now also stop the maintainer and test the system systematically. This can be performed via <code>python - m pytest</code>.</p>"},{"location":"fermions/","title":"Fermionic tweezer","text":"<p>This simulates the hopping of fermions in a fermionic tweezer. It can be used in <code>qiskit-cold-atom</code> as described in this tutorial. Below you can find the API of the simulator.</p>"},{"location":"fermions/#config","title":"Config","text":"<p>In this module we define all the configuration parameters for the fermions package. </p> <p>No simulation is performed here. The entire logic is implemented in the <code>spooler.py</code> module.</p>"},{"location":"fermions/#fermions.config.BarrierInstruction","title":"<code>BarrierInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The barrier instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['barrier']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=0, max_items=NUM_WIRES)</code> <p>The wires on which the instruction should be applied so the indices should be between 0 and NUM_WIRES-1</p> <code>params</code> <code>conlist(float, max_items=0)</code> <p>has to be empty</p> Source code in <code>fermions/config.py</code> <pre><code>class BarrierInstruction(BaseModel):\n\"\"\"\n    The barrier instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wires on which the instruction should be applied\n            so the indices should be between 0 and NUM_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"barrier\"]\n    wires: conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=0, max_items=NUM_WIRES)  # type: ignore\n    params: conlist(float, max_items=0)  # type: ignore\n</code></pre>"},{"location":"fermions/#fermions.config.FermionExperiment","title":"<code>FermionExperiment</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The class that defines the fermion experiments</p> Source code in <code>fermions/config.py</code> <pre><code>class FermionExperiment(BaseModel):\n\"\"\"\n    The class that defines the fermion experiments\n    \"\"\"\n\n    wire_order: Literal[\"interleaved\"]\n    # we use the Annotated notation to make mypy happy with constrained types\n    shots: conint(gt=0, le=N_MAX_SHOTS)  # type: ignore\n    num_wires: conint(ge=1, le=N_MAX_WIRES)  # type: ignore\n    instructions: List[list]\n    seed: Optional[int]\n</code></pre>"},{"location":"fermions/#fermions.config.FermionSpooler","title":"<code>FermionSpooler</code>","text":"<p>             Bases: <code>Spooler</code></p> <p>The sppoler class that handles all the circuit logic.</p> Source code in <code>fermions/config.py</code> <pre><code>class FermionSpooler(Spooler):\n\"\"\"\n    The sppoler class that handles all the circuit logic.\n    \"\"\"\n\n    def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check the validity of the experiment.\n        \"\"\"\n        try:\n            FermionExperiment(**exper_dict)\n            return \"\", True\n        except ValidationError as err:\n            return str(err), False\n\n    def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check all the instruction to make sure that they are valid.\n        \"\"\"\n        err_code = \"\"\n        exp_ok = False\n        for ins in ins_list:\n            try:\n                gate_dict = gate_dict_from_list(ins)\n                self.ins_schema_dict[ins[0]](**gate_dict)\n                exp_ok = True\n            except ValidationError as err:\n                err_code = \"Error in instruction \" + str(err)\n                exp_ok = False\n            if not exp_ok:\n                break\n        return err_code, exp_ok\n</code></pre>"},{"location":"fermions/#fermions.config.FermionSpooler.check_experiment","title":"<code>check_experiment(exper_dict)</code>","text":"<p>Check the validity of the experiment.</p> Source code in <code>fermions/config.py</code> <pre><code>def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check the validity of the experiment.\n    \"\"\"\n    try:\n        FermionExperiment(**exper_dict)\n        return \"\", True\n    except ValidationError as err:\n        return str(err), False\n</code></pre>"},{"location":"fermions/#fermions.config.FermionSpooler.check_instructions","title":"<code>check_instructions(ins_list)</code>","text":"<p>Check all the instruction to make sure that they are valid.</p> Source code in <code>fermions/config.py</code> <pre><code>def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check all the instruction to make sure that they are valid.\n    \"\"\"\n    err_code = \"\"\n    exp_ok = False\n    for ins in ins_list:\n        try:\n            gate_dict = gate_dict_from_list(ins)\n            self.ins_schema_dict[ins[0]](**gate_dict)\n            exp_ok = True\n        except ValidationError as err:\n            err_code = \"Error in instruction \" + str(err)\n            exp_ok = False\n        if not exp_ok:\n            break\n    return err_code, exp_ok\n</code></pre>"},{"location":"fermions/#fermions.config.HopInstruction","title":"<code>HopInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The instruction that applies the hopping gate.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['fhop']</code> <p>How to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=4, max_items=4)</code> <p>Exactly four wires have to be given.</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * np.pi), max_items=1)</code> <p>between 0 and 2 pi</p> <code>coupling_map</code> <code>List</code> <p>contains all the allowed configurations. Currently not used</p> Source code in <code>fermions/config.py</code> <pre><code>class HopInstruction(GateInstruction):\n\"\"\"\n    The instruction that applies the hopping gate.\n\n    Attributes:\n        name: How to identify the instruction\n        wires: Exactly four wires have to be given.\n        params: between 0 and 2 pi\n        coupling_map: contains all the allowed configurations. Currently not used\n    \"\"\"\n\n    name: Literal[\"fhop\"] = \"fhop\"\n    wires: conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=4, max_items=4)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * np.pi), max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"j_i\"\n    description: str = \"hopping of atoms to neighboring tweezers\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [\n        [0, 1, 2, 3],\n        [2, 3, 4, 5],\n        [4, 5, 6, 7],\n        [0, 1, 2, 3, 4, 5, 6, 7],\n    ]\n</code></pre>"},{"location":"fermions/#fermions.config.IntInstruction","title":"<code>IntInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The instruction that applies the interaction gate.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['fint']</code> <p>How to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=2, max_items=NUM_WIRES)</code> <p>Exactly one wire has to be given.</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * np.pi), max_items=1)</code> <p>Has to be empty</p> Source code in <code>fermions/config.py</code> <pre><code>class IntInstruction(GateInstruction):\n\"\"\"\n    The instruction that applies the interaction gate.\n\n    Attributes:\n        name: How to identify the instruction\n        wires: Exactly one wire has to be given.\n        params: Has to be empty\n    \"\"\"\n\n    name: Literal[\"fint\"] = \"fint\"\n    wires: conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=2, max_items=NUM_WIRES)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * np.pi), max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"u\"\n    description: str = \"on-site interaction of atoms of opposite spin state\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0, 1, 2, 3, 4, 5, 6, 7]]\n</code></pre>"},{"location":"fermions/#fermions.config.LoadMeasureInstruction","title":"<code>LoadMeasureInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The load or measure instruction.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['load', 'measure']</code> <p>How to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=1, max_items=1)</code> <p>Exactly one wire has to be given.</p> <code>params</code> <code>conlist(float, max_items=0)</code> <p>Has to be empty</p> Source code in <code>fermions/config.py</code> <pre><code>class LoadMeasureInstruction(BaseModel):\n\"\"\"\n    The load or measure instruction.\n\n    Attributes:\n        name: How to identify the instruction\n        wires: Exactly one wire has to be given.\n        params: Has to be empty\n    \"\"\"\n\n    name: Literal[\"load\", \"measure\"]\n    wires: conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(float, max_items=0)  # type: ignore\n</code></pre>"},{"location":"fermions/#fermions.config.PhaseInstruction","title":"<code>PhaseInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The instruction that applies the interaction gate.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['fphase']</code> <p>How to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=2, max_items=2)</code> <p>Exactly one wire has to be given.</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * np.pi), max_items=1)</code> <p>Has to be empty</p> Source code in <code>fermions/config.py</code> <pre><code>class PhaseInstruction(GateInstruction):\n\"\"\"\n    The instruction that applies the interaction gate.\n\n    Attributes:\n        name: How to identify the instruction\n        wires: Exactly one wire has to be given.\n        params: Has to be empty\n    \"\"\"\n\n    name: Literal[\"fphase\"] = \"fphase\"\n    wires: conlist(conint(ge=0, le=NUM_WIRES - 1), min_items=2, max_items=2)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * np.pi), max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"mu_i\"\n    description: str = (\n        \"Applying a local phase to tweezers through an external potential\"\n    )\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0, 1], [2, 3], [4, 5], [6, 7], [0, 1, 2, 3, 4, 5, 6, 7]]\n</code></pre>"},{"location":"fermions/#fermions.config.add_job","title":"<code>add_job(json_dict, status_msg_dict)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>json_dict: A dictonary of all the instructions. job_id: the ID of the job we are treating.</p> Source code in <code>fermions/config.py</code> <pre><code>def add_job(json_dict: dict, status_msg_dict: dict) -&gt; Tuple[dict, dict]:\n\"\"\"\n    The function that translates the json with the instructions into some circuit and executes it.\n    It performs several checks for the job to see if it is properly working.\n    If things are fine the job gets added the list of things that should be executed.\n\n    json_dict: A dictonary of all the instructions.\n    job_id: the ID of the job we are treating.\n    \"\"\"\n    job_id = status_msg_dict[\"job_id\"]\n\n    result_dict = {\n        \"backend_name\": \"alqor_fermionic_tweezer_simulator\",\n        \"backend_version\": \"0.0.2\",\n        \"job_id\": job_id,\n        \"qobj_id\": None,\n        \"success\": True,\n        \"status\": \"finished\",\n        \"header\": {},\n        \"results\": [],\n        \"experiments\": [],\n    }\n    return common_add_job(result_dict, json_dict, status_msg_dict)\n</code></pre>"},{"location":"fermions/#fermions.config.common_add_job","title":"<code>common_add_job(result_dict, json_dict, status_msg_dict)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. This is the part the gets called by add_job in each spooler.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>dict</code> <p>The dictionary that contains the results</p> required <code>json_dict</code> <code>dict</code> <p>A dictonary of all the instructions.</p> required <code>status_msg_dict</code> <code>dict</code> <p>the dict that will contain the status message.</p> required Source code in <code>fermions/config.py</code> <pre><code>def common_add_job(\n    result_dict: dict, json_dict: dict, status_msg_dict: dict\n) -&gt; Tuple[dict, dict]:\n\"\"\"\n    The function that translates the json with the instructions into some circuit and executes it.\n    This is the part the gets called by add_job in each spooler.\n\n    Args:\n        result_dict: The dictionary that contains the results\n        json_dict: A dictonary of all the instructions.\n        status_msg_dict: the dict that will contain the status message.\n    \"\"\"\n    err_msg, json_is_fine = spooler_object.check_json_dict(json_dict)\n    if json_is_fine:\n        for exp in json_dict:\n            exp_dict = {exp: json_dict[exp]}\n            # Here we\n            result_dict[\"results\"].append(gen_circuit(exp_dict))\n            result_dict[\"experiments\"].append(exp_dict)\n\n        status_msg_dict[\n            \"detail\"\n        ] += \"; Passed json sanity check; Compilation done. Shots sent to solver.\"\n        status_msg_dict[\"status\"] = \"DONE\"\n    else:\n        status_msg_dict[\"detail\"] += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict[\"error_message\"] += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict[\"status\"] = \"ERROR\"\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"fermions/#simulation-code","title":"Simulation code","text":"<p>The module that contains all the necessary logic for the fermions.</p>"},{"location":"fermions/#fermions.spooler.gen_circuit","title":"<code>gen_circuit(json_dict)</code>","text":"<p>The function the creates the instructions for the circuit.</p> <p>json_dict: The list of instructions for the specific run.</p> Source code in <code>fermions/spooler.py</code> <pre><code>def gen_circuit(json_dict: dict) -&gt; ExperimentDict:\n\"\"\"The function the creates the instructions for the circuit.\n\n    json_dict: The list of instructions for the specific run.\n    \"\"\"\n    exp_name = next(iter(json_dict))\n    ins_list = json_dict[next(iter(json_dict))][\"instructions\"]\n    n_shots = json_dict[next(iter(json_dict))][\"shots\"]\n    if \"seed\" in json_dict[next(iter(json_dict))]:\n        np.random.seed(json_dict[next(iter(json_dict))][\"seed\"])\n    tweezer_len = 4  # length of the tweezer array\n    n_states = 2 ** (2 * tweezer_len)\n\n    # create all the raising and lowering operators\n    lattice_length = 2 * tweezer_len\n    lowering_op_list = []\n    for i in range(lattice_length):\n        lowering_op_list.append(jordan_wigner_transform(i, lattice_length))\n\n    number_operators = []\n    for i in range(lattice_length):\n        number_operators.append(lowering_op_list[i].T.conj().dot(lowering_op_list[i]))\n    # interaction Hamiltonian\n    h_int = 0 * number_operators[0]\n    for ii in range(tweezer_len):\n        spindown_ind = 2 * ii\n        spinup_ind = 2 * ii + 1\n        h_int += number_operators[spindown_ind].dot(number_operators[spinup_ind])\n\n    # work our way through the instructions\n    psi = 1j * np.zeros(n_states)\n    psi[0] = 1\n    measurement_indices = []\n    shots_array = []\n    # pylint: disable=C0200\n    # Fix this pylint issue whenever you have time, but be careful !\n    for i in range(len(ins_list)):\n        inst = ins_list[i]\n        if inst[0] == \"load\":\n            latt_ind = inst[1][0]\n            psi = np.dot(lowering_op_list[latt_ind].T, psi)\n        if inst[0] == \"fhop\":\n            # the first two indices are the starting points\n            # the other two indices are the end points\n            latt_ind = inst[1]\n            theta = inst[2][0]\n            # couple\n            h_hop = lowering_op_list[latt_ind[0]].T.dot(lowering_op_list[latt_ind[2]])\n            h_hop += lowering_op_list[latt_ind[2]].T.dot(lowering_op_list[latt_ind[0]])\n            h_hop += lowering_op_list[latt_ind[1]].T.dot(lowering_op_list[latt_ind[3]])\n            h_hop += lowering_op_list[latt_ind[3]].T.dot(lowering_op_list[latt_ind[1]])\n            u_hop = expm(-1j * theta * h_hop)\n            psi = np.dot(u_hop, psi)\n        if inst[0] == \"fint\":\n            # the first two indices are the starting points\n            # the other two indices are the end points\n            theta = inst[2][0]\n            u_int = expm(-1j * theta * h_int)\n            # theta = inst[2][0]\n            psi = np.dot(u_int, psi)\n        if inst[0] == \"fphase\":\n            # the first two indices are the starting points\n            # the other two indices are the end points\n            h_phase = 0 * number_operators[0]\n            for ii in inst[1]:  # np.arange(len(inst[1])):\n                h_phase += number_operators[ii]\n            theta = inst[2][0]\n            u_phase = expm(-1j * theta * h_phase)\n            psi = np.dot(u_phase, psi)\n        if inst[0] == \"measure\":\n            measurement_indices.append(inst[1][0])\n\n    # only give back the needed measurments\n    if measurement_indices:\n        probs = np.abs(psi) ** 2\n        result_inds = np.random.choice(np.arange(n_states), p=probs, size=n_shots)\n\n        measurements = np.zeros((n_shots, len(measurement_indices)), dtype=int)\n        for jj in range(n_shots):\n            result = np.zeros(n_states)\n            result[result_inds[jj]] = 1\n\n            for ii, ind in enumerate(measurement_indices):\n                observed = number_operators[ind].dot(result)\n                observed = observed.dot(result)\n                measurements[jj, ii] = int(observed)\n        shots_array = measurements.tolist()\n\n    # print(\"done calc\")\n    exp_sub_dict = create_memory_data(shots_array, exp_name, n_shots)\n    return exp_sub_dict\n</code></pre>"},{"location":"fermions/#fermions.spooler.jordan_wigner_transform","title":"<code>jordan_wigner_transform(j, lattice_length)</code>","text":"<p>Builds up the fermionic operators in a 1D lattice. For details see : https://arxiv.org/abs/0705.1928</p> <p>Parameters:</p> Name Type Description Default <code>j</code> <p>site index</p> required <code>lattice_length</code> <p>how many sites does the lattice have ?</p> required <p>Returns:</p> Name Type Description <code>psi_x</code> <code>np.ndarray</code> <p>the field operator of creating a fermion on size j</p> Source code in <code>fermions/spooler.py</code> <pre><code>def jordan_wigner_transform(j: int, lattice_length: int) -&gt; np.ndarray:\n\"\"\"\n    Builds up the fermionic operators in a 1D lattice.\n    For details see : https://arxiv.org/abs/0705.1928\n\n    Args:\n        j : site index\n        lattice_length :  how many sites does the lattice have ?\n\n    Returns:\n        psi_x: the field operator of creating a fermion on size j\n    \"\"\"\n    p_arr = np.array([[0, 1], [0, 0]])\n    z_arr = np.array([[1, 0], [0, -1]])\n    id_arr = np.eye(2)\n    operators = []\n    for dummy in range(j):\n        operators.append(z_arr)\n    operators.append(p_arr)\n    for dummy in range(lattice_length - j - 1):\n        operators.append(id_arr)\n    return nested_kronecker_product(operators)\n</code></pre>"},{"location":"fermions/#fermions.spooler.nested_kronecker_product","title":"<code>nested_kronecker_product(a)</code>","text":"<p>putting together a large operator from a list of matrices.</p> <p>Provide an example here.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>list</code> <p>A list of matrices that can connected.</p> required <p>Returns:</p> Name Type Description <code>array</code> <code>np.ndarray</code> <p>An matrix that operates on the connected Hilbert space.</p> Source code in <code>fermions/spooler.py</code> <pre><code>def nested_kronecker_product(a: list) -&gt; np.ndarray:\n\"\"\"putting together a large operator from a list of matrices.\n\n    Provide an example here.\n\n    Args:\n        a (list): A list of matrices that can connected.\n\n    Returns:\n        array: An matrix that operates on the connected Hilbert space.\n    \"\"\"\n    if len(a) == 2:\n        return np.kron(a[0], a[1])\n    else:\n        return np.kron(a[0], nested_kronecker_product(a[1:]))\n</code></pre>"},{"location":"multiqudit/","title":"Multi qudit","text":"<p>This simulates the operation of a number of connected qudits. Below you can find the API of the simulator.</p>"},{"location":"multiqudit/#config","title":"Config","text":"<p>In this module we define all the configuration parameters for the multiqudit package. </p> <p>No simulation is performed here. The entire logic is implemented in the <code>spooler.py</code> module.</p>"},{"location":"multiqudit/#multiqudit.config.BarrierInstruction","title":"<code>BarrierInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The barrier instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['barrier']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=0, max_items=N_MAX_WIRES)</code> <p>The wires on which the instruction should be applied so the indices should be between 0 and NUM_WIRES-1</p> <code>params</code> <code>conlist(float, max_items=0)</code> <p>has to be empty</p> Source code in <code>multiqudit/config.py</code> <pre><code>class BarrierInstruction(BaseModel):\n\"\"\"\n    The barrier instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wires on which the instruction should be applied\n            so the indices should be between 0 and NUM_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"barrier\"]\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=0, max_items=N_MAX_WIRES)  # type: ignore\n    params: conlist(float, max_items=0)  # type: ignore\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.LoadInstruction","title":"<code>LoadInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The load instruction.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['load']</code> <p>How to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)</code> <p>Exactly one wire has to be given.</p> <code>params</code> <code>conlist(conint(ge=1, le=N_MAX_ATOMS), min_items=1, max_items=1)</code> <p>The number of atoms to be loaded onto the wire.</p> Source code in <code>multiqudit/config.py</code> <pre><code>class LoadInstruction(BaseModel):\n\"\"\"\n    The load instruction.\n\n    Attributes:\n        name: How to identify the instruction\n        wires: Exactly one wire has to be given.\n        params: The number of atoms to be loaded onto the wire.\n    \"\"\"\n\n    name: Literal[\"load\"]\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(conint(ge=1, le=N_MAX_ATOMS), min_items=1, max_items=1)  # type: ignore\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.LocalSqueezingInstruction","title":"<code>LocalSqueezingInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlz2 instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlz2']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=10 * 2 * pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>multiqudit/config.py</code> <pre><code>class LocalSqueezingInstruction(GateInstruction):\n\"\"\"\n    The rlz2 instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlz2\"] = \"rlz2\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(confloat(ge=0, le=10 * 2 * pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"chi\"\n    description: str = \"Evolution under lz2\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0], [1], [2], [3], [4]]\n    qasm_def = \"gate rlz2(chi) {}\"\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.MeasureInstruction","title":"<code>MeasureInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The measure instruction.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['measure']</code> <p>How to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)</code> <p>Exactly one wire has to be given.</p> <code>params</code> <code>conlist(float, max_items=0)</code> <p>Has to be empty</p> Source code in <code>multiqudit/config.py</code> <pre><code>class MeasureInstruction(BaseModel):\n\"\"\"\n    The measure instruction.\n\n    Attributes:\n        name: How to identify the instruction\n        wires: Exactly one wire has to be given.\n        params: Has to be empty\n    \"\"\"\n\n    name: Literal[\"measure\"]\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(float, max_items=0)  # type: ignore\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.MultiQuditExperiment","title":"<code>MultiQuditExperiment</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The class that defines the multi qudit experiments</p> Source code in <code>multiqudit/config.py</code> <pre><code>class MultiQuditExperiment(BaseModel):\n\"\"\"\n    The class that defines the multi qudit experiments\n    \"\"\"\n\n    wire_order: Literal[\"interleaved\", \"sequential\"] = \"sequential\"\n\n    # mypy keeps throwing errors here because it does not understand the type.\n    # not sure how to fix it, so we leave it as is for the moment\n    # HINT: Annotated does not work\n    shots: conint(gt=0, le=N_MAX_SHOTS)  # type: ignore\n    num_wires: conint(ge=1, le=N_MAX_WIRES)  # type: ignore\n    instructions: List[list]\n    seed: Optional[int]\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.MultiQuditSpooler","title":"<code>MultiQuditSpooler</code>","text":"<p>             Bases: <code>Spooler</code></p> <p>The class that contains the logic of the multiqudit spooler.</p> Source code in <code>multiqudit/config.py</code> <pre><code>class MultiQuditSpooler(Spooler):\n\"\"\"\n    The class that contains the logic of the multiqudit spooler.\n    \"\"\"\n\n    def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check the validity of the experiment.\n        \"\"\"\n        try:\n            MultiQuditExperiment(**exper_dict)\n            return \"\", True\n        except ValidationError as err:\n            return str(err), False\n\n    def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check all the instruction to make sure that they are valid.\n        \"\"\"\n        err_code = \"\"\n        exp_ok = False\n        for ins in ins_list:\n            try:\n                gate_dict = gate_dict_from_list(ins)\n                self.ins_schema_dict[ins[0]](**gate_dict)\n                exp_ok = True\n            except ValidationError as err:\n                err_code = \"Error in instruction \" + str(err)\n                exp_ok = False\n            if not exp_ok:\n                break\n        return err_code, exp_ok\n\n    def check_dimension(self, json_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n        Make sure that the Hilbert space dimension is not too large.\n        \"\"\"\n        dim_ok = False\n        err_code = \"Wrong experiment name or too many experiments\"\n        for expr in json_dict:\n            num_wires = json_dict[expr][\"num_wires\"]\n            dim_hilbert = 1\n            qubit_wires = num_wires\n            ins_list = json_dict[expr][\"instructions\"]\n            for ins in ins_list:\n                if ins[0] == \"load\":\n                    qubit_wires = qubit_wires - 1\n                    dim_hilbert = dim_hilbert * ins[2][0]\n            dim_hilbert = dim_hilbert * (2**qubit_wires)\n            dim_ok = dim_hilbert &lt; (MAX_HILBERT_SPACE_DIM) + 1\n            if not dim_ok:\n                err_code = \"Hilbert space dimension too large!\"\n                break\n        return err_code.replace(\"\\n\", \"..\"), dim_ok\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.MultiQuditSpooler.check_dimension","title":"<code>check_dimension(json_dict)</code>","text":"<p>Make sure that the Hilbert space dimension is not too large.</p> Source code in <code>multiqudit/config.py</code> <pre><code>def check_dimension(self, json_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n    Make sure that the Hilbert space dimension is not too large.\n    \"\"\"\n    dim_ok = False\n    err_code = \"Wrong experiment name or too many experiments\"\n    for expr in json_dict:\n        num_wires = json_dict[expr][\"num_wires\"]\n        dim_hilbert = 1\n        qubit_wires = num_wires\n        ins_list = json_dict[expr][\"instructions\"]\n        for ins in ins_list:\n            if ins[0] == \"load\":\n                qubit_wires = qubit_wires - 1\n                dim_hilbert = dim_hilbert * ins[2][0]\n        dim_hilbert = dim_hilbert * (2**qubit_wires)\n        dim_ok = dim_hilbert &lt; (MAX_HILBERT_SPACE_DIM) + 1\n        if not dim_ok:\n            err_code = \"Hilbert space dimension too large!\"\n            break\n    return err_code.replace(\"\\n\", \"..\"), dim_ok\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.MultiQuditSpooler.check_experiment","title":"<code>check_experiment(exper_dict)</code>","text":"<p>Check the validity of the experiment.</p> Source code in <code>multiqudit/config.py</code> <pre><code>def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check the validity of the experiment.\n    \"\"\"\n    try:\n        MultiQuditExperiment(**exper_dict)\n        return \"\", True\n    except ValidationError as err:\n        return str(err), False\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.MultiQuditSpooler.check_instructions","title":"<code>check_instructions(ins_list)</code>","text":"<p>Check all the instruction to make sure that they are valid.</p> Source code in <code>multiqudit/config.py</code> <pre><code>def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check all the instruction to make sure that they are valid.\n    \"\"\"\n    err_code = \"\"\n    exp_ok = False\n    for ins in ins_list:\n        try:\n            gate_dict = gate_dict_from_list(ins)\n            self.ins_schema_dict[ins[0]](**gate_dict)\n            exp_ok = True\n        except ValidationError as err:\n            err_code = \"Error in instruction \" + str(err)\n            exp_ok = False\n        if not exp_ok:\n            break\n    return err_code, exp_ok\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.RlxInstruction","title":"<code>RlxInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlz instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlx']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>multiqudit/config.py</code> <pre><code>class RlxInstruction(GateInstruction):\n\"\"\"\n    The rlz instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlx\"] = \"rlx\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"omega\"\n    description: str = \"Evolution under Lx\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0], [1], [2], [3], [4]]\n    qasm_def = \"gate lrx(omega) {}\"\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.RlxlyInstruction","title":"<code>RlxlyInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlxly or rlzlz instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlxly']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=2, max_items=N_MAX_WIRES)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=10 * 2 * pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>multiqudit/config.py</code> <pre><code>class RlxlyInstruction(GateInstruction):\n\"\"\"\n    The rlxly or rlzlz instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlxly\"] = \"rlxly\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=2, max_items=N_MAX_WIRES)  # type: ignore\n    params: conlist(confloat(ge=0, le=10 * 2 * pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"J\"\n    description: str = \"Entanglement between neighboring gates with an xy interaction\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 1, 2, 3, 4]]\n    qasm_def = \"gate rlylx(J) {}\"\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.RlzInstruction","title":"<code>RlzInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlz instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlz']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>multiqudit/config.py</code> <pre><code>class RlzInstruction(GateInstruction):\n\"\"\"\n    The rlz instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlz\"] = \"rlz\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"delta\"\n    description: str = \"Evolution under the Z gate\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0], [1], [2], [3], [4]]\n    qasm_def = \"gate rlz(delta) {}\"\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.RlzlzInstruction","title":"<code>RlzlzInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlzlz instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlzlz']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=2, max_items=N_MAX_WIRES)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=10 * 2 * pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>multiqudit/config.py</code> <pre><code>class RlzlzInstruction(GateInstruction):\n\"\"\"\n    The rlzlz instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlzlz\"] = \"rlzlz\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=2, max_items=N_MAX_WIRES)  # type: ignore\n    params: conlist(confloat(ge=0, le=10 * 2 * pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"J\"\n    description: str = \"Entanglement between neighboring gates with a zz interaction\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 1, 2, 3, 4]]\n    qasm_def = \"gate rlzlz(J) {}\"\n</code></pre>"},{"location":"multiqudit/#multiqudit.config.add_job","title":"<code>add_job(json_dict, status_msg_dict)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it.</p> <p>It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>json_dict: A dictonary of all the instructions. status_msg_dict:  WHAT IS THIS FOR ?</p> Source code in <code>multiqudit/config.py</code> <pre><code>def add_job(json_dict: dict, status_msg_dict: dict) -&gt; Tuple[dict, dict]:\n\"\"\"\n    The function that translates the json with the instructions into some circuit and executes it.\n\n    It performs several checks for the job to see if it is properly working.\n    If things are fine the job gets added the list of things that should be executed.\n\n    json_dict: A dictonary of all the instructions.\n    status_msg_dict:  WHAT IS THIS FOR ?\n    \"\"\"\n    job_id = status_msg_dict[\"job_id\"]\n\n    result_dict = {\n        \"backend_name\": spooler_object.name,\n        \"backend_version\": spooler_object.version,\n        \"job_id\": job_id,\n        \"qobj_id\": None,\n        \"success\": True,\n        \"status\": \"finished\",\n        \"header\": {},\n        \"results\": [],\n    }\n    err_msg, json_is_fine = spooler_object.check_json_dict(json_dict)\n\n    if json_is_fine:\n        # check_hilbert_space_dimension\n        dim_err_msg, dim_ok = spooler_object.check_dimension(json_dict)\n        if dim_ok:\n            for exp in json_dict:\n                exp_dict = {exp: json_dict[exp]}\n                # Here we\n                result_dict[\"results\"].append(gen_circuit(exp_dict))\n            print(\"done form\")\n\n            status_msg_dict[\n                \"detail\"\n            ] += \"; Passed json sanity check; Compilation done. Shots sent to solver.\"\n            status_msg_dict[\"status\"] = \"DONE\"\n            return result_dict, status_msg_dict\n\n        status_msg_dict[\"detail\"] += (\n            \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message : \"\n            + dim_err_msg\n        )\n        status_msg_dict[\"error_message\"] += (\n            \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message :  \"\n            + dim_err_msg\n        )\n        status_msg_dict[\"status\"] = \"ERROR\"\n        return result_dict, status_msg_dict\n    status_msg_dict[\"detail\"] += (\n        \"; Failed json sanity check. File will be deleted. Error message : \" + err_msg\n    )\n    status_msg_dict[\"error_message\"] += (\n        \"; Failed json sanity check. File will be deleted. Error message : \" + err_msg\n    )\n    status_msg_dict[\"status\"] = \"ERROR\"\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"multiqudit/#simulation-code","title":"Simulation code","text":"<p>The module that contains all the necessary logic for the multiqudit.</p>"},{"location":"multiqudit/#multiqudit.spooler.gen_circuit","title":"<code>gen_circuit(json_dict)</code>","text":"<p>The function the creates the instructions for the circuit.</p> <p>json_dict: The list of instructions for the specific run.</p> Source code in <code>multiqudit/spooler.py</code> <pre><code>def gen_circuit(json_dict: dict) -&gt; ExperimentDict:\n\"\"\"The function the creates the instructions for the circuit.\n\n    json_dict: The list of instructions for the specific run.\n    \"\"\"\n    exp_name = next(iter(json_dict))\n    ins_list = json_dict[next(iter(json_dict))][\"instructions\"]\n    n_shots = json_dict[next(iter(json_dict))][\"shots\"]\n    n_wires = json_dict[next(iter(json_dict))][\"num_wires\"]\n    spin_per_wire = 1 / 2 * np.ones(n_wires)\n    if \"seed\" in json_dict[next(iter(json_dict))]:\n        np.random.seed(json_dict[next(iter(json_dict))][\"seed\"])\n\n    for ins in ins_list:\n        if ins[0] == \"load\":\n            spin_per_wire[ins[1][0]] = 1 / 2 * ins[2][0]\n\n    dim_per_wire = 2 * spin_per_wire + np.ones(n_wires)\n    dim_per_wire = dim_per_wire.astype(int)\n    dim_hilbert = np.prod(dim_per_wire)\n\n    # we will need a list of local spin operators as their dimension can change\n    # on each wire\n    lx_list = []\n    ly_list = []\n    lz_list = []\n    lz2_list = []\n\n    for i1 in np.arange(0, n_wires):\n        # let's put together spin matrices\n        spin_length = spin_per_wire[i1]\n        qudit_range = np.arange(spin_length, -(spin_length + 1), -1)\n\n        lx = csc_matrix(\n            1\n            / 2\n            * diags(\n                [\n                    np.sqrt(\n                        [\n                            (spin_length - m + 1) * (spin_length + m)\n                            for m in qudit_range[:-1]\n                        ]\n                    ),\n                    np.sqrt(\n                        [\n                            (spin_length + m + 1) * (spin_length - m)\n                            for m in qudit_range[1:]\n                        ]\n                    ),\n                ],\n                [-1, 1],\n            )\n        )\n        ly = csc_matrix(\n            1\n            / (2 * 1j)\n            * diags(\n                [\n                    np.sqrt(\n                        [\n                            (spin_length - m + 1) * (spin_length + m)\n                            for m in qudit_range[:-1]\n                        ]\n                    ),\n                    -1\n                    * np.sqrt(\n                        [\n                            (spin_length + m + 1) * (spin_length - m)\n                            for m in qudit_range[1:]\n                        ]\n                    ),\n                ],\n                [-1, 1],\n            )\n        )\n        lz = csc_matrix(diags([qudit_range], [0]))\n        lz2 = lz.dot(lz)\n\n        lx_list.append(op_at_wire(lx, i1, list(dim_per_wire)))\n        ly_list.append(op_at_wire(ly, i1, list(dim_per_wire)))\n        lz_list.append(op_at_wire(lz, i1, list(dim_per_wire)))\n        lz2_list.append(op_at_wire(lz2, i1, list(dim_per_wire)))\n\n    initial_state = 1j * np.zeros(dim_per_wire[0])\n    initial_state[0] = 1 + 1j * 0\n    psi = sparse.csc_matrix(initial_state)\n    for i1 in np.arange(1, len(dim_per_wire)):\n        initial_state = 1j * np.zeros(dim_per_wire[i1])\n        initial_state[0] = 1 + 1j * 0\n        psi = sparse.kron(psi, initial_state)\n    psi = psi.T\n\n    measurement_indices = []\n    shots_array = []\n    for inst in ins_list:\n        if inst[0] == \"rlx\":\n            position = inst[1][0]\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * lx_list[position], psi)\n        if inst[0] == \"rly\":\n            position = inst[1][0]\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * ly_list[position], psi)\n        if inst[0] == \"rlz\":\n            position = inst[1][0]\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * lz_list[position], psi)\n        if inst[0] == \"rlz2\":\n            position = inst[1][0]\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * lz2_list[position], psi)\n        if inst[0] == \"rlxly\":\n            # apply gate on two qudits\n            if len(inst[1]) == 2:\n                position1 = inst[1][0]\n                position2 = inst[1][1]\n                theta = inst[2][0]\n                lp1 = lx_list[position1] + 1j * ly_list[position1]\n                lp2 = lx_list[position2] + 1j * ly_list[position2]\n                lxly = lp1.dot(lp2.conjugate().T)\n                lxly = lxly + lxly.conjugate().T\n                psi = expm_multiply(-1j * theta * lxly, psi)\n            # apply gate on all qudits\n            elif len(inst[1]) == n_wires:\n                theta = inst[2][0]\n                lxly = csc_matrix((dim_hilbert, dim_hilbert))\n                for i1 in np.arange(0, n_wires - 1):\n                    lp1 = lx_list[i1] + 1j * ly_list[i1]\n                    lp2 = lx_list[i1 + 1] + 1j * ly_list[i1 + 1]\n                    lxly = lxly + lp1.dot(lp2.conjugate().T)\n                lxly = lxly + lxly.conjugate().T\n                psi = expm_multiply(-1j * theta * lxly, psi)\n        if inst[0] == \"rlzlz\":\n            # apply gate on two quadits\n            if len(inst[1]) == 2:\n                position1 = inst[1][0]\n                position2 = inst[1][1]\n                theta = inst[2][0]\n                lzlz = lz_list[position1].dot(lz_list[position2])\n                psi = expm_multiply(-1j * theta * lzlz, psi)\n        if inst[0] == \"measure\":\n            measurement_indices.append(inst[1][0])\n    if measurement_indices:\n        # the following filters out the results for the indices we prefer.\n        probs = np.squeeze(abs(psi.toarray()) ** 2)\n        result_ind = np.random.choice(dim_hilbert, p=probs, size=n_shots)\n        measurements = np.zeros((n_shots, len(measurement_indices)), dtype=int)\n        for i1 in range(n_shots):\n            observed = np.unravel_index(result_ind[i1], dim_per_wire)\n            # TODO these types are messed up for the moment\n            # as ususal we add an ignore until this gets back to bite us in the ...\n            # but it simply to tough to find out where the typing goes wrong right now.\n            observed = np.array(observed)  # type: ignore\n            measurements[i1, :] = observed[measurement_indices]  # type: ignore\n        shots_array = measurements.tolist()\n\n    exp_sub_dict = create_memory_data(shots_array, exp_name, n_shots)\n    return exp_sub_dict\n</code></pre>"},{"location":"multiqudit/#multiqudit.spooler.op_at_wire","title":"<code>op_at_wire(op, pos, dim_per_wire)</code>","text":"<p>Applies an operation onto the wire and provides unitaries on the other wires. Basically this creates the nice tensor products.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>matrix</code> <p>The operation that should be applied.</p> required <code>pos</code> <code>int</code> <p>The wire onto which the operation should be applied.</p> required <code>dim_per_wire</code> <code>int</code> <p>What is the local Hilbert space of each wire.</p> required <p>Returns:</p> Type Description <code>csc_matrix</code> <p>The tensor product matrix.</p> Source code in <code>multiqudit/spooler.py</code> <pre><code>def op_at_wire(op: csc_matrix, pos: int, dim_per_wire: List[int]) -&gt; csc_matrix:\n\"\"\"\n    Applies an operation onto the wire and provides unitaries on the other wires.\n    Basically this creates the nice tensor products.\n\n    Args:\n        op (matrix): The operation that should be applied.\n        pos (int): The wire onto which the operation should be applied.\n        dim_per_wire (int): What is the local Hilbert space of each wire.\n\n    Returns:\n        The tensor product matrix.\n    \"\"\"\n    # There are two cases the first wire can be the identity or not\n    if pos == 0:\n        res = op\n    else:\n        res = csc_matrix(identity(dim_per_wire[0]))\n    # then loop for the rest\n    for i1 in np.arange(1, len(dim_per_wire)):\n        temp = csc_matrix(identity(dim_per_wire[i1]))\n        if i1 == pos:\n            temp = op\n        res = sparse.kron(res, temp)\n\n    return res\n</code></pre>"},{"location":"rydberg/","title":"Rydberg","text":"<p>This simulates the operation of a Rydberg tweezer array, i.e. a line of qubit that might be entangled through a Rydberg blockade. It can be deployed on qlued as described on their documentation. Below you can find the API of the simulator.</p>"},{"location":"rydberg/#config","title":"Config","text":"<p>In this module we define all the configuration parameters for the Rydberg package. </p> <p>No simulation is performed here. The entire logic is implemented in the <code>spooler.py</code> module.</p>"},{"location":"rydberg/#rydberg.config.BarrierInstruction","title":"<code>BarrierInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The barrier instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['barrier']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=0, max_items=N_MAX_WIRES)</code> <p>The wires on which the instruction should be applied so the indices should be between 0 and NUM_WIRES-1</p> <code>params</code> <code>conlist(float, max_items=0)</code> <p>has to be empty</p> Source code in <code>rydberg/config.py</code> <pre><code>class BarrierInstruction(BaseModel):\n\"\"\"\n    The barrier instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wires on which the instruction should be applied\n            so the indices should be between 0 and NUM_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"barrier\"]\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=0, max_items=N_MAX_WIRES)  # type: ignore\n    params: conlist(float, max_items=0)  # type: ignore\n</code></pre>"},{"location":"rydberg/#rydberg.config.MeasureInstruction","title":"<code>MeasureInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The measure instruction.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['measure']</code> <p>How to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)</code> <p>Exactly one wire has to be given.</p> <code>params</code> <code>conlist(float, max_items=0)</code> <p>Has to be empty</p> Source code in <code>rydberg/config.py</code> <pre><code>class MeasureInstruction(BaseModel):\n\"\"\"\n    The measure instruction.\n\n    Attributes:\n        name: How to identify the instruction\n        wires: Exactly one wire has to be given.\n        params: Has to be empty\n    \"\"\"\n\n    name: Literal[\"measure\"]\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(float, max_items=0)  # type: ignore\n</code></pre>"},{"location":"rydberg/#rydberg.config.RlxInstruction","title":"<code>RlxInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlx instruction. As each instruction it requires the following attributes</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlx']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>rydberg/config.py</code> <pre><code>class RlxInstruction(GateInstruction):\n\"\"\"\n    The rlx instruction. As each instruction it requires the following attributes\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlx\"] = \"rlx\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"omega\"\n    description: str = \"Evolution under Rlx\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0], [1], [2], [3], [4]]\n    qasm_def = \"gate rlx(omega) {}\"\n</code></pre>"},{"location":"rydberg/#rydberg.config.RlzInstruction","title":"<code>RlzInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlz instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlz']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>rydberg/config.py</code> <pre><code>class RlzInstruction(GateInstruction):\n\"\"\"\n    The rlz instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlz\"] = \"rlz\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=1, max_items=1)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"delta\"\n    description: str = \"Evolution under the Rlz gate\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0], [1], [2], [3], [4]]\n    qasm_def = \"gate rlz(delta) {}\"\n</code></pre>"},{"location":"rydberg/#rydberg.config.RydbergBlockInstruction","title":"<code>RydbergBlockInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The Rydberg blockade instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rydberg_block']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=2, max_items=N_MAX_WIRES)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>rydberg/config.py</code> <pre><code>class RydbergBlockInstruction(GateInstruction):\n\"\"\"\n    The Rydberg blockade instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rydberg_block\"] = \"rydberg_block\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=2, max_items=N_MAX_WIRES)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"phi\"\n    description: str = \"Apply the Rydberg blockade over the whole array\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0, 1, 2, 3, 4]]\n    qasm_def = \"gate rydberg_block(phi) {}\"\n</code></pre>"},{"location":"rydberg/#rydberg.config.RydbergExperiment","title":"<code>RydbergExperiment</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The class that defines the Rydberg experiments. Each of those <code>RydbergExperiment</code>s is executed on a <code>RydbergSpooler</code>.</p> Source code in <code>rydberg/config.py</code> <pre><code>class RydbergExperiment(BaseModel):\n\"\"\"\n    The class that defines the Rydberg experiments. Each of those\n    `RydbergExperiment`s is executed on a `RydbergSpooler`.\n    \"\"\"\n\n    wire_order: Literal[\"interleaved\", \"sequential\"] = \"sequential\"\n    # mypy keeps throwing errors here because it does not understand the type.\n    # not sure how to fix it, so we leave it as is for the moment\n    # HINT: Annotated does not work\n    shots: conint(gt=0, le=N_MAX_SHOTS)  # type: ignore\n    num_wires: conint(ge=1, le=N_MAX_WIRES)  # type: ignore\n    instructions: List[list]\n    seed: Optional[int]\n</code></pre>"},{"location":"rydberg/#rydberg.config.RydbergFullInstruction","title":"<code>RydbergFullInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The time evolution under the global Hamiltonian. It does not allow for any local control.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rydberg_full']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=2, max_items=N_MAX_WIRES)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=5000000.0 * np.pi), min_items=3, max_items=3)</code> <p>Define the paramert for <code>RX</code>, <code>RZ</code>and <code>RydbergBlock</code> in this order</p> Source code in <code>rydberg/config.py</code> <pre><code>class RydbergFullInstruction(GateInstruction):\n\"\"\"\n    The time evolution under the global Hamiltonian. It does not allow for any local control.\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: Define the paramert for `RX`, `RZ`and `RydbergBlock` in this order\n    \"\"\"\n\n    name: Literal[\"rydberg_full\"] = \"rydberg_full\"\n    wires: conlist(conint(ge=0, le=N_MAX_WIRES - 1), min_items=2, max_items=N_MAX_WIRES)  # type: ignore\n    params: conlist(confloat(ge=0, le=5e6 * np.pi), min_items=3, max_items=3)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"omega, delta, phi\"\n    description: str = \"Apply the Rydberg and Rabi coupling over the whole array.\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0, 1, 2, 3, 4]]\n    qasm_def = \"gate rydberg_full(omega, delta, phi) {}\"\n</code></pre>"},{"location":"rydberg/#rydberg.config.RydbergSpooler","title":"<code>RydbergSpooler</code>","text":"<p>             Bases: <code>Spooler</code></p> <p>The sppoler class that handles all the circuit logic.</p> Source code in <code>rydberg/config.py</code> <pre><code>class RydbergSpooler(Spooler):\n\"\"\"\n    The sppoler class that handles all the circuit logic.\n    \"\"\"\n\n    def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check the validity of the experiment.\n        \"\"\"\n        try:\n            RydbergExperiment(**exper_dict)\n            return \"\", True\n        except ValidationError as err:\n            return str(err), False\n\n    def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check all the instruction to make sure that they are valid.\n        \"\"\"\n        err_code = \"\"\n        exp_ok = False\n        for ins in ins_list:\n            try:\n                gate_dict = gate_dict_from_list(ins)\n                self.ins_schema_dict[ins[0]](**gate_dict)\n                exp_ok = True\n            except ValidationError as err:\n                err_code = \"Error in instruction \" + str(err)\n                exp_ok = False\n            if not exp_ok:\n                break\n        return err_code, exp_ok\n</code></pre>"},{"location":"rydberg/#rydberg.config.RydbergSpooler.check_experiment","title":"<code>check_experiment(exper_dict)</code>","text":"<p>Check the validity of the experiment.</p> Source code in <code>rydberg/config.py</code> <pre><code>def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check the validity of the experiment.\n    \"\"\"\n    try:\n        RydbergExperiment(**exper_dict)\n        return \"\", True\n    except ValidationError as err:\n        return str(err), False\n</code></pre>"},{"location":"rydberg/#rydberg.config.RydbergSpooler.check_instructions","title":"<code>check_instructions(ins_list)</code>","text":"<p>Check all the instruction to make sure that they are valid.</p> Source code in <code>rydberg/config.py</code> <pre><code>def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check all the instruction to make sure that they are valid.\n    \"\"\"\n    err_code = \"\"\n    exp_ok = False\n    for ins in ins_list:\n        try:\n            gate_dict = gate_dict_from_list(ins)\n            self.ins_schema_dict[ins[0]](**gate_dict)\n            exp_ok = True\n        except ValidationError as err:\n            err_code = \"Error in instruction \" + str(err)\n            exp_ok = False\n        if not exp_ok:\n            break\n    return err_code, exp_ok\n</code></pre>"},{"location":"rydberg/#rydberg.config.add_job","title":"<code>add_job(json_dict, status_msg_dict)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>json_dict: The job dictonary of all the instructions. job_id: the ID of the job we are treating.</p> Source code in <code>rydberg/config.py</code> <pre><code>def add_job(json_dict: dict, status_msg_dict: dict) -&gt; Tuple[dict, dict]:\n\"\"\"\n    The function that translates the json with the instructions into some circuit and executes it.\n    It performs several checks for the job to see if it is properly working.\n    If things are fine the job gets added the list of things that should be executed.\n\n    json_dict: The job dictonary of all the instructions.\n    job_id: the ID of the job we are treating.\n    \"\"\"\n    job_id = status_msg_dict[\"job_id\"]\n\n    result_dict = {\n        \"backend_name\": spooler_object.name,\n        \"backend_version\": spooler_object.version,\n        \"job_id\": job_id,\n        \"qobj_id\": None,\n        \"success\": True,\n        \"status\": \"finished\",\n        \"header\": {},\n        \"results\": [],\n    }\n    err_msg, json_is_fine = spooler_object.check_json_dict(json_dict)\n    if json_is_fine:\n        for exp in json_dict:\n            exp_dict = {exp: json_dict[exp]}\n            # Here we\n            result_dict[\"results\"].append(gen_circuit(exp_dict))\n        print(\"done form\")\n\n        status_msg_dict[\n            \"detail\"\n        ] += \"; Passed json sanity check; Compilation done. Shots sent to solver.\"\n        status_msg_dict[\"status\"] = \"DONE\"\n    else:\n        status_msg_dict[\"detail\"] += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict[\"error_message\"] += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict[\"status\"] = \"ERROR\"\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"rydberg/#simulation-code","title":"Simulation code","text":"<p>The module that contains all the necessary logic for the Rydberg simulator. It has to implement the code that is executed for all the instructions that we defined  in the <code>config.py</code> file.</p>"},{"location":"rydberg/#rydberg.spooler.gen_circuit","title":"<code>gen_circuit(json_dict)</code>","text":"<p>The function the creates the instructions for the circuit.</p> <p>json_dict: The list of instructions for the specific run.</p> Source code in <code>rydberg/spooler.py</code> <pre><code>def gen_circuit(json_dict: dict) -&gt; ExperimentDict:\n\"\"\"The function the creates the instructions for the circuit.\n\n    json_dict: The list of instructions for the specific run.\n    \"\"\"\n    exp_name = next(iter(json_dict))\n    ins_list = json_dict[next(iter(json_dict))][\"instructions\"]\n    n_shots = json_dict[next(iter(json_dict))][\"shots\"]\n    n_wires = json_dict[next(iter(json_dict))][\"num_wires\"]\n    spin_per_wire = 1 / 2 * np.ones(n_wires)\n    if \"seed\" in json_dict[next(iter(json_dict))]:\n        np.random.seed(json_dict[next(iter(json_dict))][\"seed\"])\n\n    dim_per_wire = 2 * spin_per_wire + np.ones(n_wires)\n    dim_per_wire = dim_per_wire.astype(int)\n    dim_hilbert = np.prod(dim_per_wire)\n\n    # we will need a list of local spin operators as their dimension can change\n    # on each wire\n    lx_list = []\n    ly_list = []\n    lz_list = []\n    nocc_list = []\n    spin_length = 1 / 2\n    qudit_range = np.arange(spin_length, -(spin_length + 1), -1)\n    lx = csc_matrix(\n        1\n        / 2\n        * diags(\n            [\n                np.sqrt(\n                    [\n                        (spin_length - m + 1) * (spin_length + m)\n                        for m in qudit_range[:-1]\n                    ]\n                ),\n                np.sqrt(\n                    [(spin_length + m + 1) * (spin_length - m) for m in qudit_range[1:]]\n                ),\n            ],\n            [-1, 1],\n        )\n    )\n    ly = csc_matrix(\n        1\n        / (2 * 1j)\n        * diags(\n            [\n                np.sqrt(\n                    [\n                        (spin_length - m + 1) * (spin_length + m)\n                        for m in qudit_range[:-1]\n                    ]\n                ),\n                -1\n                * np.sqrt(\n                    [(spin_length + m + 1) * (spin_length - m) for m in qudit_range[1:]]\n                ),\n            ],\n            [-1, 1],\n        )\n    )\n\n    lz = csc_matrix(diags([qudit_range], [0]))\n    # nocc = csc_matrix(diags([qudit_range + 1 / 2], [0]))\n    nocc = csc_matrix(diags([-qudit_range + 1 / 2], [0]))\n\n    for i1 in np.arange(0, n_wires):\n        # let's put together spin matrices\n        lx_list.append(op_at_wire(lx, i1, list(dim_per_wire)))\n        ly_list.append(op_at_wire(ly, i1, list(dim_per_wire)))\n        lz_list.append(op_at_wire(lz, i1, list(dim_per_wire)))\n        nocc_list.append(op_at_wire(nocc, i1, list(dim_per_wire)))\n\n    int_matrix = csc_matrix((dim_hilbert, dim_hilbert))\n    for i1 in np.arange(0, n_wires):\n        for i2 in np.arange(i1 + 1, n_wires):\n            int_matrix = (\n                int_matrix + nocc_list[i1].dot(nocc_list[i2]) / np.abs(i1 - i2) ** 6\n            )\n\n    initial_state = 1j * np.zeros(dim_per_wire[0])\n    initial_state[0] = 1 + 1j * 0\n    psi = sparse.csc_matrix(initial_state)\n    for i1 in np.arange(1, len(dim_per_wire)):\n        initial_state = 1j * np.zeros(dim_per_wire[i1])\n        initial_state[0] = 1 + 1j * 0\n        psi = sparse.kron(psi, initial_state)\n    psi = psi.T\n\n    measurement_indices = []\n    shots_array = []\n    for inst in ins_list:\n        if inst[0] == \"rlx\":\n            position = inst[1][0]\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * lx_list[position], psi)\n        if inst[0] == \"rlz\":\n            position = inst[1][0]\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * lz_list[position], psi)\n        if inst[0] == \"rydberg_block\":\n            # apply gate on all qubits\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * int_matrix, psi)\n        if inst[0] == \"rydberg_full\":\n            omega, delta, phi = inst[2]\n            u_full = csc_matrix((dim_hilbert, dim_hilbert))\n            # first the RX\n            for lxi in lx_list:\n                u_full = u_full + omega * lxi\n            # next the RZ\n            for lzi in lz_list:\n                u_full = u_full + delta * lzi\n            # end the blockade\n            u_full = u_full + phi * int_matrix\n            psi = expm_multiply(-1j * u_full, psi)\n        if inst[0] == \"measure\":\n            measurement_indices.append(inst[1][0])\n    if measurement_indices:\n        # the following filters out the results for the indices we prefer.\n        probs = np.squeeze(abs(psi.toarray()) ** 2)\n        result_ind = np.random.choice(dim_hilbert, p=probs, size=n_shots)\n        measurements = np.zeros((n_shots, len(measurement_indices)), dtype=int)\n        for i1 in range(n_shots):\n            observed = np.unravel_index(result_ind[i1], dim_per_wire)\n            # TODO these types are messed up for the moment\n            # as ususal we add an ignore until this gets back to bite us in the ...\n            # but it simply to tough to find out where the typing goes wrong right now.\n            observed = np.array(observed)  # type: ignore\n            measurements[i1, :] = observed[measurement_indices]  # type: ignore\n        shots_array = measurements.tolist()\n\n    exp_sub_dict = create_memory_data(shots_array, exp_name, n_shots)\n    return exp_sub_dict\n</code></pre>"},{"location":"rydberg/#rydberg.spooler.op_at_wire","title":"<code>op_at_wire(op, pos, dim_per_wire)</code>","text":"<p>Applies an operation onto the wire and provides unitaries on the other wires. Basically this creates the nice tensor products.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>matrix</code> <p>The operation that should be applied.</p> required <code>pos</code> <code>int</code> <p>The wire onto which the operation should be applied.</p> required <code>dim_per_wire</code> <code>int</code> <p>What is the local Hilbert space of each wire.</p> required <p>Returns:</p> Type Description <code>csc_matrix</code> <p>The tensor product matrix.</p> Source code in <code>rydberg/spooler.py</code> <pre><code>def op_at_wire(op: csc_matrix, pos: int, dim_per_wire: List[int]) -&gt; csc_matrix:\n\"\"\"\n    Applies an operation onto the wire and provides unitaries on the other wires.\n    Basically this creates the nice tensor products.\n\n    Args:\n        op (matrix): The operation that should be applied.\n        pos (int): The wire onto which the operation should be applied.\n        dim_per_wire (int): What is the local Hilbert space of each wire.\n\n    Returns:\n        The tensor product matrix.\n    \"\"\"\n    # There are two cases the first wire can be the identity or not\n    if pos == 0:\n        res = op\n    else:\n        res = csc_matrix(identity(dim_per_wire[0]))\n    # then loop for the rest\n    for i1 in np.arange(1, len(dim_per_wire)):\n        temp = csc_matrix(identity(dim_per_wire[i1]))\n        if i1 == pos:\n            temp = op\n        res = sparse.kron(res, temp)\n\n    return res\n</code></pre>"},{"location":"singlequdit/","title":"Single qudit","text":"<p>This simulates the operation of a single qudit, i.e. collective spin or angular momentum operator. It can be used in <code>qiskit-cold-atom</code> as described in this tutorial. Below you can find the API of the simulator.</p>"},{"location":"singlequdit/#config","title":"Config","text":"<p>In this module we define all the configuration parameters for the singlequdit package. </p> <p>No simulation is performed here. The entire logic is implemented in the <code>spooler.py</code> module.</p>"},{"location":"singlequdit/#singlequdit.config.LoadInstruction","title":"<code>LoadInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The load instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['load']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=0), min_items=0, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(conint(ge=1, le=N_MAX_ATOMS), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>singlequdit/config.py</code> <pre><code>class LoadInstruction(BaseModel):\n\"\"\"\n    The load instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"load\"]\n    wires: conlist(conint(ge=0, le=0), min_items=0, max_items=1)  # type: ignore\n    params: conlist(conint(ge=1, le=N_MAX_ATOMS), min_items=1, max_items=1)  # type: ignore\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.LocalSqueezingInstruction","title":"<code>LocalSqueezingInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlz2 instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlz2']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=0), min_items=0, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=10 * 2 * np.pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>singlequdit/config.py</code> <pre><code>class LocalSqueezingInstruction(GateInstruction):\n\"\"\"\n    The rlz2 instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlz2\"] = \"rlz2\"\n    wires: conlist(conint(ge=0, le=0), min_items=0, max_items=1)  # type: ignore\n    params: conlist(confloat(ge=0, le=10 * 2 * np.pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"chi\"\n    description: str = \"Evolution under lz2\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0], [1], [2], [3], [4]]\n    qasm_def = \"gate rlz2(chi) {}\"\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.MeasureBarrierInstruction","title":"<code>MeasureBarrierInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The measure and barrier instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['measure', 'barrier']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=0), min_items=0, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(float, min_items=0, max_items=0)</code> <p>has to be empty</p> Source code in <code>singlequdit/config.py</code> <pre><code>class MeasureBarrierInstruction(BaseModel):\n\"\"\"\n    The measure and barrier instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"measure\", \"barrier\"]\n    wires: conlist(conint(ge=0, le=0), min_items=0, max_items=1)  # type: ignore\n    params: conlist(float, min_items=0, max_items=0)  # type: ignore\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.RlxInstruction","title":"<code>RlxInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlx instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlx']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=0), min_items=0, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>singlequdit/config.py</code> <pre><code>class RlxInstruction(GateInstruction):\n\"\"\"\n    The rlx instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlx\"] = \"rlx\"\n    wires: conlist(conint(ge=0, le=0), min_items=0, max_items=1)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"omega\"\n    description: str = \"Evolution under Lx\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0], [1], [2], [3], [4]]\n    qasm_def = \"gate lrx(omega) {}\"\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.RlzInstruction","title":"<code>RlzInstruction</code>","text":"<p>             Bases: <code>GateInstruction</code></p> <p>The rlz instruction. As each instruction it requires the</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['rlz']</code> <p>The string to identify the instruction</p> <code>wires</code> <code>conlist(conint(ge=0, le=0), min_items=0, max_items=1)</code> <p>The wire on which the instruction should be applied so the indices should be between 0 and N_MAX_WIRES-1</p> <code>params</code> <code>conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)</code> <p>has to be empty</p> Source code in <code>singlequdit/config.py</code> <pre><code>class RlzInstruction(GateInstruction):\n\"\"\"\n    The rlz instruction. As each instruction it requires the\n\n    Attributes:\n        name: The string to identify the instruction\n        wires: The wire on which the instruction should be applied\n            so the indices should be between 0 and N_MAX_WIRES-1\n        params: has to be empty\n    \"\"\"\n\n    name: Literal[\"rlz\"] = \"rlz\"\n    wires: conlist(conint(ge=0, le=0), min_items=0, max_items=1)  # type: ignore\n    params: conlist(confloat(ge=0, le=2 * np.pi), min_items=1, max_items=1)  # type: ignore\n\n    # a string that is sent over to the config dict and that is necessary for compatibility with QISKIT.\n    parameters: str = \"delta\"\n    description: str = \"Evolution under the Z gate\"\n    # TODO: This should become most likely a type that is then used for the enforcement of the wires.\n    coupling_map: List = [[0], [1], [2], [3], [4]]\n    qasm_def = \"gate rlz(delta) {}\"\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.SingleQuditExperiment","title":"<code>SingleQuditExperiment</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The class that defines the single qudit experiments</p> Source code in <code>singlequdit/config.py</code> <pre><code>class SingleQuditExperiment(BaseModel):\n\"\"\"\n    The class that defines the single qudit experiments\n    \"\"\"\n\n    wire_order: Literal[\"interleaved\", \"sequential\"] = \"sequential\"\n    # mypy keeps throwing errors here because it does not understand the type.\n    # not sure how to fix it, so we leave it as is for the moment\n    # HINT: Annotated does not work\n    shots: conint(gt=0, le=N_MAX_SHOTS)  # type: ignore\n    num_wires: Literal[1]\n    instructions: List[list]\n    seed: Optional[int]\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.SingleQuditSpooler","title":"<code>SingleQuditSpooler</code>","text":"<p>             Bases: <code>Spooler</code></p> <p>The spooler class that handles all the circuit logic.</p> Source code in <code>singlequdit/config.py</code> <pre><code>class SingleQuditSpooler(Spooler):\n\"\"\"\n    The spooler class that handles all the circuit logic.\n    \"\"\"\n\n    def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check the validity of the experiment.\n        \"\"\"\n        try:\n            SingleQuditExperiment(**exper_dict)\n            return \"\", True\n        except ValidationError as err:\n            return str(err), False\n\n    def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check all the instruction to make sure that they are valid.\n        \"\"\"\n        err_code = \"\"\n        exp_ok = False\n        for ins in ins_list:\n            try:\n                gate_dict = gate_dict_from_list(ins)\n                self.ins_schema_dict[ins[0]](**gate_dict)\n                exp_ok = True\n            except ValidationError as err:\n                err_code = \"Error in instruction \" + str(err)\n                exp_ok = False\n            if not exp_ok:\n                break\n        return err_code, exp_ok\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.SingleQuditSpooler.check_experiment","title":"<code>check_experiment(exper_dict)</code>","text":"<p>Check the validity of the experiment.</p> Source code in <code>singlequdit/config.py</code> <pre><code>def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check the validity of the experiment.\n    \"\"\"\n    try:\n        SingleQuditExperiment(**exper_dict)\n        return \"\", True\n    except ValidationError as err:\n        return str(err), False\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.SingleQuditSpooler.check_instructions","title":"<code>check_instructions(ins_list)</code>","text":"<p>Check all the instruction to make sure that they are valid.</p> Source code in <code>singlequdit/config.py</code> <pre><code>def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check all the instruction to make sure that they are valid.\n    \"\"\"\n    err_code = \"\"\n    exp_ok = False\n    for ins in ins_list:\n        try:\n            gate_dict = gate_dict_from_list(ins)\n            self.ins_schema_dict[ins[0]](**gate_dict)\n            exp_ok = True\n        except ValidationError as err:\n            err_code = \"Error in instruction \" + str(err)\n            exp_ok = False\n        if not exp_ok:\n            break\n    return err_code, exp_ok\n</code></pre>"},{"location":"singlequdit/#singlequdit.config.add_job","title":"<code>add_job(json_dict, status_msg_dict)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>json_dict: The job dictonary of all the instructions. job_id: the ID of the job we are treating.</p> Source code in <code>singlequdit/config.py</code> <pre><code>def add_job(json_dict: dict, status_msg_dict: dict) -&gt; Tuple[dict, dict]:\n\"\"\"\n    The function that translates the json with the instructions into some circuit and executes it.\n    It performs several checks for the job to see if it is properly working.\n    If things are fine the job gets added the list of things that should be executed.\n\n    json_dict: The job dictonary of all the instructions.\n    job_id: the ID of the job we are treating.\n    \"\"\"\n    job_id = status_msg_dict[\"job_id\"]\n\n    result_dict = {\n        \"backend_name\": spooler_object.name,\n        \"backend_version\": spooler_object.version,\n        \"job_id\": job_id,\n        \"qobj_id\": None,\n        \"success\": True,\n        \"status\": \"finished\",\n        \"header\": {},\n        \"results\": [],\n    }\n    err_msg, json_is_fine = spooler_object.check_json_dict(json_dict)\n    if json_is_fine:\n        for exp in json_dict:\n            exp_dict = {exp: json_dict[exp]}\n            # Here we\n            result_dict[\"results\"].append(gen_circuit(exp_dict))\n        print(\"done form\")\n\n        status_msg_dict[\n            \"detail\"\n        ] += \"; Passed json sanity check; Compilation done. Shots sent to solver.\"\n        status_msg_dict[\"status\"] = \"DONE\"\n    else:\n        status_msg_dict[\"detail\"] += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict[\"error_message\"] += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict[\"status\"] = \"ERROR\"\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"singlequdit/#simulation-code","title":"Simulation code","text":"<p>The module that contains all the necessary logic to simulate the singlequdit.  It has to implement the code that is executed for all the instructions that we defined  in the <code>conf.py</code> file.</p>"},{"location":"singlequdit/#singlequdit.spooler.gen_circuit","title":"<code>gen_circuit(json_dict)</code>","text":"<p>The function the creates the instructions for the circuit. json_dict: The list of instructions for the specific run.</p> Source code in <code>singlequdit/spooler.py</code> <pre><code>def gen_circuit(json_dict: dict) -&gt; ExperimentDict:\n\"\"\"The function the creates the instructions for the circuit.\n    json_dict: The list of instructions for the specific run.\n    \"\"\"\n    # pylint: disable=R0914\n    exp_name = next(iter(json_dict))\n    ins_list = json_dict[next(iter(json_dict))][\"instructions\"]\n    n_shots = json_dict[next(iter(json_dict))][\"shots\"]\n    if \"seed\" in json_dict[next(iter(json_dict))]:\n        np.random.seed(json_dict[next(iter(json_dict))][\"seed\"])\n\n    n_atoms = 1\n\n    spin_len = n_atoms / 2  # spin length\n\n    # let's put together spin matrices\n    dim_qudit = n_atoms + 1\n    qudit_range = np.arange(spin_len, -(spin_len + 1), -1)\n\n    lx = csc_matrix(\n        1\n        / 2\n        * diags(\n            [\n                np.sqrt(\n                    [(spin_len - m + 1) * (spin_len + m) for m in qudit_range[:-1]]\n                ),\n                np.sqrt([(spin_len + m + 1) * (spin_len - m) for m in qudit_range[1:]]),\n            ],\n            [-1, 1],\n        )\n    )\n    lz = csc_matrix(diags([qudit_range], [0]))\n    lz2 = lz.multiply(lz)\n\n    psi = 1j * np.zeros(dim_qudit)\n    psi[0] = 1 + 1j * 0\n    shots_array = []\n    # work our way through the instructions\n    for inst in ins_list:\n        # this must always be the first instruction. Otherwise we should\n        # raise some error\n        if inst[0] == \"load\":\n            n_atoms = int(inst[2][0])\n            spin_len = n_atoms / 2\n            # length of the qudit\n            dim_qudit = n_atoms + 1\n            qudit_range = np.arange(spin_len, -(spin_len + 1), -1)\n\n            lx = csc_matrix(\n                1\n                / 2\n                * diags(\n                    [\n                        np.sqrt(\n                            [\n                                (spin_len - m + 1) * (spin_len + m)\n                                for m in qudit_range[:-1]\n                            ]\n                        ),\n                        np.sqrt(\n                            [\n                                (spin_len + m + 1) * (spin_len - m)\n                                for m in qudit_range[1:]\n                            ]\n                        ),\n                    ],\n                    [-1, 1],\n                )\n            )\n            lz = csc_matrix(diags([qudit_range], [0]))\n\n            lz2 = lz.multiply(lz)\n\n            psi = 1j * np.zeros(dim_qudit)\n            psi[0] = 1 + 1j * 0\n\n        if inst[0] == \"rlx\":\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * lx, psi)\n        if inst[0] == \"rlz\":\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * lz, psi)\n        if inst[0] == \"rlz2\":\n            theta = inst[2][0]\n            psi = expm_multiply(-1j * theta * lz2, psi)\n        if inst[0] == \"measure\":\n            probs = np.abs(psi) ** 2\n            result = np.random.choice(np.arange(dim_qudit), p=probs, size=n_shots)\n\n    shots_array = result.tolist()\n    exp_sub_dict = create_memory_data(shots_array, exp_name, n_shots)\n    return exp_sub_dict\n</code></pre>"},{"location":"utils/","title":"Utils","text":"<p>This is the module that contains all the basic logic to read the json files that come from <code>qlued</code>. It also allows for validation etc. So if you are not a developer that tries to extend the core behavior of the <code>sqooler</code> it is unlikely that you should modify this part of the code. However, it is instructive to have a look below to understand the  modules that are provided for the creation of a simulator.</p> <p>Below you can find the API of the <code>utils</code>.</p>"},{"location":"utils/#storage-providers","title":"Storage Providers","text":"<p>The module that contains all the necessary logic for communication with the external storage for the jobs. It creates an abstract API layer for the storage providers.</p>"},{"location":"utils/#utils.storage_providers.DropboxProvider","title":"<code>DropboxProvider</code>","text":"<p>             Bases: <code>StorageProvider</code></p> <p>The class that implements the dropbox storage provider.</p> Source code in <code>utils/storage_providers.py</code> <pre><code>class DropboxProvider(StorageProvider):\n\"\"\"\n    The class that implements the dropbox storage provider.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n\"\"\"\n        Set up the neccessary keys.\n        \"\"\"\n        self.app_key = config(\"APP_KEY\")\n        self.app_secret = config(\"APP_SECRET\")\n        self.refresh_token = config(\"REFRESH_TOKEN\")\n\n    def upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Upload the content_dict as a json file to the dropbox\n\n        content_dict: the content of the file that should be uploaded\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file without the .json extension\n        \"\"\"\n\n        # create the appropriate string for the dropbox API\n        dump_str = json.dumps(content_dict)\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            dbx.users_get_current_account()\n            dbx.files_upload(\n                dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n            )\n\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n        Get the file content from the dropbox\n\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n            full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n            _, res = dbx.files_download(path=full_path)\n            data = res.content\n        return json.loads(data.decode(\"utf-8\"))\n\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the job\n        \"\"\"\n        return self.get_file_content(storage_path=storage_path, job_id=f\"job-{job_id}\")\n\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # create the appropriate string for the dropbox API\n        dump_str = json.dumps(content_dict)\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            dbx.users_get_current_account()\n            dbx.files_upload(\n                dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n            )\n\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n        # strip trailing and leading slashes from the paths\n        start_path = start_path.strip(\"/\")\n        final_path = final_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            dbx.users_get_current_account()\n\n            full_start_path = \"/\" + start_path + \"/\" + job_id + \".json\"\n            full_final_path = \"/\" + final_path + \"/\" + job_id + \".json\"\n            dbx.files_move_v2(full_start_path, full_final_path)\n\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Remove the file from the dropbox\n\n        Args:\n            storage_path: the path where the file should be stored, but excluding the file name\n            job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n\n            full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n            _ = dbx.files_delete(path=full_path)\n\n    def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n\"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        All the configurations are stored in the Backend_files/Config folder.\n        For each backend there is a separate folder in which the configuration is stored as a json file.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n        config_path = \"Backend_files/Config/\" + backend_name\n        self.upload(config_dict, config_path, \"config\")\n\n    def update_in_database(\n        self, result_dict: dict, status_msg_dict: dict, job_id: str, backend_name: str\n    ) -&gt; None:\n\"\"\"\n        Upload the status and result to the dropbox.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # this should become part of the json file instead of its name in the future\n        extracted_username = job_id.split(\"-\")[2]\n\n        status_json_dir = (\n            \"/Backend_files/Status/\" + backend_name + \"/\" + extracted_username + \"/\"\n        )\n        status_json_name = \"status-\" + job_id\n\n        job_json_name = \"job-\" + job_id\n        job_json_start_dir = \"Backend_files/Running_Jobs\"\n\n        if status_msg_dict[\"status\"] == \"DONE\":\n            # let us create the result json file\n            result_json_dir = (\n                \"/Backend_files/Result/\" + backend_name + \"/\" + extracted_username + \"/\"\n            )\n            result_json_name = \"result-\" + job_id\n            self.upload(result_dict, result_json_dir, result_json_name)\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = (\n                \"/Backend_files/Finished_Jobs/\"\n                + backend_name\n                + \"/\"\n                + extracted_username\n                + \"/\"\n            )\n            self.move_file(job_json_start_dir, job_finished_json_dir, job_json_name)\n\n        elif status_msg_dict[\"status\"] == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = \"Backend_files/Deleted_Jobs\"\n            self.move_file(job_json_start_dir, deleted_json_dir, job_json_name)\n\n        # and create the status json file\n        self.upload(status_msg_dict, status_json_dir, status_json_name)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n\"\"\"\n        Get a list of files. Typically we are looking for the queued jobs of a backend here.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n        # strip trailing and leading slashes from the paths\n        storage_path = storage_path.strip(\"/\")\n\n        storage_path = \"/\" + storage_path.strip(\"/\") + \"/\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        file_list = []\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n            # We should really handle these exceptions cleaner, but this seems a bit\n            # complicated right now\n            # pylint: disable=W0703\n            try:\n                response = dbx.files_list_folder(path=storage_path)\n                file_list = response.entries\n                file_list = [item.name for item in file_list]\n            except ApiError:\n                print(f\"Could not obtain job queue for {storage_path}\")\n            except Exception as err:\n                print(err)\n        return file_list\n\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n\"\"\"\n        A function that obtains the next job in the queue.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n        job_json_dir = \"/Backend_files/Queued_Jobs/\" + backend_name + \"/\"\n        job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n        job_list = self.get_file_queue(job_json_dir)\n        # if there is a job, we should move it\n        if job_list:\n            job_json_name = job_list[0]\n            job_dict[\"job_id\"] = job_json_name[4:-5]\n\n            # split the .json from the job_json_name\n            job_json_name = job_json_name.split(\".\")[0]\n            # and move the file into the right directory\n            self.move_file(job_json_dir, \"Backend_files/Running_Jobs\", job_json_name)\n            job_dict[\"job_json_path\"] = \"Backend_files/Running_Jobs\"\n        return job_dict\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.__init__","title":"<code>__init__()</code>","text":"<p>Set up the neccessary keys.</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def __init__(self) -&gt; None:\n\"\"\"\n    Set up the neccessary keys.\n    \"\"\"\n    self.app_key = config(\"APP_KEY\")\n    self.app_secret = config(\"APP_SECRET\")\n    self.refresh_token = config(\"REFRESH_TOKEN\")\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Remove the file from the dropbox</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file. Is a json file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Remove the file from the dropbox\n\n    Args:\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n        _ = dbx.files_delete(path=full_path)\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Get the file content from the dropbox</p> <p>storage_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n    Get the file content from the dropbox\n\n    storage_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n        _, res = dbx.files_download(path=full_path)\n        data = res.content\n    return json.loads(data.decode(\"utf-8\"))\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of files. Typically we are looking for the queued jobs of a backend here.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n\"\"\"\n    Get a list of files. Typically we are looking for the queued jobs of a backend here.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n\n    # strip trailing and leading slashes from the paths\n    storage_path = storage_path.strip(\"/\")\n\n    storage_path = \"/\" + storage_path.strip(\"/\") + \"/\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    file_list = []\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n        # We should really handle these exceptions cleaner, but this seems a bit\n        # complicated right now\n        # pylint: disable=W0703\n        try:\n            response = dbx.files_list_folder(path=storage_path)\n            file_list = response.entries\n            file_list = [item.name for item in file_list]\n        except ApiError:\n            print(f\"Could not obtain job queue for {storage_path}\")\n        except Exception as err:\n            print(err)\n    return file_list\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the job\n    \"\"\"\n    return self.get_file_content(storage_path=storage_path, job_id=f\"job-{job_id}\")\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n\"\"\"\n    A function that obtains the next job in the queue.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n    job_json_dir = \"/Backend_files/Queued_Jobs/\" + backend_name + \"/\"\n    job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n    job_list = self.get_file_queue(job_json_dir)\n    # if there is a job, we should move it\n    if job_list:\n        job_json_name = job_list[0]\n        job_dict[\"job_id\"] = job_json_name[4:-5]\n\n        # split the .json from the job_json_name\n        job_json_name = job_json_name.split(\".\")[0]\n        # and move the file into the right directory\n        self.move_file(job_json_dir, \"Backend_files/Running_Jobs\", job_json_name)\n        job_dict[\"job_json_path\"] = \"Backend_files/Running_Jobs\"\n    return job_dict\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n    # strip trailing and leading slashes from the paths\n    start_path = start_path.strip(\"/\")\n    final_path = final_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        dbx.users_get_current_account()\n\n        full_start_path = \"/\" + start_path + \"/\" + job_id + \".json\"\n        full_final_path = \"/\" + final_path + \"/\" + job_id + \".json\"\n        dbx.files_move_v2(full_start_path, full_final_path)\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # create the appropriate string for the dropbox API\n    dump_str = json.dumps(content_dict)\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        dbx.users_get_current_account()\n        dbx.files_upload(\n            dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n        )\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>","text":"<p>Upload the status and result to the dropbox.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>dict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>dict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def update_in_database(\n    self, result_dict: dict, status_msg_dict: dict, job_id: str, backend_name: str\n) -&gt; None:\n\"\"\"\n    Upload the status and result to the dropbox.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # this should become part of the json file instead of its name in the future\n    extracted_username = job_id.split(\"-\")[2]\n\n    status_json_dir = (\n        \"/Backend_files/Status/\" + backend_name + \"/\" + extracted_username + \"/\"\n    )\n    status_json_name = \"status-\" + job_id\n\n    job_json_name = \"job-\" + job_id\n    job_json_start_dir = \"Backend_files/Running_Jobs\"\n\n    if status_msg_dict[\"status\"] == \"DONE\":\n        # let us create the result json file\n        result_json_dir = (\n            \"/Backend_files/Result/\" + backend_name + \"/\" + extracted_username + \"/\"\n        )\n        result_json_name = \"result-\" + job_id\n        self.upload(result_dict, result_json_dir, result_json_name)\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = (\n            \"/Backend_files/Finished_Jobs/\"\n            + backend_name\n            + \"/\"\n            + extracted_username\n            + \"/\"\n        )\n        self.move_file(job_json_start_dir, job_finished_json_dir, job_json_name)\n\n    elif status_msg_dict[\"status\"] == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = \"Backend_files/Deleted_Jobs\"\n        self.move_file(job_json_start_dir, deleted_json_dir, job_json_name)\n\n    # and create the status json file\n    self.upload(status_msg_dict, status_json_dir, status_json_name)\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the content_dict as a json file to the dropbox</p> <p>content_dict: the content of the file that should be uploaded storage_path: the path where the file should be stored, but excluding the file name job_id: the name of the file without the .json extension</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Upload the content_dict as a json file to the dropbox\n\n    content_dict: the content of the file that should be uploaded\n    storage_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file without the .json extension\n    \"\"\"\n\n    # create the appropriate string for the dropbox API\n    dump_str = json.dumps(content_dict)\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        dbx.users_get_current_account()\n        dbx.files_upload(\n            dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n        )\n</code></pre>"},{"location":"utils/#utils.storage_providers.DropboxProvider.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>All the configurations are stored in the Backend_files/Config folder. For each backend there is a separate folder in which the configuration is stored as a json file.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n\"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    All the configurations are stored in the Backend_files/Config folder.\n    For each backend there is a separate folder in which the configuration is stored as a json file.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n\n    config_path = \"Backend_files/Config/\" + backend_name\n    self.upload(config_dict, config_path, \"config\")\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider","title":"<code>MongodbProvider</code>","text":"<p>             Bases: <code>StorageProvider</code></p> <p>The access to the mongodb</p> Source code in <code>utils/storage_providers.py</code> <pre><code>class MongodbProvider(StorageProvider):\n\"\"\"\n    The access to the mongodb\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n\"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n        \"\"\"\n        mongodb_username = config(\"MONGODB_USERNAME\")\n        mongodb_password = config(\"MONGODB_PASSWORD\")\n        mongodb_database_url = config(\"MONGODB_DATABASE_URL\")\n\n        uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n        uri = uri + \"/?retryWrites=true&amp;w=majority\"\n        # Create a new client and connect to the server\n        self.client: MongoClient = MongoClient(uri)\n\n        # Send a ping to confirm a successful connection\n        self.client.admin.command(\"ping\")\n\n    def upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Upload the file to the storage\n\n        content_dict: the content that should be uploaded onto the mongodb base\n        storage_path: the access path towards the mongodb collection\n        job_id: the id of the file we are about to create\n        \"\"\"\n        storage_splitted = storage_path.split(\"/\")\n\n        # get the database on which we work\n        database = self.client[storage_splitted[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_splitted[1:])\n        collection = database[collection_name]\n\n        content_dict[\"_id\"] = ObjectId(job_id)\n        collection.insert_one(content_dict)\n\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n        Get the file content from the storage\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n        \"\"\"\n        document_to_find = {\"_id\": ObjectId(job_id)}\n\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        result_found = collection.find_one(document_to_find)\n\n        if not result_found:\n            return {}\n        return result_found\n\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n\n        \"\"\"\n        job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n        job_dict.pop(\"_id\")\n        return job_dict\n\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        filter_dict = {\"_id\": ObjectId(job_id)}\n\n        newvalues = {\"$set\": content_dict}\n        collection.update_one(filter_dict, newvalues)\n\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[start_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(start_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n        result_found = collection.find_one(document_to_find)\n\n        # delete the old file\n        collection.delete_one(document_to_find)\n\n        # add the document to the new collection\n        database = self.client[final_path.split(\"/\")[0]]\n        collection_name = \".\".join(final_path.split(\"/\")[1:])\n        collection = database[collection_name]\n        collection.insert_one(result_found)\n\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Remove the file from the mongodb database\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n            job_id: the name of the file\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n        collection.delete_one(document_to_find)\n\n    def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n\"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        config_path = \"backends/configs\"\n\n        # first we have to check if the device already exists in the database\n\n        document_to_find = {\"display_name\": backend_name}\n\n        # get the database on which we work\n        database = self.client[\"backends\"]\n\n        # get the collection on which we work\n        collection = database[\"configs\"]\n\n        result_found = collection.find_one(document_to_find)\n        if result_found:\n            # update the file\n            self.update_file(\n                content_dict=config_dict,\n                storage_path=config_path,\n                job_id=result_found[\"_id\"],\n            )\n            return\n\n        # if the device does not exist, we have to create it\n        config_dict[\"display_name\"] = backend_name\n        config_id = uuid.uuid4().hex[:24]\n        self.upload(config_dict, config_path, config_id)\n\n    def update_in_database(\n        self, result_dict: dict, status_msg_dict: dict, job_id: str, backend_name: str\n    ) -&gt; None:\n\"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        The function checks if the reported status of the job has changed to DONE. If so, it will create\n        a result json file and move the job json file to the finished folder. It will also update the\n        status json file.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n        job_json_start_dir = \"jobs/running\"\n        # check if the job is done or had an error\n        if status_msg_dict[\"status\"] == \"DONE\":\n            # let us create the result json file\n            result_json_dir = \"results/\" + backend_name\n            self.upload(result_dict, result_json_dir, job_id)\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = \"jobs/finished/\" + backend_name\n            self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n        elif status_msg_dict[\"status\"] == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = \"jobs/deleted\"\n            self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n        # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n        # and create the status json file\n        status_json_dir = \"status/\" + backend_name\n        self.update_file(status_msg_dict, status_json_dir, job_id)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n\"\"\"\n        Get a list of documents in the collection of all the queued jobs.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n        # strip trailing and leading slashes from the paths\n        storage_path = storage_path.strip(\"/\")\n\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        # now get the id of all the documents in the collection\n        results = collection.find({}, {\"_id\": 1})\n        file_list = []\n        for result in results:\n            file_list.append(str(result[\"_id\"]))\n        return file_list\n\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n\"\"\"\n        A function that obtains the next job in the queue. It looks in the queued folder and moves the\n        first job to the running folder.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n\n        queue_dir = \"jobs/queued/\" + backend_name\n        job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n        job_list = self.get_file_queue(queue_dir)\n        # if there is a job, we should move it\n        if job_list:\n            job_id = job_list[0]\n            job_dict[\"job_id\"] = job_id\n\n            # and move the file into the right directory\n            self.move_file(queue_dir, \"jobs/running\", job_id)\n            job_dict[\"job_json_path\"] = \"jobs/running\"\n        return job_dict\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.__init__","title":"<code>__init__()</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def __init__(self) -&gt; None:\n\"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n    \"\"\"\n    mongodb_username = config(\"MONGODB_USERNAME\")\n    mongodb_password = config(\"MONGODB_PASSWORD\")\n    mongodb_database_url = config(\"MONGODB_DATABASE_URL\")\n\n    uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n    uri = uri + \"/?retryWrites=true&amp;w=majority\"\n    # Create a new client and connect to the server\n    self.client: MongoClient = MongoClient(uri)\n\n    # Send a ping to confirm a successful connection\n    self.client.admin.command(\"ping\")\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Remove the file from the mongodb database</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file is currently stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Remove the file from the mongodb database\n\n    Args:\n        storage_path: the path where the file is currently stored, but excluding the file name\n        job_id: the name of the file\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n    collection.delete_one(document_to_find)\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Get the file content from the storage</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n    Get the file content from the storage\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n    \"\"\"\n    document_to_find = {\"_id\": ObjectId(job_id)}\n\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    result_found = collection.find_one(document_to_find)\n\n    if not result_found:\n        return {}\n    return result_found\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of documents in the collection of all the queued jobs.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n\"\"\"\n    Get a list of documents in the collection of all the queued jobs.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n    # strip trailing and leading slashes from the paths\n    storage_path = storage_path.strip(\"/\")\n\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    # now get the id of all the documents in the collection\n    results = collection.find({}, {\"_id\": 1})\n    file_list = []\n    for result in results:\n        file_list.append(str(result[\"_id\"]))\n    return file_list\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n\n    \"\"\"\n    job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n    job_dict.pop(\"_id\")\n    return job_dict\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>","text":"<p>A function that obtains the next job in the queue. It looks in the queued folder and moves the first job to the running folder.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n\"\"\"\n    A function that obtains the next job in the queue. It looks in the queued folder and moves the\n    first job to the running folder.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n\n    queue_dir = \"jobs/queued/\" + backend_name\n    job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n    job_list = self.get_file_queue(queue_dir)\n    # if there is a job, we should move it\n    if job_list:\n        job_id = job_list[0]\n        job_dict[\"job_id\"] = job_id\n\n        # and move the file into the right directory\n        self.move_file(queue_dir, \"jobs/running\", job_id)\n        job_dict[\"job_json_path\"] = \"jobs/running\"\n    return job_dict\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[start_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(start_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n    result_found = collection.find_one(document_to_find)\n\n    # delete the old file\n    collection.delete_one(document_to_find)\n\n    # add the document to the new collection\n    database = self.client[final_path.split(\"/\")[0]]\n    collection_name = \".\".join(final_path.split(\"/\")[1:])\n    collection = database[collection_name]\n    collection.insert_one(result_found)\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    filter_dict = {\"_id\": ObjectId(job_id)}\n\n    newvalues = {\"$set\": content_dict}\n    collection.update_one(filter_dict, newvalues)\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>The function checks if the reported status of the job has changed to DONE. If so, it will create a result json file and move the job json file to the finished folder. It will also update the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>dict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>dict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def update_in_database(\n    self, result_dict: dict, status_msg_dict: dict, job_id: str, backend_name: str\n) -&gt; None:\n\"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    The function checks if the reported status of the job has changed to DONE. If so, it will create\n    a result json file and move the job json file to the finished folder. It will also update the\n    status json file.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n\n    job_json_start_dir = \"jobs/running\"\n    # check if the job is done or had an error\n    if status_msg_dict[\"status\"] == \"DONE\":\n        # let us create the result json file\n        result_json_dir = \"results/\" + backend_name\n        self.upload(result_dict, result_json_dir, job_id)\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = \"jobs/finished/\" + backend_name\n        self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n    elif status_msg_dict[\"status\"] == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = \"jobs/deleted\"\n        self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n    # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n    # and create the status json file\n    status_json_dir = \"status/\" + backend_name\n    self.update_file(status_msg_dict, status_json_dir, job_id)\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the file to the storage</p> <p>content_dict: the content that should be uploaded onto the mongodb base storage_path: the access path towards the mongodb collection job_id: the id of the file we are about to create</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Upload the file to the storage\n\n    content_dict: the content that should be uploaded onto the mongodb base\n    storage_path: the access path towards the mongodb collection\n    job_id: the id of the file we are about to create\n    \"\"\"\n    storage_splitted = storage_path.split(\"/\")\n\n    # get the database on which we work\n    database = self.client[storage_splitted[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_splitted[1:])\n    collection = database[collection_name]\n\n    content_dict[\"_id\"] = ObjectId(job_id)\n    collection.insert_one(content_dict)\n</code></pre>"},{"location":"utils/#utils.storage_providers.MongodbProvider.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n\"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    config_path = \"backends/configs\"\n\n    # first we have to check if the device already exists in the database\n\n    document_to_find = {\"display_name\": backend_name}\n\n    # get the database on which we work\n    database = self.client[\"backends\"]\n\n    # get the collection on which we work\n    collection = database[\"configs\"]\n\n    result_found = collection.find_one(document_to_find)\n    if result_found:\n        # update the file\n        self.update_file(\n            content_dict=config_dict,\n            storage_path=config_path,\n            job_id=result_found[\"_id\"],\n        )\n        return\n\n    # if the device does not exist, we have to create it\n    config_dict[\"display_name\"] = backend_name\n    config_id = uuid.uuid4().hex[:24]\n    self.upload(config_dict, config_path, config_id)\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider","title":"<code>StorageProvider</code>","text":"<p>             Bases: <code>ABC</code></p> <p>The template for accessing any storage providers like dropbox, mongodb, amazon S3 etc.</p> Source code in <code>utils/storage_providers.py</code> <pre><code>class StorageProvider(ABC):\n\"\"\"\n    The template for accessing any storage providers like dropbox, mongodb, amazon S3 etc.\n    \"\"\"\n\n    @abstractmethod\n    def upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Upload the file to the storage\n        \"\"\"\n\n    @abstractmethod\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n        Get the file content from the storage\n        \"\"\"\n\n    @abstractmethod\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the job\n        \"\"\"\n\n    @abstractmethod\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Move the file from `start_path` to `final_path`\n        \"\"\"\n\n    @abstractmethod\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n        Delete the file from the storage\n        \"\"\"\n\n    @abstractmethod\n    def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n\"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def update_in_database(\n        self, result_dict: dict, status_msg_dict: dict, job_id: str, backend_name: str\n    ) -&gt; None:\n\"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n\"\"\"\n        Get a list of files\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n    @abstractmethod\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n\"\"\"\n        A function that obtains the next job in the queue.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.delete_file","title":"<code>delete_file(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Delete the file from the storage</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef delete_file(self, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Delete the file from the storage\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the file content from the storage</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n    Get the file content from the storage\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>  <code>abstractmethod</code>","text":"<p>Get a list of files</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_file_queue(self, storage_path: str) -&gt; list[str]:\n\"\"\"\n    Get a list of files\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n\"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the job\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>  <code>abstractmethod</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n\"\"\"\n    A function that obtains the next job in the queue.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Move the file from <code>start_path</code> to <code>final_path</code></p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Move the file from `start_path` to `final_path`\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>  <code>abstractmethod</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>dict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>dict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef update_in_database(\n    self, result_dict: dict, status_msg_dict: dict, job_id: str, backend_name: str\n) -&gt; None:\n\"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Upload the file to the storage</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef upload(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n\"\"\"\n    Upload the file to the storage\n    \"\"\"\n</code></pre>"},{"location":"utils/#utils.storage_providers.StorageProvider.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>  <code>abstractmethod</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>utils/storage_providers.py</code> <pre><code>@abstractmethod\ndef upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n\"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"utils/#schemes","title":"Schemes","text":"<p>The module that contains common logic for schemes, validation etc. There is no obvious need, why this code should be touch in a new back-end.</p>"},{"location":"utils/#utils.schemes.ExperimentDict","title":"<code>ExperimentDict</code>","text":"<p>             Bases: <code>TypedDict</code></p> <p>A class that defines the structure of the experiments.</p> Source code in <code>utils/schemes.py</code> <pre><code>class ExperimentDict(TypedDict):\n\"\"\"\n    A class that defines the structure of the experiments.\n    \"\"\"\n\n    header: dict\n    shots: int\n    success: bool\n    data: dict\n</code></pre>"},{"location":"utils/#utils.schemes.GateInstruction","title":"<code>GateInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The basic class for all the gate intructions of a backend. Any gate has to have the following attributes.</p> Source code in <code>utils/schemes.py</code> <pre><code>class GateInstruction(BaseModel):\n\"\"\"\n    The basic class for all the gate intructions of a backend.\n    Any gate has to have the following attributes.\n    \"\"\"\n\n    name: str\n    parameters: str\n    description: str\n    coupling_map: List\n    qasm_def: str = \"{}\"\n    is_gate: bool = True\n\n    @classmethod\n    def config_dict(cls) -&gt; Dict:\n\"\"\"\n        Give back the properties of the instruction such as needed for the server.\n        \"\"\"\n        return {\n            \"coupling_map\": cls.__fields__[\"coupling_map\"].default,\n            \"description\": cls.__fields__[\"description\"].default,\n            \"name\": cls.__fields__[\"name\"].default,\n            \"parameters\": [cls.__fields__[\"parameters\"].default],\n            \"qasm_def\": cls.__fields__[\"qasm_def\"].default,\n        }\n</code></pre>"},{"location":"utils/#utils.schemes.GateInstruction.config_dict","title":"<code>config_dict()</code>  <code>classmethod</code>","text":"<p>Give back the properties of the instruction such as needed for the server.</p> Source code in <code>utils/schemes.py</code> <pre><code>@classmethod\ndef config_dict(cls) -&gt; Dict:\n\"\"\"\n    Give back the properties of the instruction such as needed for the server.\n    \"\"\"\n    return {\n        \"coupling_map\": cls.__fields__[\"coupling_map\"].default,\n        \"description\": cls.__fields__[\"description\"].default,\n        \"name\": cls.__fields__[\"name\"].default,\n        \"parameters\": [cls.__fields__[\"parameters\"].default],\n        \"qasm_def\": cls.__fields__[\"qasm_def\"].default,\n    }\n</code></pre>"},{"location":"utils/#utils.schemes.Spooler","title":"<code>Spooler</code>","text":"<p>The class for the spooler. So it is not just a scheme, but it also contains some common logic. So it should most likely live in another file at some point.</p> <p>Attributes:</p> Name Type Description <code>n_max_wires</code> <p>maximum number of wires for the spooler</p> <code>n_max_shots</code> <p>the maximum number of shots for the spooler</p> <code>ins_schema_dict</code> <p>A dictionary the contains all the allowed instructions for this spooler.</p> <p>Parameters:</p> Name Type Description Default <code>exper_schema</code> <p>Sets the <code>exper_schema</code> attribute of the class</p> required <code>ins_schema_dict</code> <p>Sets the <code>ins_schema_dict</code> attribute of the class</p> required Source code in <code>utils/schemes.py</code> <pre><code>class Spooler:\n\"\"\"\n    The class for the spooler. So it is not just a scheme, but it also contains some common logic.\n    So it should most likely live in another file at some point.\n\n    Attributes:\n        n_max_wires: maximum number of wires for the spooler\n        n_max_shots: the maximum number of shots for the spooler\n        ins_schema_dict : A dictionary the contains all the allowed instructions for this spooler.\n\n    Args:\n        exper_schema: Sets the `exper_schema` attribute of the class\n        ins_schema_dict : Sets the `ins_schema_dict` attribute of the class\n    \"\"\"\n\n    def __init__(\n        self,\n        ins_schema_dict: dict,\n        n_wires: int,\n        name: str,\n        description: str = \"\",\n        n_max_shots: int = 1000,\n        version: str = \"0.0.1\",\n        cold_atom_type: str = \"spin\",\n        n_max_experiments: int = 15,\n        wire_order: str = \"interleaved\",\n        num_species: int = 1,\n    ):\n\"\"\"\n        The constructor of the class.\n        \"\"\"\n        self.ins_schema_dict = ins_schema_dict\n        self.n_max_shots = n_max_shots\n        self.name = name\n        self.n_wires = n_wires\n        self.description = description\n        self.version = version\n        self.cold_atom_type = cold_atom_type\n        self.n_max_experiments = n_max_experiments\n        self.wire_order = wire_order\n        self.num_species = num_species\n\n    def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check the validity of the experiment.\n        This has to be implement in each subclass extra.\n\n        Args:\n            exper_dict: The dictionary that contains the logic and should\n                be verified.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses should implement this!\")\n\n    def get_configuration(self) -&gt; dict:\n\"\"\"\n        Sends back the configuration dictionary of the spooler.\n        \"\"\"\n        gate_list = []\n        for _, ins_obj in self.ins_schema_dict.items():\n            if \"is_gate\" in ins_obj.__fields__:\n                gate_list.append(ins_obj.config_dict())\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"version\": self.version,\n            \"cold_atom_type\": self.cold_atom_type,\n            \"gates\": gate_list,\n            \"max_experiments\": self.n_max_experiments,\n            \"max_shots\": self.n_max_shots,\n            \"simulator\": True,\n            \"supported_instructions\": list(self.ins_schema_dict.keys()),\n            \"num_wires\": self.n_wires,\n            \"wire_order\": self.wire_order,\n            \"num_species\": self.num_species,\n        }\n\n    def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check all the instruction to make sure that they are valid.\n        \"\"\"\n        err_code = \"\"\n        exp_ok = False\n        for ins in ins_list:\n            try:\n                gate_dict = gate_dict_from_list(ins)\n                self.ins_schema_dict[ins[0]](**gate_dict)\n                exp_ok = True\n            except ValidationError as err:\n                err_code = \"Error in instruction \" + str(err)\n                exp_ok = False\n            if not exp_ok:\n                break\n        return err_code, exp_ok\n\n    def check_json_dict(self, json_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n        Check if the json file has the appropiate syntax.\n\n        Args:\n            json_dict (dict): the dictonary that we will test.\n\n        Returns:\n            bool: is the expression having the appropiate syntax ?\n        \"\"\"\n        for expr in json_dict:\n            err_code = \"Wrong experiment name or too many experiments\"\n            # Fix this pylint issue whenever you have time, but be careful !\n            # pylint: disable=W0702\n            try:\n                exp_ok = (\n                    expr.startswith(\"experiment_\")\n                    and expr[11:].isdigit()\n                    and (int(expr[11:]) &lt;= self.n_max_experiments)\n                )\n            except:\n                exp_ok = False\n                break\n            if not exp_ok:\n                break\n            # test the structure of the experiment\n            err_code, exp_ok = self.check_experiment(json_dict[expr])\n            if not exp_ok:\n                break\n            # time to check the structure of the instructions\n            ins_list = json_dict[expr][\"instructions\"]\n            err_code, exp_ok = self.check_instructions(ins_list)\n            if not exp_ok:\n                break\n        return err_code.replace(\"\\n\", \"..\"), exp_ok\n</code></pre>"},{"location":"utils/#utils.schemes.Spooler.__init__","title":"<code>__init__(ins_schema_dict, n_wires, name, description='', n_max_shots=1000, version='0.0.1', cold_atom_type='spin', n_max_experiments=15, wire_order='interleaved', num_species=1)</code>","text":"<p>The constructor of the class.</p> Source code in <code>utils/schemes.py</code> <pre><code>def __init__(\n    self,\n    ins_schema_dict: dict,\n    n_wires: int,\n    name: str,\n    description: str = \"\",\n    n_max_shots: int = 1000,\n    version: str = \"0.0.1\",\n    cold_atom_type: str = \"spin\",\n    n_max_experiments: int = 15,\n    wire_order: str = \"interleaved\",\n    num_species: int = 1,\n):\n\"\"\"\n    The constructor of the class.\n    \"\"\"\n    self.ins_schema_dict = ins_schema_dict\n    self.n_max_shots = n_max_shots\n    self.name = name\n    self.n_wires = n_wires\n    self.description = description\n    self.version = version\n    self.cold_atom_type = cold_atom_type\n    self.n_max_experiments = n_max_experiments\n    self.wire_order = wire_order\n    self.num_species = num_species\n</code></pre>"},{"location":"utils/#utils.schemes.Spooler.check_experiment","title":"<code>check_experiment(exper_dict)</code>","text":"<p>Check the validity of the experiment. This has to be implement in each subclass extra.</p> <p>Parameters:</p> Name Type Description Default <code>exper_dict</code> <code>dict</code> <p>The dictionary that contains the logic and should be verified.</p> required Source code in <code>utils/schemes.py</code> <pre><code>def check_experiment(self, exper_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check the validity of the experiment.\n    This has to be implement in each subclass extra.\n\n    Args:\n        exper_dict: The dictionary that contains the logic and should\n            be verified.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses should implement this!\")\n</code></pre>"},{"location":"utils/#utils.schemes.Spooler.check_instructions","title":"<code>check_instructions(ins_list)</code>","text":"<p>Check all the instruction to make sure that they are valid.</p> Source code in <code>utils/schemes.py</code> <pre><code>def check_instructions(self, ins_list: list) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check all the instruction to make sure that they are valid.\n    \"\"\"\n    err_code = \"\"\n    exp_ok = False\n    for ins in ins_list:\n        try:\n            gate_dict = gate_dict_from_list(ins)\n            self.ins_schema_dict[ins[0]](**gate_dict)\n            exp_ok = True\n        except ValidationError as err:\n            err_code = \"Error in instruction \" + str(err)\n            exp_ok = False\n        if not exp_ok:\n            break\n    return err_code, exp_ok\n</code></pre>"},{"location":"utils/#utils.schemes.Spooler.check_json_dict","title":"<code>check_json_dict(json_dict)</code>","text":"<p>Check if the json file has the appropiate syntax.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the dictonary that we will test.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>Tuple[str, bool]</code> <p>is the expression having the appropiate syntax ?</p> Source code in <code>utils/schemes.py</code> <pre><code>def check_json_dict(self, json_dict: dict) -&gt; Tuple[str, bool]:\n\"\"\"\n    Check if the json file has the appropiate syntax.\n\n    Args:\n        json_dict (dict): the dictonary that we will test.\n\n    Returns:\n        bool: is the expression having the appropiate syntax ?\n    \"\"\"\n    for expr in json_dict:\n        err_code = \"Wrong experiment name or too many experiments\"\n        # Fix this pylint issue whenever you have time, but be careful !\n        # pylint: disable=W0702\n        try:\n            exp_ok = (\n                expr.startswith(\"experiment_\")\n                and expr[11:].isdigit()\n                and (int(expr[11:]) &lt;= self.n_max_experiments)\n            )\n        except:\n            exp_ok = False\n            break\n        if not exp_ok:\n            break\n        # test the structure of the experiment\n        err_code, exp_ok = self.check_experiment(json_dict[expr])\n        if not exp_ok:\n            break\n        # time to check the structure of the instructions\n        ins_list = json_dict[expr][\"instructions\"]\n        err_code, exp_ok = self.check_instructions(ins_list)\n        if not exp_ok:\n            break\n    return err_code.replace(\"\\n\", \"..\"), exp_ok\n</code></pre>"},{"location":"utils/#utils.schemes.Spooler.get_configuration","title":"<code>get_configuration()</code>","text":"<p>Sends back the configuration dictionary of the spooler.</p> Source code in <code>utils/schemes.py</code> <pre><code>def get_configuration(self) -&gt; dict:\n\"\"\"\n    Sends back the configuration dictionary of the spooler.\n    \"\"\"\n    gate_list = []\n    for _, ins_obj in self.ins_schema_dict.items():\n        if \"is_gate\" in ins_obj.__fields__:\n            gate_list.append(ins_obj.config_dict())\n    return {\n        \"name\": self.name,\n        \"description\": self.description,\n        \"version\": self.version,\n        \"cold_atom_type\": self.cold_atom_type,\n        \"gates\": gate_list,\n        \"max_experiments\": self.n_max_experiments,\n        \"max_shots\": self.n_max_shots,\n        \"simulator\": True,\n        \"supported_instructions\": list(self.ins_schema_dict.keys()),\n        \"num_wires\": self.n_wires,\n        \"wire_order\": self.wire_order,\n        \"num_species\": self.num_species,\n    }\n</code></pre>"},{"location":"utils/#utils.schemes.create_memory_data","title":"<code>create_memory_data(shots_array, exp_name, n_shots)</code>","text":"<p>The function to create memory key in results dictionary with proprer formatting.</p> Source code in <code>utils/schemes.py</code> <pre><code>def create_memory_data(\n    shots_array: list, exp_name: str, n_shots: int\n) -&gt; ExperimentDict:\n\"\"\"\n    The function to create memory key in results dictionary\n    with proprer formatting.\n    \"\"\"\n    exp_sub_dict: ExperimentDict = {\n        \"header\": {\"name\": \"experiment_0\", \"extra metadata\": \"text\"},\n        \"shots\": 3,\n        \"success\": True,\n        \"data\": {\"memory\": None},\n    }\n\n    exp_sub_dict[\"header\"][\"name\"] = exp_name\n    exp_sub_dict[\"shots\"] = n_shots\n    memory_list = [\n        str(shot).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n        for shot in shots_array\n    ]\n    exp_sub_dict[\"data\"][\"memory\"] = memory_list\n    return exp_sub_dict\n</code></pre>"},{"location":"utils/#utils.schemes.gate_dict_from_list","title":"<code>gate_dict_from_list(inst_list)</code>","text":"<p>Transforms a list into an appropiate dictionnary for instructions.</p> Source code in <code>utils/schemes.py</code> <pre><code>def gate_dict_from_list(inst_list: list) -&gt; dict:\n\"\"\"\n    Transforms a list into an appropiate dictionnary for instructions.\n    \"\"\"\n    return {\"name\": inst_list[0], \"wires\": inst_list[1], \"params\": inst_list[2]}\n</code></pre>"}]}